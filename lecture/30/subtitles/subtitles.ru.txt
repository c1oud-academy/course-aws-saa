Добрый день, уважаемые студенты! 
Я рад вас всех видеть на очередной лекции.
Тема сегодняшней лекции - это введение в Cloud Architecting.
Итак, давайте начнем.
Сегодняшняя лекция состоит из четырех частей.
В первой части мы познакомимся с облачной архитектурой.
Во второй части поговорим о документе AWS Well-Architected Framework.
В третьей части разберем best practices и антипаттерны при построении решений в облаке AWS.
Здесь хотелось бы отметить, что эти best practices также применимы при работе с любыми другими облачными провайдерами.
В самой последней части мы вспомним, что же такое глобальная инфраструктура AWS и узнаем дополнительно новую информацию.
На этом слайде вы видите пример типовой архитектуры в облаке AWS.
Если сейчас вам некоторые моменты непонятны, не переживайте, так как это конечный результат работы над текущим курсом.
С каждым занятием мы будем изучать какую-то определенную часть из этой архитектуры и понимать как она работает, для чего она есть в этой архитектуре.
В будущем, после прохождения наших курсов, используя полученные знания, познакомившись с определенным количеством основных AWS сервисов, у вас будет возможность самостоятельно строить, поднимать архитектуру в облаке AWS такой же сложности, либо еще сложнее.
Касательно других сервисов, все те навыки изучения сервисов, которые вы получите на наших курсах, пригодятся вам для более быстрого изучения новых AWS сервисов.
Таким образом, вы не будете ничем ограничены и будете в состоянии построить архитектуру абсолютно любой сложности в облаке AWS.
Мы с вами начинаем первую часть сегодняшней лекции и поговорим, что такое облачная архитектура.
Для того, чтобы понять важность построения правильной облачной архитектуры, давайте вспомним историю.
В 2000 году, когда e-commerce бизнес Амазона бурно развивался, для того, чтобы поддерживать этот веб-сайт, развивалась и IT инфраструктура.
Но сам бизнес очень бурно рос, что IT решения не поспевали за развитием бизнеса.
На тот момент, CEO компании AWS Энди Ясси в одном из интервью сказал, что все те инструменты, сервисы, которые поддерживают веб-сайт, это какой-то беспорядок и хаос.
Очень сложно было что-то планировать наперед и как-то отдельно рассматривать какой-то кусочек инфраструктуры, чтобы ее можно было развивать.
Она была сильно связана.
Как решение собрались лучшие специалисты и написали некоторый документ, который описывает API.
Это позволило стандартизировать какую-то часть инфраструктуры и появился хорошо задокументированный, понятный для всех команд API.
Проблемы на самом деле все не решились, осталась проблема того, что написанные компоненты, сервисы, либо инструменты, они не переиспользовались.
За счет этого команды двигались очень медленно.
Один из ярких примеров, проект рассчитан на три месяца, за три месяца было написано лишь три компонента.
Это - компонент работы с базами данных, с серверами и с хранением.
Таким образом команда даже не добралась до бизнесовой части этого проекта.
То есть все двигалось очень медленно.
В результате было решено разработать внутренние сервисы, которые развивались определенной командой.
Эти сервисы объединяли вокруг себя группу API и отвечали за некоторые IT ресурсы.
Как пример, мы знаем, что у нас есть самый популярный сервис Amazon EC2 и в этом случае IT ресурсом является сервер, то есть вычислительные мощности.
Таким образом команды внутри AWS поделились на два лагеря.
Одна часть команд разрабатывала внутренние сервисы и отвечала за корректную работу этого сервиса, а другие команды развивали сам продукт, то есть веб-сайт Amazon.
Но при этом команды двигались очень быстро, так как переиспользовали готовые внутренние сервисы.
В результате Amazon решил дать возможность всем компаниям переиспользовать эти внутренние сервисы и в 2006 году была анонсирована AWS со своими ресурсами.
Итак, возвращаясь к понятию облачная архитектура, следует понимать, это практика построения IT инфраструктуры в облаке с применением всех доступных облачных сервисов и возможностей функционала для того, чтобы удовлетворить технические требования, а также бизнесовые требования компании.
Построением облачных архитектур занимаются облачные архитекторы.
Задача облачных архитекторов: первая - это вести диалог с бизнесом для того, чтобы понять, что необходимо сделать.
Далее, вторая задача - это разработать архитектуру, черновичный вариант в виде схемы и удостовериться, что технически это можно решить.
И третья задача - это вести диалог с командой разработки для того, чтобы убедиться, что все, что нарисовано на схеме было реализовано точно в таком же виде.
В результате этих работ облачного архитектора, компания достигает своих бизнес целей, а команда разработки достигает своих технических целей и является фактически некоторым связующим звеном бизнеса и технических команд.
На этом мы подошли к концу первой части и основной идеей здесь является, что же такое облачная архитектура.
Облачная архитектура - это когда облачный архитектор используя все доступные средства, в нашем случае это сервисы и функционал сервисов AWS, построить IT архитектуру таким образом, чтобы решить и технические задачи и самое главное задачи бизнеса.
Я напоминаю, что на стороне AWS есть более 200 различных сервисов, что позволяет вам строить архитектуру абсолютно любой сложности.
Самое главное, нужен достаточный опыт и знания, чтобы правильно компоновать и комбинировать между собой эти сервисы.
Мы с вами переходим ко второй части нашей сегодняшней лекции и подробнее остановимся на документе, который называется AWS Well-Architected Framework.
AWS Well-Architected Framework - это некоторый документ, который рассматривает идеальную архитектуру в облаке AWS с точки зрения 5 направлений.
Первое направление - это Security, второе - Operational excellence, третье - Reliability, четвертое - Performance efficiency и пятое - это Cost optimization.
Для каждого направления была написана отдельная инструкция, так называемый white paper и в нем описывается все рекомендуемые командами AWS, best practices, антипаттерны для того, чтобы быть максимально приближены к идеальной архитектуре в облаке AWS.
Давайте сейчас остановимся на каждой из этих направлений более подробно.
Первое направление - это Security.
Здесь необходимо запомнить несколько основных моментов.
Первое - это то, что нам необходимо выдавать права для сущностей, как сущности могут выступать пользователи, роли либо же сервисы.
И выдавать права и доступы только в необходимом объеме, так называемый least privilege principle.
Второе - это необходимо обеспечить traceability.
Идея в том, что в случае поломки одного из компонентов, эта поломка может быть следствием предыдущей поломки.
Таким образом необходимо обеспечить видимость этой цепочки для того, чтобы однозначно и оперативно определить источник проблемы.
То есть самый первый компонент, который сломался и привел к тому, что следующие компоненты тоже после него сломались.
И третий пункт - это то, что нам необходимо обеспечить безопасность на всех слоях.
А именно это то, что данные должны храниться в зашифрованном виде, а также данные должны передаваться в защищённом зашифрованном виде.
Второе направление - это Operational excellence.
Идея в том, что нам необходимо добиться видимости нашей инфраструктуры.
Это делается за счет метрик и за счет логов.
Когда у нас есть на руках эти данные, мы можем анализировать и понимать насколько хорошо и эффективно работает наша система.
В случае, если некоторые наши IT ресурсы не соответствуют по типу и за счет этого работают не эффективно, мы это можем увидеть и можем небольшими шагами её улучшать и подгонять под специфичные на наш IT продукт нагрузки.
Этот процесс будет происходить постоянно.
Невозможно добиться до идеального состояния, потому как нагрузки меняются, продукты постоянно развиваются, появляются разные компоненты.
Но идея этого направления в том, что мы должны обеспечить этот процесс необходимыми данными и соответственно небольшими шагами с каждым разом улучшать и оптимизировать размеры нашей инфраструктуры, даже если когда нагрузки меняются.
Следующее направление - это Reliability.
Идея этого направления в том, что нам необходимо строить IT инфраструктуру таким образом, что в случае поломки мы оперативно понимали где эта поломка произошла и в лучшем случае обеспечить автоматическое восстановление инфраструктуры.
То есть в случае нехватки IT ресурсов с увеличением нагрузки система должна динамически увеличивать количество вычислительных ресурсов.
В случае когда у нас выходит из строя одна availability зона, инфраструктура должна быть способна продолжать корректно работать на другой availability зоне и так далее.
Четвертое направление - это Performance efficiency.
Идея этого направления в том, что нам необходимо в зависимости от нашей бизнес задачи и технической задачи подобрать инструмент, с которым мы ее будем решать, а не наоборот.
Я несколько раз упоминал, что на стороне AWS есть более 200 сервисов, которые доступны для нас и одним из примеров может быть наличие более 7 сервисов связанных с базами данных.
Таким образом в зависимости от того какие у вас данные, как к этим данным идет обращение, какая частота обращения, как часто эти данные записываются или наоборот считываются, вы можете понять какая из существующих сервисов баз данных вам подойдет больше всего.
Последнее, пятое направление - это Cost optimization.
Это одно из самых моих любимых направлений.
Связано это с тем, что при корректной работе в этом направлении мы сможем максимально раскрыть потенциал работы с облачными технологиями.
Идея этого направления в том, что мы должны обеспечить видимость для чего и кем создаются те или иные ресурсы.
За счет этого мы понимаем насколько эффективно работают те или иные компоненты, команды или даже IT ресурсы в облаке AWS.
Таким образом, получив эту видимость, мы можем исключить избыточные расходы на облачную инфраструктуру.
На этом мы добрались до AWS Well-Architected Tool.
Да, это еще один специальный сервис, который включается на уровне AWS аккаунта и говорит о том, насколько хорошо или плохо мы построили IT инфраструктуру по сравнению с идеальной IT инфраструктурой, описанной в Well-Architected Framework.
Мы добрались до конца второй части нашей сегодняшней лекции.
Давайте вспомним основные моменты.
AWS Well-Architected Framework - это некоторый документ, который описывает идеальную инфраструктуру по мнению архитекторов AWS.
Она описана в пяти различных направлениях, каждый из которых состоит из некоторых best practices.
Я ранее говорил, что этот документ описан по мнению архитекторов AWS и здесь подразумевается то, что этот документ не видит вашего контекста.
Поэтому слепо следовать этим рекомендациям не следует, так как не все рекомендации одинаково будут эффективны для конкретно вашего случая.
Поэтому надо знать, что есть такие рекомендации, отдельно применять каждую для своего случая и в случае, если это действительно дает ту эффективность, которую вы ожидаете, следует ее исполнить и реализовать.
Есть также AWS Well-Architected Tool, который автоматически позволяет некоторые best practices видеть, насколько вы следуете или не следуете в рамках вашего AWS аккаунта.
Мы с вами добрались до третьей части нашей сегодняшней лекции.
Здесь мы будем говорить про best practices и антипаттерны при построении решений в облаке AWS.
Основная мысль этой части в том, что вам необходимо понимать, действительно ли тот или иной best practice подходит для вашего случая.
Более того, любой best practice требует ее реализации и в этом случае есть определенные жертвы, которые вы понесете.
Например, это могут быть время, которое потратит команда разработки, либо команда облачных инженеров на реализацию этого best practices.
Другой момент может быть в том, что вы увеличите свои расходы на облачную инфраструктуру и так далее.
Поэтому всегда при рассмотрении best practices нужно понимать, какие недостатки она с собой приносит и понимать, действительно ли оно того стоит.
Для того, чтобы лучше понять смысл каждого best practices, мы будем приводить антипаттерны того, как не следует делать.
Таким образом, вы лучше поймете в сравнении, как должно быть и как не должно быть.
В этой части мы рассмотрим 10 best practices.
Итак, давайте начнем.
Первый best practice - это Enable scalability.
Идея в том, что ваша инфраструктура должна быть способной автоматически меняться в размерах, как в сторону увеличения, так и в сторону уменьшения, в зависимости от нагрузки.
Если у вас инфраструктура построена следующим образом, как на картинке на слайде: у вас есть пользователи, они дают некоторую нагрузку на вашу инфраструктуру, есть определенное количество настроенных серверов.
Далее у вас есть администратор, который может получать по тем или иным каналам связи уведомления о том, что сервера испытывают большие нагрузки.
Далее, этот администратор подключается к инфраструктуре, настраивает вручную сервер и подключает к балансировке.
Это - не есть best practice, так как оно не выгодно с точки зрения затрат, так как сюда еще и входит время работы специалиста.
Более того, оно подвержено человеческому фактору, то есть пока администратор подключится, нагрузки могут превысить некоторый порог и приложение перестанет отвечать.
В этом случае будет поздно новый сервер поднимать.
Другой момент - это то, что администратор забыл отключить сервера, а нагрузка уже давно упала.
В этом случае вы будете нести избыточные расходы.
Правильный вариант - это использовать все необходимые инструменты и доступные сервисы AWS, чтобы динамически увеличивать количество серверов, либо уменьшать, когда нагрузки нет.
Вы видите пример, что есть пользователи, от них приходят запросы, есть текущие серверы, на которых балансируется нагрузка и в случае увеличения нагрузки выше определенного порога приходят уведомления на соответствующий сервис.
Этот сервис автоматически поднимает необходимое количество серверов, чтобы каждый запрос пользователей был обработан.
И обратный случай, когда пользователи завершают свои покупки или действия на вашем сайте и уходят, то срабатывает обратная ситуация: приходит уведомление сервису масштабирования о том, что нагрузка на сервера спала и этот сервис может отключать лишние сервера, для того чтобы не нести эти расходы.
Следующий best practice - это Automate your environment.
Идея - там где это возможно автоматически создавать, уничтожать, а также конфигурировать ваши ресурсы в вашей инфраструктуре.
Рассмотрим антипаттерн.
Он очень похож на антипаттерн на предыдущем слайде, но отличается тем, что ваш сервер может словить некоторую внутреннюю ошибку и перестать работать.
В этом случае количество рабочих серверов становится меньше.
Представим, что вы настроили уведомление вашему администратору, подключается администратор и начинает восстанавливать этот сервер, либо начинает создавать новый, чтобы потом спокойно сесть и разобраться с поломанным сервером.
И это происходит в то время, когда происходит ошибка и поломка в системе.
Это может быть ночью, утром, днем и в нерабочее время вашего специалиста.
Это является антипаттерном, так как есть очевидные недостатки.
Первое - вам необходимо поверх дополнительно оплачивать время работы вашего специалиста.
Это могут быть оплата за сверхурочные часы.
Другой момент - здесь есть человеческий фактор, то есть человек может быть недоступен или не успеть, не заметить.
Таким образом, состояние вашей инфраструктуры зависит от одного или нескольких специалистов, которые не смогут в нужный момент подключиться.
Обратная ситуация - best practice - как рекомендуется сделать, это использовать имеющиеся средства, а именно сервис Auto Scaling, для того, чтобы определять проблемные сервера, убирать эти сервера в сторону, вместо них поднимать необходимое количество серверов, которые точно будут работать, так как только настроены.
Опционально могут еще отправить уведомление администратору о том, что такое-то количество с такими-то ID-шниками сервера были поломаны и вместо них были подняты следующие сервера с такими-то ID-шниками.
Это best practice, который не вынуждает специалиста подключаться во время поломки, дает возможность не вводить специалиста в стрессовое состояние, а сохранить ваши поломанные сервера отдельно в сторонке, при этом продолжать обрабатывать успешно запросы ваших пользователей.
В тот момент, когда начнется рабочий день, специалист уже получит уведомление и сразу пойдет смотреть на сервера, которые были отложены в сторону, разбираться в проблеме.
Следующий, третий best practice - это Treat resources as disposable.
Идея в том, что нам необходимо воспринимать нашу инфраструктуру, наши IT ресурсы не как железо hardware, а больше как software.
Таким образом, мы не привязаны к железу и это приводит к тому, что каждый IT ресурс может быть легко заменен.
А это в свою очередь позволит нам динамически управлять нашими IT ресурсами, что доступно в облачной среде.
Следующий, четвертый best practice - это Use loosely coupled components.
Идея этого best practice в том, что нам необходимо строить инфраструктуру таким образом, чтобы каждый компонент был связан с наименьшим количеством соседних компонентов.
Для того, чтобы это понять, давайте рассмотрим антипаттерн.
Представим, что у нас есть слой веб-серверов, у нас есть слой back-end, то есть application сервера.
И каждый сервер слоя веб-серверов сильно связан с серверами back-end.
Это приводит к тому, что при замене, обновлении одного из компонентов в веб-слое нам необходимо учитывать все связи и если требуется изменение на стороне соседних связанных компонентов, то необходимо произвести это изменение в нескольких соседних компонентах, не в одном.
Это может быть дорого, сложно и не всегда реализуемо.
Более того, если при сильно связанной архитектуре какой-то компонент ломается, оно может повлечь за собой волну поломок, и потенциально все связанные компоненты с поломанным компонентом также могут сломаться.
И так далее: все поломанные уже от исходной поломки, исходного компонента, они также может привести к поломке следующих компонентов.
В итоге вся инфраструктура может просто упасть из-за какой-то маленькой ошибки на уровне одного компонента.
Это очень рискованно, это является антипаттерном.
Лучшим решением best practice является то, что мы строим каждый компонент минимально связанный с другими соседними компонентами.
Это позволяет достаточно безопасно, дешево и эффективно заменять, удалять либо обновлять каждый из компонентов.
Примерами сервисов, которые позволяют нам строить слабосвязные архитектуры, являются ELB, Amazon SQS.
Это сервис очередей сообщения, о которых мы будем говорить на следующих наших занятиях.
Следующий пятый best practice - это Design Services, Not Servers.
Идея в том, что в самом начале в период активной разработки рекомендуется смотреть в сторону Managed Services, Serverless Services или любых других сервисов AWS, которые потенциально смогут разгрузить вашу команду.
То есть команде нет необходимости разрабатывать тот или иной технический функционал, технический инструмент.
За счет этого команда может сконцентрироваться на написании бизнес-логики, которая будет решать задачи бизнеса.
Это в свою очередь позволит раньше выйти на рынок, раньше начать зарабатывать в компании и в целом это правильное направление.
Далее уже в период пассивной разработки, когда основной функционал разработан и задач не так много, есть рекомендация пересмотреть структуру расходов на облако.
Если окажется, что определенный сервис не соразмерно потребляет много денег, в этом случае вы можете сделать некоторый расчет.
Например, для реализации сервиса очереди сообщений вы можете посмотреть расходы AWS, далее посмотреть и прикинуть, сколько подобный функционал, внутренний инструмент будет разрабатывать ваша команда либо отдельно взятый специалист.
В случае, когда эти расходы сопоставимы, вы можете делать расчет на краткосрочный период, среднесрочный период и долгосрочный период.
В случае, если окажется, что написание внутреннего решения окажется выгодным, в этот момент вы можете потихоньку переходить на собственные разработки.
Почему не рекомендуется делать это с самого начала? 
Так это то, что вся ваша команда может оказаться в состоянии, что они разрабатывают некоторые технические инструменты и зависнуть на этом этапе и даже не добраться до написания бизнес-логики для решения ваших бизнес-задач.
Это в свою очередь может поставить крест на будущем вашей компании и компания может в результате обанкротиться.
Следующий, шестой best practice - это Choose the right database solution.
Идея этого best practices в том, что при работе с облачными технологиями у нас имеется в распоряжении несколько десятков сервисов, которые позволяют хранить, обрабатывать, анализировать данные.
И в зависимости от того, как ваши данные используются, как часто записываются, как часто считываются, какой объем данных ожидается, потенциально до каких размеров ваши данные могут вырасти, какие требования по передаче данных, какие требования по количеству одновременных подключений к вашим данным и так далее, вы можете подобрать оптимальный сервис.
И с учетом того, что расходы на вычислительные мощности и базы данных могут с легкостью доходить до 50% всех ваших расходов на облако, выбрав в самом начале пути верное решение, вы можете сразу получить большую выгоду и в будущем не нести избыточные расходы.
Следующий best practice - это Avoid single points of failure.
Идея в том, что вам необходимо строить вашу инфраструктуру таким образом, что в критически важных местах у вас есть некоторая избыточность.
Здесь понимается то, что в случае поломки критических узлов есть запасной вариант и в случае поломки этого критического узла вся система не остановится, а продолжит работать.
Примерами могут быть, когда мы хостим наше решение на нескольких availability зонах, либо в той же availability зоне, но у нас есть, например, в случае базы данных есть основная база данных, а рядом стоит standby копия, которая при необходимости может стать master базой и продолжить принимать запросы от ваших приложений.
Следующий best practice - это Optimize for cost.
Идея этого best practice в том, что вам необходимо использовать возможности, предоставляемые облачным провайдерам, а именно то, что предоставляется широкий выбор типов инстансов, широкий выбор сервисов, которые автоматически масштабируют вашу инфраструктуру.
Таким образом, экспериментируя с типами IT ресурсов и их комбинациями, можно построить такую инфраструктуру, которая идеально подходит вашим нагрузкам.
В случае когда мы говорим локальный дата-центр таких возможностей может не быть, так как выделение под ваш аккаунт, под вашу организацию дополнительных IT ресурсов может занимать некоторое время.
В нем могут присутствовать некоторые человеческие факторы, например, нужно завести заявку, отправить ее в техподдержку для того, чтобы вам выделили эти ресурсы.
Либо даже если там все автоматизировано, то размеры дата-центра несравнимо малы по сравнению с глобальной инфраструктурой AWS.
Поэтому ожидать, что там будет большой выбор типов тех же серверов не стоит.
Он будет скорее всего намного меньше и будет мало вариантов, с которыми вы сможете поэкспериментировать.
Следующий best practice - это Use caching.
Идея в том, что во всех тех местах, где можно организовать кэширование необходимо это делать.
Есть для этого несколько важных причин.
Первое - это то, что когда данные извлекаются с оригинального источника, они могут видоизменяться, трансформироваться.
И для этого необходимо потратить больше вычислительных ресурсов.
Это требует большего времени и, соответственно, все будет стоить дороже, нежели вы  извлечете с кэша готовый результат.
Другой момент - это то, что кэш сервера они могут находиться ближе к вашим пользователям.
Таким образом, и пользователи получат данные быстрее и вы также сэкономите на Network трафике.
Так как он значительно уменьшится и вам нет необходимости для каждого запроса обращаться к оригинальному источнику.
Примерами может быть использование сервиса CloudFront - это глобальный CDN, Content Delivery Network.
Также если мы говорим про кэширование можно назвать сервис ElastiCache, когда можем настроить Redis либо Memcached ресурс для того, чтобы разгрузить вашу базу данных.
Самый последний, десятый best practice - это Secure your entire infrastructure.
Основная идея этого best practice связана с тем, что нам необходимо обеспечить безопасность на каждом уровне нашей инфраструктуры.
Приведу пару примеров.
Первый пример - необходимо обеспечить шифрование ваших данных не только во время хранения, но и во время передачи этих данных.
Другой пример - необходимо следовать принципу Least Privilege, когда вы выдаёте права роли пользователям либо какому-либо сервису только в том объёме, который нужно для выполнения определённой задачи.
Следующий пример - необходимо включить MFA там, где это возможно.
MFA - это Multi-Factor Authentication.
Таким образом, события, которые могут быть катастрофическими либо являются критическими, вы можете дополнительно обезопасить проверкой личности конкретного пользователя.
Другой пример - это использование Managed Services.
Managed Services - это когда большую часть рутинного администрирования берет на себя AWS, а нам как пользователям облачных технологий и этих конкретных сервисов необходимо обеспечить корректную настройку этих сервисов.
Таким образом, настройка безопасности, установка, обновление патчей безопасности, это все ложится на плечи облачного провайдера.
Другой пример - это то, что необходимо логировать все действия связанные с критическими ресурсами, так чтобы в нужный момент вы могли определить кто, когда, как, для чего обращался к конкретным ресурсам.
На этом мы добрались до конца третьей части нашей сегодняшней лекции.
Мы рассмотрели 10 best practices.
Для каждого best practices рассмотрели антипаттерн и несколько примеров для того, чтобы лучше ее освоить.
Я надеюсь, вы лучше поняли, что такое best practices, как это связано с облачной архитектурой и в будущем это вам будет помогать при построении своей архитектуры в облаке AWS.
А мы с вами плавно переходим к последней четвертой части нашей сегодняшней лекции и поговорим про глобальную инфраструктуру AWS.
Мы эту тему затрагивали на предыдущем курсе Cloud Practitioner.
Сейчас ее повторим и добавим некоторые новые нюансы.
Начнем мы с понятия AWS Regions.
Region - это некоторая физическая географическая локация, которая изолирована от других регионов.
Всего в мире есть более 20 AWS Regions.
Каждый AWS Region состоит из двух или более availability zone.
Regions, связанные между собой, отдельно специально выделены сетью AWS.
Так как регионы изолированы друг от друга, то задачу репликации или передачи данных между регионами вам необходимо настраивать самостоятельно.
Для этого имеются все средства, лишь требуется дополнительная настройка, она недоступна нативно.
В случае с availability zone во время настройки некоторых ресурсов вы там же можете выбрать какие availability zone этот сервис будет использовать.
В случае с регионами такой опции не будет.
В мире есть разные типы AWS регионов.
Большее количество регионов это стандартные регионы.
Есть также два региона относящихся к Китаю, то есть так называемые AWS China.
Они изолированы от всего остального мира и развивается отдельно.
Зачастую мы наблюдаем то, что любой сервис, который находится в AWS China на год или более отстает по развитию по сравнению с регионами вне Китая.
Есть еще другой тип региона это AWS GovCloud.
Это специально созданный регион для хостинга IT инфраструктур связанных с государственными учреждениями в Америке.
Теперь давайте рассмотрим следующий элемент глобальной инфраструктуры AWS - это availability zone.
Availability zone относится к определенному региону.
Если мы говорим, что у нас есть глобальная AWS, у нее есть несколько десятков регионов, например, eu-west-1.
У этого региона есть несколько availability zone и примером availability zone является eu-west-1a.
То есть название availability zone это название региона плюс некоторая буква алфавита.
Когда мы говорим про availability zone, каждая availability zone состоит как минимум из одного, а то и нескольких дата-центров.
Таким образом, вероятность того, что availability zone станет недоступной маловероятна, не говоря уже о том, что весь регион станет недоступным.
Но есть в мире некоторые очень критические нагрузки, которые ни в коем случае не должны быть прерваны.
В этих случаях компании развертывают свою инфраструктуру на нескольких регионах.
Это очень дорого, но когда есть бизнес задача и некоторые требования, то подобные инфраструктуры тоже имеют место быть.
Availability zone в рамках региона связаны между собой специальной связкой и данные могут передаваться на больших скоростях между этими availability zone.
Следующий достаточно новый компонент глобальной инфраструктуры - это AWS local zones.
Идея local zones в том, что оно является мини регионом, который находится в какой-то отдаленной локации.
То есть в случае, если на ближайшем расстоянии не имеется AWS регионов, а вам нужно, чтобы в определенной местности в рамках страны был доступен AWS, в этом случае вам в помощь придет AWS local zones.
То есть разворачивается мини дата-центр, который доступен для вас и вы можете использовать эти ресурсы в рамках вашей страны.
Для некоторых случаев нагрузок и бизнесов это достаточно интересное решение.
Теперь мы переходим к следующему компоненту внутри availability зоны - это дата-центры.
Дата-центры - это как раз таки то место, где находятся все наши сервера, хранятся все данные на этих серверах и это наименьший компонент глобальной инфраструктуры AWS.
Если мы говорим о размерах дата-центров, то каждый дата-центр как минимум содержит несколько десятков тысяч серверов.
Эти сервера могут быть очень мощными, так как происходит процесс виртуализации и один мощный сервер может быть разделен и предоставлен для вас как несколько разных маленьких инстансов.
Таким образом понимая, что дата-центр это физически ограниченное пространство, то AWS старается каждый кусочек пространства использовать максимально выгодно и соответственно каждый сервер будет максимально мощным, если умножать на то количество, которое я говорил ранее, это несколько десятков тысяч таких мощных серверов, то вы можете представить какие масштабы вычислительных мощностей доступны в рамках лишь одного дата-центра.
Следующим отдельно стоящим компонентом глобальной инфраструктуры AWS и которая относится к CDN, то есContent Delivery Networkть  является AWS Points of presence.
Они непосредственно относятся к сервису Amazon CloudFront и выделяют несколько разных видов.
Это Edge locations и Regional edge caches.
Отличается тем, что Edge locations - это наиболее ближайшие к вашим потенциальным пользователям кэш сервера и данные максимально быстро передаются именно с Edge locations.
Далее, чуть-чуть отдаленные кэш сервера - это Regional edge caches, туда попадают те данные, которые не так часто запрашиваются как данные в Edge locations, но тем не менее запрашиваются и они агрегируются на более масштабной географической местности, то есть объединяют в себе не частые данные из нескольких Edge locations.
На карте вы видите также Multiple edge locations, выделенные фиолетовым цветом.
Это как раз таки те локации, в которых очень хорошо развит AWS, очень активно используется сервис Amazon CloudFront и вы видите, что на этом слайде они выделены отдельно.
На этом мы подошли к концу последней части нашей сегодняшней лекции.
Мы рассмотрели глобальную инфраструктуру AWS, основные ее компоненты и для чего они нужны.
На этом мы подошли к концу нашей сегодняшней лекции, разобрали достаточно важные основные понятия, которые вам помогут легче освоить следующие наши лекции.
Здесь вы можете увидеть несколько полезных ссылок для более углубленного изучения пройденных материалов.
На этом хотелось бы завершить нашу сегодняшнюю сессию.
Спасибо за внимание.
Увидимся с вами на следующих наших активностях.
