WEBVTT

00:00:00.000 --> 00:00:05.000
Добрый день, уважаемые студенты! Я рад вас всех видеть на очередной лекции.

00:00:05.000 --> 00:00:09.000
Тема сегодняшней лекции – это хранение.

00:00:09.000 --> 00:00:14.000
Эта тема достаточно объемная, поэтому мы будем проходить ее в течение двух недель.

00:00:14.000 --> 00:00:17.000
Сегодня будет первая часть. Итак, давайте начнем.

00:00:19.000 --> 00:00:22.000
В сегодняшней лекции у нас будет две секции.

00:00:22.000 --> 00:00:27.000
В первой секции мы разберем архитектуру, над которой будем работать в течение всего семестра.

00:00:27.000 --> 00:00:32.000
И по мере прохождения новых сервисов AWS, будем дополнять эту архитектуру.

00:00:33.000 --> 00:00:38.000
Во второй секции мы разберем use-кейсы использования сервиса Amazon S3.

00:00:39.000 --> 00:00:44.000
Также в отдельной видео активности на этой неделе для вас будет доступна демо.

00:00:44.000 --> 00:00:51.000
В этом демо мы разберем фенкционал вершининга для сервиса Amazon S3.

00:00:52.000 --> 00:00:54.000
Далее у нас будет лабораторная работа.

00:00:54.000 --> 00:00:59.000
Как мы с вами помним, для лабораторной работы будут две отдельные видео активности.

00:00:59.000 --> 00:01:04.000
Это обзор лабораторной работы, а также разбор лабораторной работы.

00:01:04.000 --> 00:01:14.000
Тема лабораторной работы – это создание статического веб-сайта и его хостинг в сервисы Amazon S3.

00:01:14.000 --> 00:01:21.000
Мы начинаем с вами первую секцию и рассматриваем простейшую архитектуру в облаке AWS.

00:01:21.000 --> 00:01:24.000
Эту архитектуру мы будем разрабатывать в течение всего семестра.

00:01:24.000 --> 00:01:31.000
И в результате вы видите всю эту архитектуру в виде диаграммы.

00:01:32.000 --> 00:01:36.000
В рамках текущей недели мы активируем компонент внизу слева.

00:01:36.000 --> 00:01:38.000
Это static website on S3.

00:01:38.000 --> 00:01:44.000
У сервиса Amazon S3 есть функционал хостинга статических веб-сайтов.

00:01:44.000 --> 00:01:53.000
Таким образом, мы в рамках нашей бизнес задачи, бизнес-кейса активируем этот функционал.

00:01:53.000 --> 00:02:09.000
И для нашего кафе внутри use-кейса создадим статический веб-сайт.

00:02:09.000 --> 00:02:13.000
Он будет хоститься в сервисе Amazon S3.

00:02:15.000 --> 00:02:21.000
Чтобы задача по построению архитектуры в облаке AWS не выглядела абстрактной задачей,

00:02:21.000 --> 00:02:25.000
мы будем рассматривать ее в рамках бизнес-кейса.

00:02:25.000 --> 00:02:31.000
В нашем случае это будет бизнес небольшого кафе с пекарней.

00:02:31.000 --> 00:02:35.000
Владельцами этой пекарни являются Фрэнк и Марта.

00:02:35.000 --> 00:02:40.000
Они муж с женой, а также являются пенсионерами.

00:02:40.000 --> 00:02:43.000
У Фрэнка с Мартой есть дочка София.

00:02:43.000 --> 00:02:46.000
Она помогает родителям вести этот небольшой бизнес.

00:02:46.000 --> 00:02:52.000
А также параллельно обучается IT-технологиям в университете.

00:02:52.000 --> 00:02:55.000
В том числе уличные технологии.

00:02:55.000 --> 00:03:08.000
В этом кафе также работает на полставки Нихилл, который также является студентом университета и изучает IT-дисциплины.

00:03:08.000 --> 00:03:14.000
Кафе недавно открылось.

00:03:14.000 --> 00:03:19.000
У нее еще нет какой-то маркетинговой стратегии развития.

00:03:19.000 --> 00:03:28.000
Поэтому об этом кафе знают только местные жители, а также знакомые владельцев этого небольшого бизнеса.

00:03:28.000 --> 00:03:36.000
София предложила своим родителям попытаться увеличить количество посетителей через создание веб-сайта.

00:03:36.000 --> 00:03:48.000
На этом веб-сайте они могли бы опубликовать меню, время работы, месторасположение, адрес этого кафе и другие детали.

00:03:48.000 --> 00:03:53.000
� одителям Фрэнку и Марте эта идея понравилась.

00:03:53.000 --> 00:04:07.000
Поэтому в рамках этой недели мы будем изучать возможности облачных технологий сервисов AWS, которые помогут нам решить эту бизнес-задачу.

00:04:07.000 --> 00:04:13.000
На этом мы завершаем первую секцию и двигаемся к следующей части.

00:04:13.000 --> 00:04:22.000
Мы с вами добрались до второй секции нашей сегодняшней лекции и разберем use-кейсы сервиса Amazon S3.

00:04:22.000 --> 00:04:30.000
Amazon S3 это Simple Storage Service, сервис который предоставляет нам объектное хранение.

00:04:30.000 --> 00:04:39.000
В этом сервисе мы можем хранить достаточно большой объем информации, данных практически в неограниченном объеме.

00:04:39.000 --> 00:04:44.000
Данные хранятся объектно внутри так называемых бакетов.

00:04:44.000 --> 00:04:54.000
Так как мы говорим объектное хранилище, то подразумевается, что внутри S3 изменять файлы мы не можем.

00:04:54.000 --> 00:05:00.000
Если нам необходимо изменить файл, мы должны либо его скачать, либо локальную копию изменить и загрузить ее обратно.

00:05:00.000 --> 00:05:05.000
Таким образом в S3 появится следующая новая версия.

00:05:05.000 --> 00:05:14.000
Когда мы говорим бакеты, это некие корневые папки, в которых хранятся наши данные.

00:05:14.000 --> 00:05:26.000
Название бакета оно должно быть уникально глобально, то есть вы не можете создать два бакета с одинаковыми названиями в различных регионах.

00:05:26.000 --> 00:05:34.000
Он должен быть уникальный глобально, но тем не менее ваши данные внутри S3 бакета, они хранятся в определенном регионе.

00:05:34.000 --> 00:05:44.000
Поэтому при создании бакета вы указываете глобальное имя, но рядом также указываете регион, в котором фактически ваши данные будут храниться.

00:05:44.000 --> 00:05:56.000
Если мы говорим про размер файлов внутри S3 бакета, то для одного файла он может быть от 0 байтов до 5 терабайтов.

00:05:56.000 --> 00:06:05.000
То есть практически любой вид объекта он спокойно помещается в S3.

00:06:10.000 --> 00:06:16.000
Каждый объект внутри S3 бакета содержит пять характеристик.

00:06:16.000 --> 00:06:25.000
Первое это key, либо по другому говоря, путь до этого файла, подразумевается весь полный путь.

00:06:25.000 --> 00:06:32.000
Сам S3 не различает файл храниться внутри папки, либо хранится в корне S3 бакета.

00:06:32.000 --> 00:06:45.000
Возможность создания папок и организации всех наших файлов внутри бакета в различных вложенных папках это сделано специально для удобства использования.

00:06:45.000 --> 00:06:56.000
Сам же S3 хранит у себя внутри по другому и значением для каждого файла является весь полный путь до этого файла.

00:06:56.000 --> 00:07:05.000
Следующая характеристика это versionid, то есть во время перезагрузки вашего файла он обретает новый versionid.

00:07:05.000 --> 00:07:11.000
Так мы можем различать различные версии одного и того же файла.

00:07:11.000 --> 00:07:21.000
Следующий компонент это значение, в нашем случае это последовательность байтов, то есть само значение, сами наши данные.

00:07:21.000 --> 00:07:35.000
Четвертое это metadata, так называемые теги. Теги это пары ключ-значения, они могут быть системными, также они могут быть user defined, то есть определены пользователем.

00:07:35.000 --> 00:07:49.000
Самое последнее это subresources, это некоторая дополнительная информация специфичная для конкретного объекта для работы сервиса Amazon S3.

00:07:49.000 --> 00:07:57.000
Давайте подробнее остановимся на основных преимуществах сервиса Amazon S3.

00:07:57.000 --> 00:08:07.000
Первое это надежность. Надежность сервиса S3 измеряется 11 девятками или 99.99%.

00:08:07.000 --> 00:08:15.000
Это достаточно хорошие показатели, давайте приведем пример для наглядности.

00:08:15.000 --> 00:08:24.000
Если мы в одном бакете будем хранить 10 тысяч объектов, то в течение целого года мы максимум потеряем один объект.

00:08:24.000 --> 00:08:38.000
Следующее преимущество это availability, она измеряется четырьмя девятками, то есть 99.99% того, что мы доберемся до наших файлов и сможем их загрузить.

00:08:38.000 --> 00:08:54.000
Availability чуть ниже чем durability, это нормально ввиду того, что могут возникнуть некоторые проблемы с сетью, но самое главное, что данные надежно хранятся.

00:08:54.000 --> 00:09:10.000
В случае, если возникли проблемы с загрузкой объекта, мы можем всегда сделать вторую попытку и вторая попытка чаще всего успешно срабатывает и файл в итоге загружается.

00:09:10.000 --> 00:09:27.000
Другое преимущество это то, что мы оплачиваем сервис S3 по модели pay as you go, то есть если мы храним лишь 1 гигабайт данных внутри этого сервиса, то ровно столько мы будем оплачивать ежемесячно.

00:09:27.000 --> 00:09:39.000
Если на второй месяц мы очистили наши бакеты и на текущий момент у нас 0 гигабайтов данных хранятся в S3 бакете, то мы ничего не будем оплачивать через месяц.

00:09:39.000 --> 00:09:53.000
Таким образом это удобно и нас никто не вынуждает покупать пакет 100 гигабайт 500 гигабайт или 1 терабайт места и оплачивать это место вне зависимости от того мы используем ее или нет.

00:09:53.000 --> 00:09:59.000
Таким образом хранение в S3 оно может быть экономически выгодно.

00:09:59.000 --> 00:10:14.000
Мы с вами добрались до основной части текущей секции и рассмотрим основные юскейсы сервиса Amazon S3. Самые первые и самые популярные это использование S3 в качестве хранилища медиа данных.

00:10:14.000 --> 00:10:23.000
Это могут быть различные видео материалы, аудио, картинки, может текстовая информация и так далее.

00:10:23.000 --> 00:10:32.000
Вы можете используя S3 давать прямую ссылку для загрузки вашим пользователям.

00:10:32.000 --> 00:10:47.000
В этом случае домен будет стандартного вида это bucketname.s3.amazon.aws.com. Дальше указывается путь до вашего объекта.

00:10:47.000 --> 00:10:59.000
Вы также можете распространять ваши медиа данные через CDN. В нашем случае это Amazon CloudFront.

00:10:59.000 --> 00:11:06.000
Давайте подробнее остановимся на теме безопасности S3 бакетов и объектов внутри этих бакетов.

00:11:06.000 --> 00:11:12.000
Все бакеты они изначально приватные и защищенные.

00:11:12.000 --> 00:11:18.000
Когда мы выдаем доступ к объектам или бакетам необходимо следовать принципу list privilege.

00:11:18.000 --> 00:11:28.000
То есть мы выдаем только доступ только тем сущностям и только в том объеме, который нужно для выполнения задачи.

00:11:28.000 --> 00:11:37.000
Если мы говорим про предоставление доступа у нас есть широкий выбор функционала.

00:11:37.000 --> 00:11:42.000
Давайте остановимся на каждом из них. Самое первое это блок Public Access Feature.

00:11:42.000 --> 00:11:53.000
Идея в том, что если мы хотим гарантированно закрыть любой публичный доступ на наши S3 бакеты, то необходимо эти галочки включить.

00:11:53.000 --> 00:12:02.000
Это некоторый переключатель и нужно выставлять флажочки на уровне настройка бакета.

00:12:02.000 --> 00:12:10.000
В случае если вам все таки нужно предоставить некоторый публичный доступ пусть и ограниченный.

00:12:10.000 --> 00:12:14.000
Первым делом вам необходимо эти флажочки снять.

00:12:14.000 --> 00:12:18.000
Следующее это IAM Policies.

00:12:18.000 --> 00:12:27.000
Идея в том, что у нас есть некоторые сущности это роли пользователей и группы, которым мы привязываем наши полиси.

00:12:27.000 --> 00:12:37.000
В полисе мы прописываем куда и каким образом могут обращаться сущности, к которым привязана эта полиси.

00:12:37.000 --> 00:12:46.000
Если говорить конкретнее, то мы можем пользователю User1 привязать некоторую полиси,

00:12:46.000 --> 00:12:58.000
а в полисе будет прописано, что мы можем считывать и записывать файлы в Bucket1.

00:12:58.000 --> 00:13:03.000
Далее есть так называемые Bucket Policies.

00:13:03.000 --> 00:13:14.000
Они привязываются уже к бакету и на уровне бакета мы можем расписать кому и в каком виде предоставляется доступ.

00:13:14.000 --> 00:13:19.000
А эта полиси уже привязывается к этому бакету.

00:13:19.000 --> 00:13:23.000
Следующее это Access Control Lists, так называемые ACLs.

00:13:23.000 --> 00:13:34.000
Это старый подход, который сейчас также работает для обратной совместимости, но оно было успешно заменено IAM Policies.

00:13:34.000 --> 00:13:46.000
Поэтому рекомендуется использовать IAM Policies и в случае если вам критичное использование ACL вы можете ее включить и уже использовать.

00:13:46.000 --> 00:13:51.000
Следующий метод это S3 Access Points.

00:13:51.000 --> 00:14:02.000
Идея в том, что вы можете для каждого вашего приложения предоставить специфичный набор прав и доступов на ваши объекты внутри S3 Bucket.

00:14:02.000 --> 00:14:05.000
Другой функционал это Presigned URLs.

00:14:05.000 --> 00:14:22.000
Идея в том, что вы можете на определенные действия, на определенные объекты сгенерировать некий URL, то есть адрес, который будет доступен ограниченное время.

00:14:22.000 --> 00:14:31.000
Представим, что вам нужно передать объект кому-либо и вы можете сгенерировать Presigned URL, который будет доступен в течение часа.

00:14:31.000 --> 00:14:36.000
И при открытии который он начинает скачивать ваш объект.

00:14:36.000 --> 00:14:39.000
Это можно сделать через Presigned URL.

00:14:39.000 --> 00:14:52.000
И отдельный сервис AWS Trusted Advisor, она бесплатная и позволяет нам автоматически проверять доступы на наших бакетах.

00:14:52.000 --> 00:14:57.000
То есть рекомендуется к использованию.

00:14:57.000 --> 00:15:04.000
Давайте рассмотрим три состояния наших бакетов и уровня доступа к этим бакетам.

00:15:04.000 --> 00:15:14.000
Самый первый дефолтовый это когда у нас бакет защищенный и приватный и доступ к этому бакету есть только у Owners, то есть создатели этого бакета.

00:15:14.000 --> 00:15:22.000
Он по умолчанию уже может выдавать явно доступ к другим пользователям внутри AWS аккаунта.

00:15:22.000 --> 00:15:26.000
Для всех других доступ к этому бакету запрещен.

00:15:26.000 --> 00:15:39.000
Далее второй случай это когда мы открываем паблик доступ к нашему бакету и любой пользователь в интернете может обращаться к нашему бакету и к объектам внутри нашего бакета.

00:15:39.000 --> 00:15:49.000
И третий вариант это более такой реалистичный вариант когда у нас может быть публичный доступ к нашему бакету.

00:15:49.000 --> 00:16:05.000
Он контролируется, доступ выдаётся только к определенным пользователям на основе некоторых условий либо к определенным приложениям, а для всех остальных он блокируется.

00:16:05.000 --> 00:16:11.000
Теперь остановимся на вопросах шифрования объектов внутри S3 бакетов.

00:16:11.000 --> 00:16:16.000
Для того чтобы файл наши данные зашифровать нам нужен Secret Key.

00:16:16.000 --> 00:16:26.000
Secret Key превращает файл в некоторую последовательность байтов, которые не читаемы.

00:16:26.000 --> 00:16:36.000
Только при наличии секретного ключа вы можете расшифровать зашифрованный файл и прочитать данные которые там есть.

00:16:36.000 --> 00:16:46.000
Существует два подхода это Server Side Encryption SSE либо Client Signed Encryption то есть CSE.

00:16:46.000 --> 00:16:55.000
Отличается тем что при Server Side Encryption шифрование происходит на стороне сервиса Amazon S3.

00:16:55.000 --> 00:16:58.000
То есть вы передаете файл в незашифрованном виде.

00:16:58.000 --> 00:17:04.000
Amazon S3 принимает этот файл, шифрует её, после чего записывает на жёсткие диски.

00:17:04.000 --> 00:17:09.000
Далее когда вы запрашиваете этот файл тоже самое только в обратном порядке.

00:17:09.000 --> 00:17:25.000
S3 считывает зашифрованный файл жёстких дисков, далее расшифровывает её ключом и передает вам уже файл в незашифрованном виде.

00:17:25.000 --> 00:17:41.000
Если мы говорим Client Signed Encryption это когда мы сами менеджим наши ключи шифрования и должны зашифровать наш файл перед тем как мы её отправим в сервис Amazon S3.

00:17:41.000 --> 00:17:49.000
Далее Amazon S3 шифрование на своей стороне не производит, а в исходном виде её записывает на жёсткий диск, так как оно уже зашифровано.

00:17:49.000 --> 00:18:01.000
Если же происходит сочетание, то Amazon S3 извлекает наш шифрованный файл с жёстких дисков и в таком же виде передает обратно.

00:18:01.000 --> 00:18:12.000
А мы уже у себя на стороне должны организовать процесс расшифровки ключом который хранится где-то, но не в AWS.

00:18:12.000 --> 00:18:25.000
Какой вариант нужно применить это зависит от бизнес задачи, самое главное что вы должны знать какие есть варианты шифрования объектов внутри S3 Bucket.

00:18:25.000 --> 00:18:33.000
Следующим довольно таки популярным use case сервиса Amazon S3 является хостинг статических веб сайтов.

00:18:33.000 --> 00:18:43.000
Это тот функционал который можно активировать в настройках Bucket. Во время активации вам необходимо указать файл который является индекс HTML,

00:18:43.000 --> 00:18:51.000
также указать файл который является error HTML, то есть будет направлять на указанную вами страницу в случае какой-то ошибки.

00:18:51.000 --> 00:18:59.000
После того как вы её активируете ваш веб сайт уже сразу становится доступным по определенному URL.

00:18:59.000 --> 00:19:12.000
Шаблоны URL вы видите на слайде. Вы также можете привязать к вашему веб сайту на S3 свой кастомный домен.

00:19:12.000 --> 00:19:19.000
Для этого вам необходимо интегрировать S3 с сервисом Root53.

00:19:19.000 --> 00:19:32.000
Здесь сразу можно увидеть очевидные плюсы хостинга веб сайта на S3. Это то что вам нет необходимости поднимать собственный веб сервер,

00:19:32.000 --> 00:19:45.000
настраивать ПО, более того отвечать за масштабируемость и высокую доступность вашего веб сервера. Все эти моменты они входят в цену сервиса S3 и это на стороне AWS.

00:19:45.000 --> 00:19:58.000
Таким образом в случае с веб сервером который хостите вы сами может быть ситуация такая что при увеличении спроса сервер не выдерживает нагрузки и перестает работать.

00:19:58.000 --> 00:20:11.000
Как только перестает работать ваш веб сервер ваш веб сайт становится недоступным. Подобные проблемы не может быть на стороне S3 так как она высокодоступная и высоко масштабируемая.

00:20:11.000 --> 00:20:22.000
Другой момент это то что в случае с веб сервером вы покупаете цельную единицу IT ресурса и оплачиваете ее вне зависимости от того какие нагрузки на нее идут.

00:20:22.000 --> 00:20:34.000
Если ваш сайт не такой популярный то вне зависимости от того были запросы на ваш сайт или нет вы оплачиваете фиксированную сумму за использование этого веб сервера.

00:20:34.000 --> 00:20:46.000
В случае же с S3 подобных платежей проводить не нужно вам достаточно оплачивать только за размер ваших медиа файлов которые вы хостите на S3.

00:20:46.000 --> 00:20:58.000
Это довольно такие небольшие суммы и в целом это решение помимо того что технически лучше она и по экономической части более выгодны.

00:20:58.000 --> 00:21:08.000
Другой немаловажный момент это то что вы услышав static websites возможно понимаете статические простейшие веб сайты.

00:21:08.000 --> 00:21:14.000
На самом деле динамические веб сайты также можно хостить на S3.

00:21:14.000 --> 00:21:21.000
Связано это с тем что JavaScript сам по себе он генерирует JS файлы которые сами по себе статичные.

00:21:21.000 --> 00:21:28.000
Их можно будет обслуживать в рамках static website хостинга на S3.

00:21:28.000 --> 00:21:32.000
Тем не менее тот код который исполняется в этих JS файлах он динамический.

00:21:32.000 --> 00:21:36.000
В зависимости от того какой запрос приходит он может менять свое поведение.

00:21:36.000 --> 00:21:45.000
Таким образом мы можем хостить на S3 динамические веб сайты.

00:21:45.000 --> 00:21:50.000
Следующим интересным функционалом сервиса Amazon S3 является versioning.

00:21:50.000 --> 00:22:03.000
Вершениг это когда вы активируете этот функционал и он сохраняет все версии которые когда-либо были когда-либо были загружены на этот S3 bucket под определенным ключом.

00:22:03.000 --> 00:22:10.000
Под ключом как вы помните понимается весь путь хранения вашего файла включая все ложные папки где он находится.

00:22:10.000 --> 00:22:24.000
Таким образом даже при удалении файлов из S3 bucket с включенным versioning вы всегда можете откатиться назад восстановить очень быстро этот файл.

00:22:24.000 --> 00:22:44.000
Более того вы если работаете с несколькими версиями одного и того же файла вы опять же легко с versioning можете вернуться на любую версию которую пожелаете исходя из вашей задачи.

00:22:44.000 --> 00:22:49.000
S3 bucket касательно versioning может находиться в трех состояниях.

00:22:49.000 --> 00:22:58.000
Первое состояние это дефолтовое когда вершин отключен. Если вам нужен вершин вам нужно ее отдельно активировать.

00:22:58.000 --> 00:23:06.000
Далее второе состояние это включенный вершин и третье состояние это приостановленный вершин.

00:23:06.000 --> 00:23:15.000
Почему существует третья версия это потому что вершин невозможно отключить после того как вы ее включили ее можно только приостановить.

00:23:15.000 --> 00:23:25.000
Таким образом все версии файлов которые сгенерируются во время включенного versioning они сохраняются.

00:23:25.000 --> 00:23:33.000
В тот момент как вы приостанавливаете вершин новые загруженные файлы они не генерируют новых версий.

00:23:33.000 --> 00:23:45.000
И для того чтобы продолжить сохранять новые версии вам необходимо обратно включить вершин.

00:23:45.000 --> 00:23:50.000
Следующий функционал который поддерживается Amazon S3 это course.

00:23:50.000 --> 00:24:05.000
Это cross-origin resource sharing. Идея в том что настроив course вы можете предоставить доступ другому сайту использовать части вашего веб сайта либо обращаться напрямую к медиа файлам вашего веб сайта.

00:24:05.000 --> 00:24:20.000
Если course не прописан то браузеры по умолчанию запрещают подобные действия а именно не могут находясь на одном веб сайте использовать части или обращаться к другому веб сайту.

00:24:20.000 --> 00:24:23.000
Это не разрешено в целях безопасности.

00:24:23.000 --> 00:24:37.000
Если у вас есть необходимость подобные действия проводить то вы выборочно для выделенных ресурсов можете прописать course и другие веб сайты смогут использовать ваши ресурсы.

00:24:37.000 --> 00:24:49.000
Следующим интересным use case сервиса Amazon S3 является хранение данных в рамках масштабных расчетов и аналитики.

00:24:49.000 --> 00:25:02.000
Объектное хранение в этом случае идеально подходит так как данные для подобного рода расчетов они записываются один раз и много раз считывается обычно эти данные не изменяются.

00:25:02.000 --> 00:25:13.000
Какие это данные? Это данные о транзакциях платежей это информация о посещении страниц пользователей различные логи и так далее.

00:25:13.000 --> 00:25:22.000
Таким образом записываются эти данные один раз в S3. S3 может также использоваться как источник царых данных.

00:25:22.000 --> 00:25:33.000
Далее вы видите на слайде пример когда запускаются spot инстанции либо какой-то EMR кластер который проводит эти расчеты.

00:25:33.000 --> 00:25:43.000
Далее после того как расчеты проведены уже измененные данные попадают в следующий S3 bucket в котором они хранятся уже в обработанном виде.

00:25:43.000 --> 00:26:00.000
Далее можно подключить различные системы аналитики есть сервис Amazon QuickSight который позволяет нам визуализировать наши данные.

00:26:00.000 --> 00:26:20.000
Следующим интересным использованием сервиса Amazon S3 является хранение различных бэкапов, архивов критических данных которые вы обязаны хранить там какой-то период времени согласно регуляторным требованиям либо своим внутренним корпоративным документам.

00:26:20.000 --> 00:26:33.000
Источником этих данных может выступать не только ваша инфраструктура на уровне AWS вы также с локального дата центра можете напрямую передавать и хранить эти данные в Amazon S3.

00:26:33.000 --> 00:27:01.000
Мы помним что хранение данных в сервисе Amazon S3 является достаточно надежным вариантом так как обеспечивает надежность 11 девяток если по тем или иным причинам вам необходима еще большая надежность то есть функционал cross region replication когда вы создаете второй бакет в другом регионе и в первом бакете настраиваете cross region replication.

00:27:01.000 --> 00:27:12.000
Таким образом когда данные попадают в первый бакет она автоматически replicates эти данные в бакет находящийся на другом регионе.

00:27:12.000 --> 00:27:25.000
Это еще больше увеличивает надежность хранения ваших данных но в этом случае вам необходимо нести дополнительные затраты на поддержание этой простейшей инфраструктуры для хранения ваших данных.

00:27:25.000 --> 00:27:53.000
Следует учитывать и предварительно рассчитать объемы хотя бы примерно в каком объеме вы будете хранить данные в каком какой период они будут там храниться и сделать расчет сколько денег вам предстоит оплатить в случае того или иного варианта хранения ваших критических данных.

00:27:53.000 --> 00:28:03.000
Давайте затронем пару моментов связанных с consistency model идея в том что как изменения связанные с сервисом amazon s3 применяются.

00:28:03.000 --> 00:28:21.000
Когда мы говорим про объекты то все объекты во всех регионах strong consistent это говорит о том что изменения над существующими объектами и новыми объектами они вступают в силу сразу после записи.

00:28:21.000 --> 00:28:50.000
Проще говоря после того как мы проведем успешную пут операцию то есть запишем объект в s3 bucket если сразу после этого мы запустим get или list операцию который считывает объект либо запрашивает список имеющихся объектов в бакете то этот недавно записанный объект сразу появится в этом списке либо вернется обновленное содержание этого объекта.

00:28:50.000 --> 00:29:00.000
Таким образом обеспечивается read after write consistency для операции get, list и put.

00:29:00.000 --> 00:29:14.000
Когда мы говорим про конфигурации бакетов то они eventually consistent что означает применение новых настроек через небольшой промежуток времени не сразу.

00:29:14.000 --> 00:29:28.000
Пример если мы поменяли если мы например удалили бакет и сразу после этого запросили список бакетов то удаленный бакет может отобразиться в этом списке.

00:29:28.000 --> 00:29:48.000
Если через несколько секунд мы еще раз запросим список существующих бакетов то в этом случае удаленный бакет уже не будет присутствовать в этом списке то есть вот такие нюансы по работе с бакетами и объектами в сервисе amazon s3.

00:29:48.000 --> 00:30:06.000
Итак мы добрались до конца второй секции и давайте остановимся на самых основных моментах связанных с сервисом с s3. Первое самое важное это то что названия бакетов они должны быть глобальными среди всех регионов AWS.

00:30:06.000 --> 00:30:22.000
В то время как для хранения данных мы выбираем определенный регион и все данные хранятся в этом регионе. Далее это то что все бакеты по умолчанию приватные для того чтобы предоставить публичный доступ вам нужно совершить дополнительные действия.

00:30:22.000 --> 00:30:40.000
Для того чтобы предоставить доступ к вашему бакету будь то публичный будь то для сущностей внутри AWS аккаунта вы можете воспользоваться различными вариантами это может быть IAM policy, Bucket policy, Access control листы и так далее.

00:30:40.000 --> 00:30:55.000
Для всех объектов новых и существующих работает модель Strongly Consistency что означает то что изменение объектов вступает в силу моментально.

00:30:55.000 --> 00:31:10.000
Максимальный размер одного файла в сервисе s3 это 5 терабайтов что более чем достаточно практически для всех задач хранения и существующих файлов.

00:31:10.000 --> 00:31:25.000
Также мы рассмотрели 4 популярных use case сервиса Amazon s3 оно не ограничивается этими use case есть очень много различных менее популярных use case.

00:31:25.000 --> 00:31:37.000
Самое главное вы получили общее представление каким образом в каких местах архитектуры можно успешно применить этот сервис.

00:31:37.000 --> 00:31:43.000
На этом мы подошли к концу первой части посвященной теме хранения в облаке AWS.

00:31:43.000 --> 00:31:49.000
Я очень надеюсь что вы получили более полное представление о сервисе s3.

00:31:49.000 --> 00:31:57.000
Также в дальнейших наших активностях у нас будет демо и лабораторная работа посвященная сервису Amazon s3.

00:31:57.000 --> 00:32:01.000
На этом мы заканчиваем нашу сегодняшнюю сессию.

00:32:01.000 --> 00:32:07.000
Спасибо за внимание увидимся с вами на следующих наших активностях.
