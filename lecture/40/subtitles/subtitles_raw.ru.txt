 Добрый день, уважаемые студенты! Я рад вас всех видеть на очередной лекции. Тема сегодняшней лекции – это хранение. Эта тема достаточно объемная, поэтому мы будем проходить ее в течение двух недель. Сегодня будет первая часть. Итак, давайте начнем. В сегодняшней лекции у нас будет две секции. В первой секции мы разберем архитектуру, над которой будем работать в течение всего семестра. И по мере прохождения новых сервисов AWS, будем дополнять эту архитектуру. Во второй секции мы разберем use-кейсы использования сервиса Amazon S3. Также в отдельной видео активности на этой неделе для вас будет доступна демо. В этом демо мы разберем фенкционал вершининга для сервиса Amazon S3. Далее у нас будет лабораторная работа. Как мы с вами помним, для лабораторной работы будут две отдельные видео активности. Это обзор лабораторной работы, а также разбор лабораторной работы. Тема лабораторной работы – это создание статического веб-сайта и его хостинг в сервисы Amazon S3. Мы начинаем с вами первую секцию и рассматриваем простейшую архитектуру в облаке AWS. Эту архитектуру мы будем разрабатывать в течение всего семестра. И в результате вы видите всю эту архитектуру в виде диаграммы. В рамках текущей недели мы активируем компонент внизу слева. Это static website on S3. У сервиса Amazon S3 есть функционал хостинга статических веб-сайтов. Таким образом, мы в рамках нашей бизнес задачи, бизнес-кейса активируем этот функционал. И для нашего кафе внутри use-кейса создадим статический веб-сайт. Он будет хоститься в сервисе Amazon S3. Чтобы задача по построению архитектуры в облаке AWS не выглядела абстрактной задачей, мы будем рассматривать ее в рамках бизнес-кейса. В нашем случае это будет бизнес небольшого кафе с пекарней. Владельцами этой пекарни являются Фрэнк и Марта. Они муж с женой, а также являются пенсионерами. У Фрэнка с Мартой есть дочка София. Она помогает родителям вести этот небольшой бизнес. А также параллельно обучается IT-технологиям в университете. В том числе уличные технологии. В этом кафе также работает на полставки Нихилл, который также является студентом университета и изучает IT-дисциплины. Кафе недавно открылось. У нее еще нет какой-то маркетинговой стратегии развития. Поэтому об этом кафе знают только местные жители, а также знакомые владельцев этого небольшого бизнеса. София предложила своим родителям попытаться увеличить количество посетителей через создание веб-сайта. На этом веб-сайте они могли бы опубликовать меню, время работы, месторасположение, адрес этого кафе и другие детали. Родителям Фрэнку и Марте эта идея понравилась. Поэтому в рамках этой недели мы будем изучать возможности облачных технологий сервисов AWS, которые помогут нам решить эту бизнес-задачу. На этом мы завершаем первую секцию и двигаемся к следующей части. Мы с вами добрались до второй секции нашей сегодняшней лекции и разберем use-кейсы сервиса Amazon S3. Amazon S3 это Simple Storage Service, сервис который предоставляет нам объектное хранение. В этом сервисе мы можем хранить достаточно большой объем информации, данных практически в неограниченном объеме. Данные хранятся объектно внутри так называемых бакетов. Так как мы говорим объектное хранилище, то подразумевается, что внутри S3 изменять файлы мы не можем. Если нам необходимо изменить файл, мы должны либо его скачать, либо локальную копию изменить и загрузить ее обратно. Таким образом в S3 появится следующая новая версия. Когда мы говорим бакеты, это некие корневые папки, в которых хранятся наши данные. Название бакета оно должно быть уникально глобально, то есть вы не можете создать два бакета с одинаковыми названиями в различных регионах. Он должен быть уникальный глобально, но тем не менее ваши данные внутри S3 бакета, они хранятся в определенном регионе. Поэтому при создании бакета вы указываете глобальное имя, но рядом также указываете регион, в котором фактически ваши данные будут храниться. Если мы говорим про размер файлов внутри S3 бакета, то для одного файла он может быть от 0 байтов до 5 терабайтов. То есть практически любой вид объекта он спокойно помещается в S3. Каждый объект внутри S3 бакета содержит пять характеристик. Первое это key, либо по другому говоря, путь до этого файла, подразумевается весь полный путь. Сам S3 не различает файл храниться внутри папки, либо хранится в корне S3 бакета. Возможность создания папок и организации всех наших файлов внутри бакета в различных вложенных папках это сделано специально для удобства использования. Сам же S3 хранит у себя внутри по другому и значением для каждого файла является весь полный путь до этого файла. Следующая характеристика это versionid, то есть во время перезагрузки вашего файла он обретает новый versionid. Так мы можем различать различные версии одного и того же файла. Следующий компонент это значение, в нашем случае это последовательность байтов, то есть само значение, сами наши данные. Четвертое это metadata, так называемые теги. Теги это пары ключ-значения, они могут быть системными, также они могут быть user defined, то есть определены пользователем. Самое последнее это subresources, это некоторая дополнительная информация специфичная для конкретного объекта для работы сервиса Amazon S3. Давайте подробнее остановимся на основных преимуществах сервиса Amazon S3. Первое это надежность. Надежность сервиса S3 измеряется 11 девятками или 99.99%. Это достаточно хорошие показатели, давайте приведем пример для наглядности. Если мы в одном бакете будем хранить 10 тысяч объектов, то в течение целого года мы максимум потеряем один объект. Следующее преимущество это availability, она измеряется четырьмя девятками, то есть 99.99% того, что мы доберемся до наших файлов и сможем их загрузить. Availability чуть ниже чем durability, это нормально ввиду того, что могут возникнуть некоторые проблемы с сетью, но самое главное, что данные надежно хранятся. В случае, если возникли проблемы с загрузкой объекта, мы можем всегда сделать вторую попытку и вторая попытка чаще всего успешно срабатывает и файл в итоге загружается. Другое преимущество это то, что мы оплачиваем сервис S3 по модели pay as you go, то есть если мы храним лишь 1 гигабайт данных внутри этого сервиса, то ровно столько мы будем оплачивать ежемесячно. Если на второй месяц мы очистили наши бакеты и на текущий момент у нас 0 гигабайтов данных хранятся в S3 бакете, то мы ничего не будем оплачивать через месяц. Таким образом это удобно и нас никто не вынуждает покупать пакет 100 гигабайт 500 гигабайт или 1 терабайт места и оплачивать это место вне зависимости от того мы используем ее или нет. Таким образом хранение в S3 оно может быть экономически выгодно. Мы с вами добрались до основной части текущей секции и рассмотрим основные юскейсы сервиса Amazon S3. Самые первые и самые популярные это использование S3 в качестве хранилища медиа данных. Это могут быть различные видео материалы, аудио, картинки, может текстовая информация и так далее. Вы можете используя S3 давать прямую ссылку для загрузки вашим пользователям. В этом случае домен будет стандартного вида это bucketname.s3.amazon.aws.com. Дальше указывается путь до вашего объекта. Вы также можете распространять ваши медиа данные через CDN. В нашем случае это Amazon CloudFront. Давайте подробнее остановимся на теме безопасности S3 бакетов и объектов внутри этих бакетов. Все бакеты они изначально приватные и защищенные. Когда мы выдаем доступ к объектам или бакетам необходимо следовать принципу list privilege. То есть мы выдаем только доступ только тем сущностям и только в том объеме, который нужно для выполнения задачи. Если мы говорим про предоставление доступа у нас есть широкий выбор функционала. Давайте остановимся на каждом из них. Самое первое это блок Public Access Feature. Идея в том, что если мы хотим гарантированно закрыть любой публичный доступ на наши S3 бакеты, то необходимо эти галочки включить. Это некоторый переключатель и нужно выставлять флажочки на уровне настройка бакета. В случае если вам все таки нужно предоставить некоторый публичный доступ пусть и ограниченный. Первым делом вам необходимо эти флажочки снять. Следующее это IAM Policies. Идея в том, что у нас есть некоторые сущности это роли пользователей и группы, которым мы привязываем наши полиси. В полисе мы прописываем куда и каким образом могут обращаться сущности, к которым привязана эта полиси. Если говорить конкретнее, то мы можем пользователю User1 привязать некоторую полиси, а в полисе будет прописано, что мы можем считывать и записывать файлы в Bucket1. Далее есть так называемые Bucket Policies. Они привязываются уже к бакету и на уровне бакета мы можем расписать кому и в каком виде предоставляется доступ. А эта полиси уже привязывается к этому бакету. Следующее это Access Control Lists, так называемые ACLs. Это старый подход, который сейчас также работает для обратной совместимости, но оно было успешно заменено IAM Policies. Поэтому рекомендуется использовать IAM Policies и в случае если вам критичное использование ACL вы можете ее включить и уже использовать. Следующий метод это S3 Access Points. Идея в том, что вы можете для каждого вашего приложения предоставить специфичный набор прав и доступов на ваши объекты внутри S3 Bucket. Другой функционал это Presigned URLs. Идея в том, что вы можете на определенные действия, на определенные объекты сгенерировать некий URL, то есть адрес, который будет доступен ограниченное время. Представим, что вам нужно передать объект кому-либо и вы можете сгенерировать Presigned URL, который будет доступен в течение часа. И при открытии который он начинает скачивать ваш объект. Это можно сделать через Presigned URL. И отдельный сервис AWS Trusted Advisor, она бесплатная и позволяет нам автоматически проверять доступы на наших бакетах. То есть рекомендуется к использованию. Давайте рассмотрим три состояния наших бакетов и уровня доступа к этим бакетам. Самый первый дефолтовый это когда у нас бакет защищенный и приватный и доступ к этому бакету есть только у Owners, то есть создатели этого бакета. Он по умолчанию уже может выдавать явно доступ к другим пользователям внутри AWS аккаунта. Для всех других доступ к этому бакету запрещен. Далее второй случай это когда мы открываем паблик доступ к нашему бакету и любой пользователь в интернете может обращаться к нашему бакету и к объектам внутри нашего бакета. И третий вариант это более такой реалистичный вариант когда у нас может быть публичный доступ к нашему бакету. Он контролируется, доступ выдаётся только к определенным пользователям на основе некоторых условий либо к определенным приложениям, а для всех остальных он блокируется. Теперь остановимся на вопросах шифрования объектов внутри S3 бакетов. Для того чтобы файл наши данные зашифровать нам нужен Secret Key. Secret Key превращает файл в некоторую последовательность байтов, которые не читаемы. Только при наличии секретного ключа вы можете расшифровать зашифрованный файл и прочитать данные которые там есть. Существует два подхода это Server Side Encryption SSE либо Client Signed Encryption то есть CSE. Отличается тем что при Server Side Encryption шифрование происходит на стороне сервиса Amazon S3. То есть вы передаете файл в незашифрованном виде. Amazon S3 принимает этот файл, шифрует её, после чего записывает на жёсткие диски. Далее когда вы запрашиваете этот файл тоже самое только в обратном порядке. S3 считывает зашифрованный файл жёстких дисков, далее расшифровывает её ключом и передает вам уже файл в незашифрованном виде. Если мы говорим Client Signed Encryption это когда мы сами менеджим наши ключи шифрования и должны зашифровать наш файл перед тем как мы её отправим в сервис Amazon S3. Далее Amazon S3 шифрование на своей стороне не производит, а в исходном виде её записывает на жёсткий диск, так как оно уже зашифровано. Если же происходит сочетание, то Amazon S3 извлекает наш шифрованный файл с жёстких дисков и в таком же виде передает обратно. А мы уже у себя на стороне должны организовать процесс расшифровки ключом который хранится где-то, но не в AWS. Какой вариант нужно применить это зависит от бизнес задачи, самое главное что вы должны знать какие есть варианты шифрования объектов внутри S3 Bucket. Следующим довольно таки популярным use case сервиса Amazon S3 является хостинг статических веб сайтов. Это тот функционал который можно активировать в настройках Bucket. Во время активации вам необходимо указать файл который является индекс HTML, также указать файл который является error HTML, то есть будет направлять на указанную вами страницу в случае какой-то ошибки. После того как вы её активируете ваш веб сайт уже сразу становится доступным по определенному URL. Шаблоны URL вы видите на слайде. Вы также можете привязать к вашему веб сайту на S3 свой кастомный домен. Для этого вам необходимо интегрировать S3 с сервисом Root53. Здесь сразу можно увидеть очевидные плюсы хостинга веб сайта на S3. Это то что вам нет необходимости поднимать собственный веб сервер, настраивать ПО, более того отвечать за масштабируемость и высокую доступность вашего веб сервера. Все эти моменты они входят в цену сервиса S3 и это на стороне AWS. Таким образом в случае с веб сервером который хостите вы сами может быть ситуация такая что при увеличении спроса сервер не выдерживает нагрузки и перестает работать. Как только перестает работать ваш веб сервер ваш веб сайт становится недоступным. Подобные проблемы не может быть на стороне S3 так как она высокодоступная и высоко масштабируемая. Другой момент это то что в случае с веб сервером вы покупаете цельную единицу IT ресурса и оплачиваете ее вне зависимости от того какие нагрузки на нее идут. Если ваш сайт не такой популярный то вне зависимости от того были запросы на ваш сайт или нет вы оплачиваете фиксированную сумму за использование этого веб сервера. В случае же с S3 подобных платежей проводить не нужно вам достаточно оплачивать только за размер ваших медиа файлов которые вы хостите на S3. Это довольно такие небольшие суммы и в целом это решение помимо того что технически лучше она и по экономической части более выгодны. Другой немаловажный момент это то что вы услышав static websites возможно понимаете статические простейшие веб сайты. На самом деле динамические веб сайты также можно хостить на S3. Связано это с тем что JavaScript сам по себе он генерирует JS файлы которые сами по себе статичные. Их можно будет обслуживать в рамках static website хостинга на S3. Тем не менее тот код который исполняется в этих JS файлах он динамический. В зависимости от того какой запрос приходит он может менять свое поведение. Таким образом мы можем хостить на S3 динамические веб сайты. Следующим интересным функционалом сервиса Amazon S3 является versioning. Вершениг это когда вы активируете этот функционал и он сохраняет все версии которые когда-либо были когда-либо были загружены на этот S3 bucket под определенным ключом. Под ключом как вы помните понимается весь путь хранения вашего файла включая все ложные папки где он находится. Таким образом даже при удалении файлов из S3 bucket с включенным versioning вы всегда можете откатиться назад восстановить очень быстро этот файл. Более того вы если работаете с несколькими версиями одного и того же файла вы опять же легко с versioning можете вернуться на любую версию которую пожелаете исходя из вашей задачи. S3 bucket касательно versioning может находиться в трех состояниях. Первое состояние это дефолтовое когда вершин отключен. Если вам нужен вершин вам нужно ее отдельно активировать. Далее второе состояние это включенный вершин и третье состояние это приостановленный вершин. Почему существует третья версия это потому что вершин невозможно отключить после того как вы ее включили ее можно только приостановить. Таким образом все версии файлов которые сгенерируются во время включенного versioning они сохраняются. В тот момент как вы приостанавливаете вершин новые загруженные файлы они не генерируют новых версий. И для того чтобы продолжить сохранять новые версии вам необходимо обратно включить вершин. Следующий функционал который поддерживается Amazon S3 это course. Это cross-origin resource sharing. Идея в том что настроив course вы можете предоставить доступ другому сайту использовать части вашего веб сайта либо обращаться напрямую к медиа файлам вашего веб сайта. Если course не прописан то браузеры по умолчанию запрещают подобные действия а именно не могут находясь на одном веб сайте использовать части или обращаться к другому веб сайту. Это не разрешено в целях безопасности. Если у вас есть необходимость подобные действия проводить то вы выборочно для выделенных ресурсов можете прописать course и другие веб сайты смогут использовать ваши ресурсы. Следующим интересным use case сервиса Amazon S3 является хранение данных в рамках масштабных расчетов и аналитики. Объектное хранение в этом случае идеально подходит так как данные для подобного рода расчетов они записываются один раз и много раз считывается обычно эти данные не изменяются. Какие это данные? Это данные о транзакциях платежей это информация о посещении страниц пользователей различные логи и так далее. Таким образом записываются эти данные один раз в S3. S3 может также использоваться как источник царых данных. Далее вы видите на слайде пример когда запускаются spot инстанции либо какой-то EMR кластер который проводит эти расчеты. Далее после того как расчеты проведены уже измененные данные попадают в следующий S3 bucket в котором они хранятся уже в обработанном виде. Далее можно подключить различные системы аналитики есть сервис Amazon QuickSight который позволяет нам визуализировать наши данные. Следующим интересным использованием сервиса Amazon S3 является хранение различных бэкапов, архивов критических данных которые вы обязаны хранить там какой-то период времени согласно регуляторным требованиям либо своим внутренним корпоративным документам. Источником этих данных может выступать не только ваша инфраструктура на уровне AWS вы также с локального дата центра можете напрямую передавать и хранить эти данные в Amazon S3. Мы помним что хранение данных в сервисе Amazon S3 является достаточно надежным вариантом так как обеспечивает надежность 11 девяток если по тем или иным причинам вам необходима еще большая надежность то есть функционал cross region replication когда вы создаете второй бакет в другом регионе и в первом бакете настраиваете cross region replication. Таким образом когда данные попадают в первый бакет она автоматически replicates эти данные в бакет находящийся на другом регионе. Это еще больше увеличивает надежность хранения ваших данных но в этом случае вам необходимо нести дополнительные затраты на поддержание этой простейшей инфраструктуры для хранения ваших данных. Следует учитывать и предварительно рассчитать объемы хотя бы примерно в каком объеме вы будете хранить данные в каком какой период они будут там храниться и сделать расчет сколько денег вам предстоит оплатить в случае того или иного варианта хранения ваших критических данных. Давайте затронем пару моментов связанных с consistency model идея в том что как изменения связанные с сервисом amazon s3 применяются. Когда мы говорим про объекты то все объекты во всех регионах strong consistent это говорит о том что изменения над существующими объектами и новыми объектами они вступают в силу сразу после записи. Проще говоря после того как мы проведем успешную пут операцию то есть запишем объект в s3 bucket если сразу после этого мы запустим get или list операцию который считывает объект либо запрашивает список имеющихся объектов в бакете то этот недавно записанный объект сразу появится в этом списке либо вернется обновленное содержание этого объекта. Таким образом обеспечивается read after write consistency для операции get, list и put. Когда мы говорим про конфигурации бакетов то они eventually consistent что означает применение новых настроек через небольшой промежуток времени не сразу. Пример если мы поменяли если мы например удалили бакет и сразу после этого запросили список бакетов то удаленный бакет может отобразиться в этом списке. Если через несколько секунд мы еще раз запросим список существующих бакетов то в этом случае удаленный бакет уже не будет присутствовать в этом списке то есть вот такие нюансы по работе с бакетами и объектами в сервисе amazon s3. Итак мы добрались до конца второй секции и давайте остановимся на самых основных моментах связанных с сервисом с s3. Первое самое важное это то что названия бакетов они должны быть глобальными среди всех регионов AWS. В то время как для хранения данных мы выбираем определенный регион и все данные хранятся в этом регионе. Далее это то что все бакеты по умолчанию приватные для того чтобы предоставить публичный доступ вам нужно совершить дополнительные действия. Для того чтобы предоставить доступ к вашему бакету будь то публичный будь то для сущностей внутри AWS аккаунта вы можете воспользоваться различными вариантами это может быть IAM policy, Bucket policy, Access control листы и так далее. Для всех объектов новых и существующих работает модель Strongly Consistency что означает то что изменение объектов вступает в силу моментально. Максимальный размер одного файла в сервисе s3 это 5 терабайтов что более чем достаточно практически для всех задач хранения и существующих файлов. Также мы рассмотрели 4 популярных use case сервиса Amazon s3 оно не ограничивается этими use case есть очень много различных менее популярных use case. Самое главное вы получили общее представление каким образом в каких местах архитектуры можно успешно применить этот сервис. На этом мы подошли к концу первой части посвященной теме хранения в облаке AWS. Я очень надеюсь что вы получили более полное представление о сервисе s3. Также в дальнейших наших активностях у нас будет демо и лабораторная работа посвященная сервису Amazon s3. На этом мы заканчиваем нашу сегодняшнюю сессию. Спасибо за внимание увидимся с вами на следующих наших активностях.
