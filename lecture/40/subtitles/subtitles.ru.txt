Добрый день, уважаемые студенты! 
Я рад вас всех видеть на очередной лекции.
Тема сегодняшней лекции – это хранение.
Эта тема достаточно объемная, поэтому мы будем проходить ее в течение двух недель.
Сегодня будет первая часть.
Итак, давайте начнем.
В сегодняшней лекции у нас будут две секции.
В первой секции мы разберем архитектуру, над которой будем работать в течение всего семестра.
И по мере прохождения новых сервисов AWS, будем дополнять эту архитектуру.
Во второй секции мы разберем use case использования сервиса Amazon S3.
Также в отдельной видеоактивности на этой неделе для вас будет доступна Демо-активность.
В этом Демо мы разберем функционал Versioning для сервиса Amazon S3.
Далее у нас будет лабораторная работа.
Как мы с вами помним, для лабораторной работы будут две отдельные видео-активности.
Это обзор лабораторной работы, а также разбор лабораторной работы.
Тема лабораторной работы – это создание статического веб-сайта и его хостинг в сервисе Amazon S3.
Мы начинаем первую секцию и рассматриваем простейшую архитектуру в облаке AWS.
Эту архитектуру мы будем разрабатывать в течение всего семестра.
И в результате вы увидите всю эту архитектуру в виде диаграммы.
В рамках текущей недели мы активируем компонент, который находится внизу слева - это static website on S3.
У сервиса Amazon S3 есть функционал хостинга статических веб-сайтов.
Таким образом, мы в рамках нашей бизнес задачи, бизнес-кейса активируем этот функционал.
И для нашего кафе внутри use кейса создадим статический веб-сайт.
Он будет хоститься в сервисе Amazon S3.
Чтобы задача по построению архитектуры в облаке AWS не выглядела абстрактной задачей, мы будем рассматривать ее в рамках бизнес-кейса.
В нашем случае это будет бизнес небольшого кафе с пекарней.
Владельцами этой пекарни являются Фрэнк и Марта.
Они муж с женой, а также являются пенсионерами.
У Фрэнка с Мартой есть дочка София.
Она помогает родителям вести этот небольшой бизнес.
А также параллельно обучается IT технологиям в университете, в том числе облачные технологии.
В этом кафе также работает на полставки Нихил, который также является студентом университета и изучает IT дисциплины.
Кафе недавно открылось.
У него еще нет какой-то маркетинговой стратегии развития.
Поэтому об этом кафе знают только местные жители, а также знакомые владельцев этого небольшого бизнеса.
София предложила своим родителям попытаться увеличить количество посетителей через создание веб-сайта.
На этом веб-сайте они могли бы опубликовать меню, время работы, местоположение, адрес этого кафе и другие детали.
Родителям, Фрэнку и Марте, эта идея понравилась.
Поэтому в рамках этой недели мы будем изучать возможности облачных технологий, сервисов AWS, которые помогут нам решить эту бизнес-задачу.
На этом мы завершаем первую секцию и двигаемся к следующей части.
Мы с вами добрались до второй секции нашей сегодняшней лекции и разберем use кейсы сервиса Amazon S3.
Amazon S3 - это Simple Storage Service, сервис который предоставляет нам объектное хранение.
В этом сервисе мы можем хранить достаточно большой объем информации, данных практически в неограниченном объеме.
Данные хранятся объектно внутри так называемых бакетов (buckets).
Так как мы говорим объектное хранилище, то подразумевается, что внутри S3 изменять файлы мы не можем.
Если нам необходимо изменить файл, мы должны либо его скачать, либо изменить локальную копию и загрузить ее обратно.
Таким образом в S3 появится следующая новая версия.
Когда мы говорим бакеты, это некие корневые папки, в которых хранятся наши данные.
Название бакета должно быть уникально глобально, то есть вы не можете создать два бакета с одинаковыми названиями в различных регионах.
Оно должно быть уникальной глобально, но тем не менее ваши данные внутри S3 бакета, они хранятся в определенном регионе.
Поэтому при создании бакета, вы указываете глобальное имя, но рядом также указываете регион, в котором фактически ваши данные будут храниться.
Если мы говорим про размер файлов внутри S3 бакета, то для одного файла он может быть от 0 байтов до 5 терабайтов.
То есть практически любой вид объекта спокойно помещается в S3.
Каждый объект внутри S3 бакета содержит пять характеристик.
Первое - это Key, либо по другому говоря, путь до этого файла, подразумевается весь полный путь.
Сам S3 не различает, что файл хранится внутри папки, либо хранится в корне S3 бакета.
Возможность создания папок и организации всех наших файлов внутри бакета в различных вложенных папках сделано специально для удобства использования.
Сам же S3 хранит у себя внутри по-другому и значением для каждого файла является весь полный путь до этого файла.
Следующая характеристика - это Version ID, то есть во время перезагрузки вашего файла он обретает новый Version ID.
Так мы можем различать различные версии одного и того же файла.
Следующий компонент - это значение (Value), в нашем случае это последовательность байтов, то есть само значение, сами наши данные.
Четвертое - это Metadata, так называемые теги.
Теги - это пары ключ - значение (key - value), они могут быть системными, также они могут быть user defined, то есть определены пользователем.
Самое последнее - это Subresources, это некоторая дополнительная информация специфичная для конкретного объекта для работы сервиса Amazon S3.
Давайте подробнее остановимся на основных преимуществах сервиса Amazon S3.
Первое - это надежность (durability).
Надежность сервиса S3 измеряется 11 девятками или 99.999999999%.
Это достаточно хорошие показатели, давайте приведем пример для наглядности.
Если мы в одном бакете будем хранить 10 тысяч объектов, то в течение целого года мы максимум потеряем один объект.
Следующее преимущество - это availability, она измеряется четырьмя девятками, то есть 99.99% того, что мы доберемся до наших файлов и сможем их загрузить.
Availability чуть ниже чем durability, это нормально ввиду того, что могут возникнуть некоторые проблемы с сетью, но самое главное, что данные надежно хранятся.
В случае, если возникли проблемы с загрузкой объекта, мы можем всегда сделать вторую попытку и вторая попытка чаще всего успешно срабатывает и файл в итоге загружается.
Другое преимущество - это то, что мы оплачиваем сервис S3 по модели pay as you go, то есть если мы храним лишь 1 гигабайт данных внутри этого сервиса, то ровно столько мы будем оплачивать ежемесячно.
Если на второй месяц мы очистили наши бакеты и на текущий момент у нас 0 гигабайтов данных хранятся в S3 бакете, то мы ничего не будем оплачивать через месяц.
Таким образом это удобно и нас никто не вынуждает покупать пакет, к примеру 100 гигабайт, 500 гигабайт или 1 терабайт места и оплачивать это место вне зависимости от того мы используем ее или нет.
Таким образом хранение в S3 оно может быть экономически выгодно.
Мы с вами добрались до основной части текущей секции и рассмотрим основные use кейсы сервиса Amazon S3.
Самые первые и самые популярные - это использование S3 в качестве хранилища медиа данных.
Это могут быть различные видео материалы, аудио, картинки, может текстовая информация и так далее.
Используя S3, вы можете  давать прямую ссылку для загрузки вашим пользователям.
В этом случае домен будет стандартного вида - это https://<bucket-name>.s3.amazonaws.com.
Дальше указывается путь до вашего объекта.
Вы также можете распространять ваши медиа данные через CDN.
В нашем случае, это Amazon CloudFront.
Давайте подробнее остановимся на теме безопасности S3 бакетов и объектов внутри этих бакетов.
Все бакеты изначально приватные и защищенные.
Когда мы выдаем доступ к объектам или бакетам необходимо следовать принципу least privilege.
То есть мы выдаем только доступ только тем сущностям и только в том объеме, который нужно для выполнения задачи.
Если мы говорим про предоставление доступа, у нас есть широкий выбор функционала.
Давайте остановимся на каждом из них.
Самое первое - это Block Public Access Feature.
Идея в том, что если мы хотим гарантированно закрыть любой публичный доступ на наши S3 бакеты, то необходимо эти галочки включить.
Это некоторый переключатель и нужно выставлять флажочки на уровне настройки бакета.
В случае если вам нужно предоставить некоторый публичный доступ пусть и ограниченный, первым делом вам необходимо эти флажочки снять.
Следующее - это IAM Policies.
Идея в том, что у нас есть некоторые сущности - роли, пользователи и группы, которым мы привязываем наши policy.
В policy мы прописываем куда и каким образом могут обращаться сущности, к которым привязана эта policy.
Если говорить конкретнее, то мы можем пользователю User1 привязать некоторую policy, а в policy будет прописано, что мы можем считывать и записывать файлы в Bucket1.
Далее, есть так называемые Bucket Policies.
Они привязываются уже к бакету и на уровне бакета мы можем расписать кому и в каком виде предоставляется доступ.
А эта policy уже привязывается к этому бакету.
Следующее - это Access Control Lists, так называемые ACLs.
Это старый подход, который сейчас также работает для обратной совместимости, но оно было успешно заменено IAM Policies.
Поэтому рекомендуется использовать IAM Policies и в случае, если вам критично использование ACLs, вы можете ее включить и уже использовать.
Следующий метод - это S3 Access Points.
Идея в том, что вы можете для каждого вашего приложения предоставить специфичный набор прав и доступов на ваши объекты внутри S3 Bucket.
Другой функционал - это Presigned URLs.
Идея в том, что вы можете на определенные действия, на определенные объекты сгенерировать некий URL, то есть адрес, который будет доступен ограниченное время.
Представим, что вам нужно передать объект кому-либо и вы можете сгенерировать Presigned URL, который будет доступен в течение часа.
При открытии этого URL, начинается загрузка вашего объекта.
Это можно сделать через Presigned URL.
И отдельный сервис - AWS Trusted Advisor - это бесплатный сервис, который позволяет нам автоматически проверять доступы на наших бакетах.
То есть рекомендуется к использованию.
Давайте рассмотрим три состояния наших бакетов и уровни доступа к этим бакетам.
Самый первый Default - это когда у нас бакет защищенный и приватный и доступ к этому бакету есть только у Owner, то есть создателя этого бакета.
Он по умолчанию уже может выдавать явно доступ к другим пользователям внутри AWS аккаунта.
Для всех других доступ к этому бакету запрещен.
Далее, второй случай - это когда мы открываем Public access к нашему бакету и любой пользователь в интернете может обращаться к нашему бакету и к объектам внутри нашего бакета.
И третий вариант - это более реалистичный вариант, когда у нас может быть публичный доступ к нашему бакету, но он контролируется, доступ выдаётся только к определенным пользователям на основе некоторых условий либо к определенным приложениям, а для всех остальных он блокируется.
Теперь остановимся на вопросах шифрования объектов внутри S3 бакетов.
Для того чтобы файл наши данные зашифровать нам нужен Secret Key.
Secret Key превращает файл в некоторую последовательность байтов, которые не читаемы.
Только при наличии секретного ключа вы можете расшифровать зашифрованный файл и прочитать данные, которые там есть.
Существует два подхода - это Server-side encryption (SSE), либо Client-side encryption (CSE).
Отличается тем, что при Server-side encryption шифрование происходит на стороне сервиса Amazon S3.
То есть вы передаете файл в незашифрованном виде.
Amazon S3 принимает этот файл, шифрует файл, после чего записывает на жёсткие диски.
Далее, когда вы запрашиваете этот файл, тоже самое только в обратном порядке, Amazon S3 считывает зашифрованный файл с жёстких дисков, далее расшифровывает её ключом и передает вам уже файл в незашифрованном виде.
Если мы говорим Client Signed Encryption - это когда мы сами руководствуемся нашими ключами шифрования и должны зашифровать наш файл перед тем как мы её отправим в сервис Amazon S3.
Далее, Amazon S3 шифрование на своей стороне не производит, а в исходном виде её записывает на жёсткий диск, так как оно уже зашифровано.
Если же происходит считывание, то Amazon S3 извлекает наш шифрованный файл с жёстких дисков и в таком же виде передает обратно.
А мы уже у себя на стороне должны организовать процесс расшифровки ключом, который хранится где-то, но не в AWS.
Вариант, который нужно применить, зависит от бизнес задачи.
Самое главное, что вы должны знать какие есть варианты шифрования объектов внутри S3 Bucket.
Следующим довольно популярным use case сервиса Amazon S3 является хостинг статических веб-сайтов.
Это тот функционал, который можно активировать в настройках Bucket.
Во время активации вам необходимо указать файл, который является index.html, также указать файл, который является error.html, то есть будет направлять на указанную вами страницу в случае какой-то ошибки.
После того как вы её активируете ваш веб-сайт уже сразу становится доступным по определенному URL.
Шаблоны URL вы видите на слайде.
Вы также можете привязать к вашему веб-сайту на S3 свой кастомный домен.
Для этого вам необходимо интегрировать Amazon S3 с сервисом Amazon Route 53.
Здесь сразу можно увидеть очевидные плюсы хостинга веб-сайта на Amazon S3.
Это то, что вам нет необходимости поднимать собственный веб-сервер, настраивать ПО, более того отвечать за масштабируемость и высокую доступность вашего веб-сервера.
Все эти моменты входят в цену сервиса Amazon S3 и это на стороне AWS.
Таким образом, в случае с веб-сервером, который хостите вы сами, может быть такая ситуация, что при увеличении спроса сервер не выдерживает нагрузки и перестает работать.
Как только перестает работать ваш веб-сервер, ваш веб-сайт становится недоступным.
Подобные проблемы не могут быть на стороне Amazon S3, так как она высокодоступная и высокомасштабируемая.
Другой момент - это то, что в случае с веб-сервером вы покупаете цельную единицу IT ресурса и оплачиваете вне зависимости от того какие будут нагрузки.
Если ваш сайт не такой популярный, то вне зависимости от того были запросы на ваш сайт или нет, вы оплачиваете фиксированную сумму за использование этого веб-сервера.
В случае же с Amazon S3 подобных платежей проводить не нужно.
Вам достаточно оплачивать только за размер ваших медиа файлов, которые вы хостите на Amazon S3.
Это довольно небольшие суммы и в целом это решение более выгодное не только по экономической части, но и технически лучше.
Другой немаловажный момент - это, то что вы под static websites возможно понимаете статические простейшие веб-сайты.
На самом деле динамические веб-сайты также можно хостить на Amazon S3.
Связано это с тем, что JavaScript сам по себе генерирует JS файлы, которые сами по себе статичные.
Их можно будет обслуживать в рамках static website хостинга на Amazon S3.
Тем не менее, тот код, который исполняется в этих JS файлах, динамический.
В зависимости от того какой запрос приходит, он может менять свое поведение.
Таким образом, мы можем хостить на Amazon S3 динамические веб-сайты.
Следующим интересным функционалом сервиса Amazon S3 является Versioning.
Versioning - это когда вы активируете этот функционал и он сохраняет все версии, которые когда-либо были загружены на этот S3 bucket под определенным ключом.
Под ключом, как вы помните, понимается весь путь хранения вашего файла, включая все папки, где он находится.
Таким образом, даже при удалении файлов из S3 bucket с включенным versioning, вы всегда можете откатиться назад и быстро восстановить этот файл.
Более того, если вы работаете с несколькими версиями одного и того же файла, вы опять же легко с versioning можете вернуться на любую версию, которую пожелаете исходя из вашей задачи.
S3 bucket касательно versioning может находиться в трех состояниях.
Первое состояние - это Default, когда versioning отключен (Versioning not enabled).
Если вам нужен versioning, вам нужно ее отдельно активировать.
Далее, второе состояние - это включенный versioning (Versioning-enabled).
И третье состояние - это приостановленный versioning (Versioning-suspended).
Третья версия существует потому, что versioning невозможно отключить, после того как вы ее включили, ее можно только приостановить.
Таким образом, все версии файлов, которые сгенерировались во время включенного versioning, сохраняются.
В тот момент как вы приостанавливаете versioning, новые загруженные файлы не генерируют новые версий.
И для того чтобы продолжить сохранять новые версии, вам необходимо обратно включить versioning.
Следующий функционал, который поддерживается Amazon S3 - это CORS (Cross-Origin Resource Sharing).
Идея в том, что настроив CORS, вы можете предоставить доступ другому сайту использовать части вашего веб-сайта, либо обращаться напрямую к медиа файлам вашего веб-сайта.
Если CORS не прописан, то браузеры по умолчанию запрещают подобные действия, а именно, находясь на одном веб-сайте, не могут использовать части или обращаться к другому веб-сайту.
Это не разрешено в целях безопасности.
Если у вас есть необходимость подобные действия проводить, то вы выборочно для выделенных ресурсов можете прописать CORS и другие веб-сайты смогут использовать ваши ресурсы.
Следующим интересным use case сервиса Amazon S3 является хранение данных в рамках масштабных расчетов и аналитики.
Объектное хранение в этом случае идеально подходит, так как данные для подобного рода расчетов записываются один раз и много раз считывается: обычно эти данные не изменяются.
Какие это данные? 
Это данные о транзакциях платежей, информация о посещении страниц пользователей, различные логи и так далее.
Таким образом, записываются эти данные один раз в Amazon S3.
Amazon S3 может также использоваться как источник сырых данных.
Далее, вы видите на слайде пример, когда запускаются spot instances, либо какой-то EMR Cluster, который проводит эти расчеты.
Далее, после того как расчеты проведены, уже измененные данные попадают в следующий S3 bucket, в котором они хранятся уже в обработанном виде.
Далее, можно подключить различные системы аналитики: есть сервис Amazon QuickSight, который позволяет нам визуализировать наши данные.
Следующим интересным использованием сервиса Amazon S3 является хранение различных бэкапов, архивов критических данных, которые вы обязаны хранить какой-то период времени согласно регуляторным требованиям, либо своим внутренним корпоративным документам.
Источником этих данных может выступать не только ваша инфраструктура на уровне AWS, вы также с локального дата-центра можете напрямую передавать и хранить эти данные в Amazon S3.
Мы помним, что хранение данных в сервисе Amazon S3 является достаточно надежным вариантом так как обеспечивает надежность 11 девяток.
Если по тем или иным причинам вам необходима еще большая надежность, то есть функционал Cross-Region Replication (CRR), когда вы создаете второй бакет в другом регионе и в первом бакете настраиваете Cross-Region Replication.
Таким образом, когда данные попадают в первый бакет, он автоматически реплицирует эти данные в бакет находящийся на другом регионе.
Это еще больше увеличивает надежность хранения ваших данных, но в этом случае вам необходимо нести дополнительные затраты на поддержание этой простейшей инфраструктуры для хранения ваших данных.
Следует учитывать и предварительно рассчитать объемы, хотя бы примерно в каком объеме вы будете хранить данные, какой период они будут там храниться и сделать расчет сколько денег вам предстоит оплатить в случае того или иного варианта хранения ваших критических данных.
Давайте затронем пару моментов, связанных с consistency model.
Идея в том, что как изменения, связанные с сервисом Amazon S3 применяются.
Когда мы говорим про объекты, то все объекты во всех регионах strongly consistent.
Это говорит о том, что изменения над существующими объектами и новыми объектами вступают в силу сразу после записи.
Проще говоря, после того как мы проведем успешную PUT операцию, то есть запишем объект в S3 bucket, если сразу после этого мы запустим GET или LIST операцию, который считывает объект либо запрашивает список имеющихся объектов в бакете, то этот недавно записанный объект сразу появится в этом списке, либо вернется обновленное содержание этого объекта.
Таким образом обеспечивается read-after-write consistency для операции GET, LIST и PUT.
Когда мы говорим про конфигурации бакетов, то они eventually consistent, что означает применение новых настроек через небольшой промежуток времени, не сразу.
Пример: если мы удалили бакет, и сразу после этого запросили список бакетов, то удаленный бакет может отобразиться в этом списке.
Если через несколько секунд мы еще раз запросим список существующих бакетов, то в этом случае удаленный бакет уже не будет присутствовать в этом списке.
Есть вот такие нюансы по работе с бакетами и объектами в сервисе Amazon S3.
Итак, мы добрались до конца второй секции и давайте остановимся на самых основных моментах связанных с сервисом Amazon S3.
Первое, самое важное - это то, что названия бакетов должны быть глобальными среди всех регионов AWS.
В то время как для хранения данных мы выбираем определенный регион и все данные хранятся в этом регионе.
Далее, это то, что все бакеты по умолчанию приватные: для того чтобы предоставить публичный доступ вам нужно совершить дополнительные действия.
Для того чтобы предоставить доступ к вашему бакету, будь то публичный или для сущностей внутри AWS аккаунта, вы можете воспользоваться различными вариантами.
Это может быть IAM policy, Bucket policy, Access control Lists и так далее.
Для всех новых и существующих объектов работает модель Strongly Consistency, изменение объектов вступает в силу моментально.
Максимальный размер одного файла в сервисе Amazon S3 - 5 терабайтов, что более чем достаточно практически для всех задач хранения и существующих файлов.
Также мы рассмотрели 4 популярных use case сервиса Amazon S3.
Оно не ограничивается этими use case: есть очень много различных менее популярных use case.
Самое главное - вы получили общее представление каким образом, в каких местах архитектуры можно успешно применить этот сервис.
На этом мы подошли к концу первой части лекции, посвященной теме хранения в облаке AWS.
Я очень надеюсь, что вы получили более полное представление о сервисе Amazon S3.
Также в дальнейших наших активностях у нас будет Демо и лабораторная работа, посвященная сервису Amazon S3.
На этом мы заканчиваем нашу сегодняшнюю сессию.
Спасибо за внимание.
Увидимся с вами на следующих наших активностях.
