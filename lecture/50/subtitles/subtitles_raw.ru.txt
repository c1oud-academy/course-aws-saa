 Добрый день, уважаемые студенты! Я рад вас всех видеть на очередной лекции. Тема сегодняшней лекции это сервисы хранения AWS. Сегодняшняя лекция это продолжение предыдущей лекции, вторая часть. Мы продолжим говорить о сервисе Amazon S3. Итак, давайте начнем. Сегодняшняя лекция состоит из трех частей. В первой секции мы поговорим про некоторые нюансы хранения данных в сервисе Amazon S3, какие классы хранения бывают, за что мы платим и так далее. Во второй секции мы поговорим про нюансы связанные с переносом данных в и из Amazon S3 Bucket. И в последней секции мы поговорим о том, как правильно выбирать регион, какие нюансы есть, на что нужно обратить внимание. Также на этой неделе будет специальная демо. Она посвящена функционалу Transfer Acceleration от сервиса Amazon S3. Мы ее подробно разберем и наглядно посмотрим, как это работает. Также на этой неделе у нас запланирована лабораторная работа. Будет две активности ведения и разбор лабораторной работы. Это Challenge Lab, где в задании будет минимальное количество деталей и вам необходимо будет на основе тех знаний, которые вы получили на лекциях, а также на предыдущем Guided Lab применить эти знания для решения конкретной бизнес-задачи. Итак, поехали. Итак, мы с вами начинаем третью секцию. Третья секция, потому что мы взяли сквозную нумерацию. Первые две секции мы прошли на предыдущей неделе. Итак, мы сейчас разберем нюансы, связанные с хранением данных в сервисе Amazon S3. Начнем мы с существующих storage классов, то есть классов хранения. Самый первый, самый популярный и часто используемый вариант, это S3 Standard. Он идеально подходит для тех данных, которые должны быть доступны всегда в онлайне. При этом вы оплачиваете только за то, что вы используете и хранение оно достаточно надежное, как мы говорили ранее, 11 девяток. Следующий класс хранения это S3 Standard IA, то есть Infra-Contact Access. Оно немного дешевле с точки зрения хранения, но необходимо оплачивать отдельно за услуги извлечения ваших данных. Если ваши данные не часто запрашиваются, то вы фактически не будете оплачивать часть за извлечение данных. Соответственно, в целом хранение в этом классе будет для вас более выгодным решением. Следующий класс, который еще более выгодный, это S3 One Zone Infra-Contact Access. Он идеально подходит для тех данных, которые мы храним на более долгий период, которые не так часто запрашиваются и данные, которые мы можем себе позволить частично потерять, это не так критично, либо это могут быть те данные, которые можно легко восстановить. В этом случае мы оплачиваем еще меньше и отличие в том, что данные хранятся только на одной availability зоне, соответственно durability здесь чуть ниже, тогда как стандарт и стандарт IA Infra-Contact Access, они надежны на 11 девяток. Следующие два класса хранения, они больше относятся к архивным данным, это Amazon S3 Glacier и DeepArchive. Эти классы хранения идеально подходят для тех данных, которые мы сохраняем на долго, по тем или иным причинам, должны хранить некоторый период времени и хранение должно быть дешевым. Мало вероятно, что мы эти данные будем запрашивать, поэтому и излечение данных из этих классов хранения достаточно трудозатратно с точки зрения времени. Например, если мы говорим S3 Glacier, там есть три варианта излечения данных, самый первый и самый быстрый, но тем не менее самый дорогой это Expedited, когда мы данные можем излечь в течение одной и пяти минуты. Далее есть Standard Retrieval, это когда мы данные извлекаем в течение трех-пяти часов, она немного дешевле и самый дешевый вариант излечения для Glacier это Bulk Retrievals, когда мы данные получаем в течение пяти-двенадцати часов. Это самое дешевое с точки зрения оплаты за излечение, но тем не менее больше всего времени нужно будет ждать. Если мы говорим про Glacier Deep Archive, то оно еще больше дешевле, чем Glacier, то есть данные, которые мы совсем не планируем извлекать, можно сохранять в Glacier Deep Archive, оно также в себе содержит надежность 11 девяток и данные реплицируются на как минимум три availability зоны. Если мы говорим про излечение данных, то для Glacier Deep Archive данные изликаются в течение 12 часов. И самый последний класс хранения это S3 Intelligent Tiering, в этом случае мы оплачиваем некоторую дополнительную сумму за работу этого класса хранения. Идея этого класса хранения в том, что мы забываем про существование классов хранения и передаем эту работу самому AWS. AWS уже на основе логов обращения к файлам индивидуально для каждого файла подбирает подходящий класс хранения. При этом, если по тем или иным причинам определенный файл был запрошен чаще или наоборот реже, чем ожидалось, то перенос с одного класса хранения на другой класс хранения не оплачивается в случае использования Intelligent Tiering класса хранения. Однозначно утверждать, что тот или иной класс хранения лучше не совсем верно, так как в зависимости от вашей бизнес задачи тот или иной класс хранения может лучше для вас подходить, поэтому нужно смотреть на ваш бизнес кейс. То, что существует Intelligent класс хранения это очень хорошо, AWS старается по возможности помогать бизнесу, чтобы он не отвлекался на технические задачи и смог сконцентрироваться на бизнес задачах, но мы как владельцы данных лучше знаем как эти данные будут запрашиваться, мы знаем что при возникновении некоторых изменений как может поменяться частота обращения к этим файлам, поэтому была разработана специальная функция это Lifecycle Policies, идея в том что мы можем настроить полисе для нашего бакета и согласно этому полисе класс хранения на уровне каждого объекта будет изменяться в зависимости от этого полисе. Например мы говорим что у нас в систему загружается некие видео.mp4 файл и первые 30 дней она активно запрашивается используется, поэтому наиболее рационально его хранить в классе хранения S3 standard. Далее уже после 30 дней и до 60 дней файл потенциально может быть запрошен, но это достаточно редкий кейс, поэтому мы можем для уменьшения наших затрат на хранение перенести ее на следующий класс хранения standard.infra-frequent-access. Далее уже после двух месяцев после загрузки конкретно этого файла этот файл определенно использоваться не будет и мы в течение года возможно по некоторым внутренним положениям компании должны хранить ее в случае если оно нам понадобится. Поэтому после 60 дней она переходит в класс хранения Glacier для того чтобы снизить затраты на хранение зная что мы запрашивать не будем и после года использования этот файл нам не нужен и мы безопасно можем его удалить. Таким образом life cycle policy позволяет нам зная как наши данные будут запрашиваться в amazon S3 задать логику переноса между классами хранения и эта логика это life cycle policy будет накладываться на каждый объект в момент ее загрузки. Давайте теперь подробнее остановимся с вопросами оплаты за использование сервис amazon S3. Этот слайд посвящен тем пунктам когда мы оплачиваем за использование сервиса. Это связано с объемом данных которые мы храним. Есть определенный тариф за каждый гигабайт хранения и мы оплачиваем только за то что мы используем. Представим что мы храним один единственный наш файл размером 1 гигабайт нашим единственном S3 бакете загрузили ее на три дня после чего ее удалили. В конце месяца придет счет на оплату за 1 гигабайт объем данных но ровно за три дня. За оставшиеся 27 дней месяца так как amazon S3 ничего не хранила мы не оплачиваем. Следует также учитывать что цены могут отличаться в зависимости от региона и в зависимости от класса хранения. Второй пункт пункт где нам необходимо оплачивать за использование сервиса amazon S3 это перенос данных от S3 бакета. То есть представим случай когда мы с S3 бакета в регионе Норс-Вирджиния переносим данные в другой регион например Орегон наши данные. В этом случае это воспринимается как transfer out поэтому за этот объем данных необходимо будет некоторую сумму оплатить. Это также относится к кейсу когда мы с S3 бакета загружаем некий объем данных на локальный компьютер. Третье это то что мы оплачиваем также все API вызовы на amazon S3. Это могут быть запросы когда мы передаем файл на хранение, когда мы копируем ее, запрашиваем список объектов хранящихся в определенном S3 бакете и так далее. Это также относится к lifecycle transition мы помним что у нас есть функционал lifecycle policy которые в определенные промежутки времени индивидуально для каждого объекта переносится с одного класса хранения на другой класс хранения либо удаляет этот файл. Так вот каждый переход необходимо тоже отдельно оплачивать. Эти суммы относительно небольшие но что важно это перед началом использования amazon S3 если у вас очень большой объем данных рекомендуется более подробно изучить за что мы оплачиваем за сервис amazon S3 рассчитать ту стоимость которую мы будем ежемесячно оплачивать будь то приблизительные суммы и если эти суммы нам подходят мы можем начинать работать с этим сервисом зная что никаких дополнительных сюрпризов никаких дополнительных оплат точно не будет. Теперь мы остановимся на тех пунктах когда мы не оплачиваем при использовании сервиса amazon S3. Первый пункт это когда мы с интернета загружаем данные в S3 бакет. Как я говорил ранее политика такая что AWS с радостью принимает данные от вас для того чтобы ее накапливать но при этом когда вы эти данные начинаете извлекать вам необходимо производить некоторую оплату это применимо ко многим сервисам. Мы также не оплачиваем за перенос данных между двумя бакетами если они находятся в одном и том же регионе. Также мы не оплачиваем за перенос данных с S3 на любой другой сервис который также находится в одном регионе. Самый популярный кейс это использование сервиса S3 в вашем приложении и ваше приложение хостится на EC2 инстанциях. В этом случае если S3 и EC2 находятся в одном и том же регионе за трансфер данных мы не будем оплачивать. Другой кейс это то что у нас есть сервис Amazon CloudFront который является CDN то есть Content Delivery Network. Оно нативно интегрируется с S3 для того чтобы быстро доставлять данные вашим пользователям по всему миру. Так вот во время интеграции S3 с CloudFront при передаче данных с S3 на CloudFront для кэширования мы никаких оплат не производим. И последнее на те запросы которые связаны с удалением объектов S3 бакете а также отмененные действия они не учитываются и за эти вызовы API сервиса Amazon S3 мы не оплачиваем. Мы с вами добрались до конца третьей секции давайте остановимся на самых важных моментах. Мы рассмотрели какие классы хранения бывают далее познакомились с функционалом LifeCycle Policy и также рассмотрели все кейсы когда мы оплачиваем за использование сервиса Amazon S3 и когда оплачивать ничего не нужно. Двигаемся к следующей секции четвертая секция и здесь мы будем говорить про все нюансы связанные с трансфером данных из и в Amazon S3 бакеты. Давайте разберем те методы с применением которых мы можем загружать наши данные в Amazon S3. Самое первое и то что мы уже с вами неоднократно проделывали на наших демо и лабораторных работах это AWS Management Console используя UI консоли мы можем как загружать так и выгружать данные оттуда и полноценно видеть все необходимое связанное с сервисом Amazon S3. Следующая это AWS CLI более продвинутая опция когда мы можем написать некоторые скрипты либо набор команд и таким образом работать с объектами в сервисе Amazon S3. Далее еще более продвинутый вариант это использовать SDK software development kit. Самый популярный SDK для AWS это BOT03 он написан для языка программирования Python и вы можете используя высокоуровневый язык программирования написать некоторую логику когда код взаимодействует с сервисом Amazon S3. Мы двигаемся дальше и теперь рассмотрим интересный функционал называется Multi-Part Upload. Идея в том что для объектов большого размера мы можем ускорить загрузку в S3 bucket путем разделения ее на более мелкие части и загрузки этих частей индивидуально в S3. Далее после завершения загрузки всех частей она собирается на стороне S3 и этот файл становится доступен на стороне S3 bucket. Важные нюансы которые следует упомянуть минимальный размер файла который можно загрузить использование Multi-Part Upload это 5 мегабайтов. Если размер файла будет меньше то эту опция не сработает. Есть также такая рекомендация что файлы размером менее 100 мегабайтов загружать рекомендуется цельным образом не применяя Multi-Part Upload. Если размер файла больше 100 мегабайтов в этом случае Multi-Part Upload может вам ускорить вашу загрузку в S3. Используя Multi-Part Upload у нас есть возможность загружать части параллельно это уменьшает время загрузки. Также в случае возникновения некоторых проблем с сетью если это один единственный файл то в случае проблем сетью загрузка полностью отменяется и все то что загружено она удаляется таким образом вам нужно будет начать загрузку еще раз. В случае когда мы это делаем через Multi-Part Upload все части которые были уже загружены их повторно загружать не нужно. Нужно загрузить перезагрузить только те части которые упали с ошибкой в связи с проблем с сетью. Также при загрузке через Multi-Part Upload у нас есть возможность паузить то есть временно приостанавливать загрузку и продолжать ее. Используя Multi-Part Upload мы можем загружать достаточно большие объекты до 5 терабайтов. Следующий функционал который достаточно интересный и позволяет нам большие объемы данных передавать в S3 Bucket это Transfer Acceleration. Идея ее в том что мы задействуем edge сервера от сервиса Amazon CloudFront таким образом мы не загружаем наши данные напрямую на S3 Bucket, а загружаем на ближайший кэш сервер. Таким образом загрузка происходит намного быстрее. Использовать Transfer Acceleration рекомендуется в случаях когда мы загружаем данные со всего мира в один централизованный Bucket на постоянной основе. Также рекомендуется использовать Transfer Acceleration когда мы гигабайты или терабайты данных загружаем в Bucket находящийся в другом регионе на постоянной основе. У нас будет отдельное демо посвященное Transfer Acceleration. Мы более подробнее разберем этот функционал и наглядно покажем какие преимущества оно дает. Следующие два примера связанные с семейством сервисов AWS Snow это Snowball и Snowmobile. Отличаются они размерами. Давайте сейчас подробнее остановимся на AWS Snowmobile. Это некий сервис который позволяет нам загружать несколько терабайтов или несколько десятков терабайтов данных на Amazon S3. Как это работает? Вы заходите в сервис, оставляете свою заявку и AWS выгружает вам физический чемоданчик который доезжает до вашего офиса и вы подключаете этот чемоданчик к локальной сети и загружаете в него все необходимые данные. Этот чемоданчик содержит необходимые для работы вычислительные мощности, а самое главное компоненты хранения, то есть жесткие диски. Как только вы загрузили намного быстрее через локальную сеть все необходимые данные вы ее запаковываете и отправляете обратно на адрес с которого он пришел. Как только он доезжает до ближайшего дата центра AWS она подключается к глобальной инфраструктуре и опять же через локальную сеть все эти данные загружается в S3 bucket на который вы указываете и ваши данные появляются в S3. Это отличная возможность если у вас большой объем данных и вы решили переезжать на AWS. Есть пример представим что у нас есть 10 петобайтов данных это 10 миллионов гигабайтов и если мы будем передавать это через интернет при этом у нас будет достаточно широкий канал загрузки данных в 10 гигабитов в секунду то на все про все нам необходимо будет порядка 100 дней это может быть дорого и нерационально для бизнеса поэтому Snowmobile может быть отличным решением. Второй похожий сервис предназначенный для еще большего объема данных для передачи с локального дата центра AWS а именно в Amazon S3 это AWS Snowmobile это порядка 14 метровый контейнер который содержит в себе все необходимые вычислительные мощности по сути это маленький дата центр он привязан к нативно к своему грузовику и этот грузовик время после того как вы оставляете заявку в этом сервисе выезжает в сторону вашего офиса как только доезжает вы также подключаете к локальной сети и передаете ваши данные оно рассчитано на передачу петобайтов нескольких петобайтов и более данных с локального дата центра в облако AWS. Для того чтобы обслуживать подобный контейнер выделяется специальные люди они приезжают вместе с контейнером также у вас есть специальное наблюдение различные элементы безопасности вы можете отслеживать передвижение вашего контейнера через GPS все необходимое чтобы безопасно добраться до вашего локального офиса и в безопасности ваши данные доставить до ближайшего дата центра AWS. Мы с вами добрались до конца четвертой секции, вкратце пройдемся по основным моментам это то что есть функционал multi-part upload когда мы большие файлы с размером более 100 мегабайтов разделяем на несколько частей и отправляем в S3 по частям это дает некоторые преимущества другой вариант который позволяет ускорить загрузку ваших данных с локального дата центра в облако AWS это Transfer Acceleration который задействует edge сервера сервиса amazon cloud front и третье это то что есть семейство snow которое позволяет вам передавать еще большие объемы данных путем загрузки в некоторое физическое устройство которое приезжает к вам загружать туда ваши данные и отправляйте обратно в ближайшие дата центра AWS откуда оно потом через локальную сеть что намного быстрее загружает ваши данные сервис Amazon S3. Мы добрались с вами до пятой секции и здесь мы остановимся на некоторых нюансах какой же регион AWS выбрать для хостинга нашей архитектуры. При выборе регионе первым делом необходимо проверить есть ли некоторые положения либо регуляторные требования которые накладывают ограничения на хранение ваших данных вне вашей страны либо похожие нюансы нужно проверить действительно ли этот регион подходит вам с точки зрения закона вы не нарушаете закон в случае если есть подобные ограничения и если есть AWS регион в вашей стране либо в стране где вы не будете нарушать закон то следует использовать ее. Второй момент который также нужно учитывать это расстояние до ваших потенциальных пользователей даже небольшие изменения точнее отличия в скорости передачи данных оно может сильно отразиться на опыте использования вашим продуктом вашими пользователями поэтому необходимо проверить какой регион находится ближайшие до ваших потенциальных пользователей. Следующий пункт на который следует обратить внимание это доступность сервисов и функционала этих сервисов в выбранном вами регионе все новинки все новые сервисы и функционал сервисов в первую очередь появляется на первом основном регионе это регион Норс-Вирджиния далее по истечении некоторого времени после прохождения некоторых внутренних тестов новые сервисы новый функционал начинает распространяться на другие регионы таким образом есть некоторые регионы до которых обновление доходит несколько месяцев следует это учитывать есть на уровне каждого сервиса в документации так называемые AWS region table где прописывается доступность тех или иных сервисов также функционала в определенном регионе. Последний но немаловажный пункт на который стоит обратить внимание это cost то есть стоимость использования сервисов AWS в конкретном выбранном регионе. Цены отличаются здесь определенной логики ценообразования нет поэтому необходимо проверить в интересующих вас регионах цены на интересующие сервисы на тот функционал который дополнительно оплачивается и прикинуть действительно ли эти цены они вас устраивают. Мы с вами добрались до конца пятой секции вкратце остановились на четырех важных пунктах на которые следует обратить внимание при выборе AWS региона. Это была последняя секция на этом мы завершаем вторую часть темы посвященные хранению в облаке AWS мы сегодня рассмотрели какие классы хранения бывают у сервиса Amazon S3 рассмотрели нюансы передачи данных в и из S3 бакетов какие сервисы и функционал позволяет нам это делать более оптимально также рассмотрели кейсы связанные с выбором региона для хостинга нашей IT инфраструктуры здесь вы можете видеть ссылки на некоторые полезные источники это документация связанная с сервисом Amazon S3 также эти страницы вы можете легко найти вбив необходимые ключевые слова в поисковик на этом мы подошли к концу нашей сегодняшней лекции я очень надеюсь что вы получили более полные представления у сервиса Amazon S3 мы рассмотрели более подробнее этот сервис напоминаю что у нас будет на этой неделе еще демо активность а также лаборатурная работа связанная с сервисом Amazon S3 спасибо за внимание увидимся с вами на следующих наших активностях
