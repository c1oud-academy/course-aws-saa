WEBVTT

00:00:00.000 --> 00:00:07.120
Добрый день, уважаемые студенты! Я рад вас всех видеть на очередной лекции. Тема сегодняшней

00:00:07.120 --> 00:00:14.920
лекции это сервисы хранения AWS. Сегодняшняя лекция это продолжение предыдущей лекции,

00:00:14.920 --> 00:00:20.720
вторая часть. Мы продолжим говорить о сервисе Amazon S3. Итак, давайте начнем.

00:00:20.720 --> 00:00:28.360
Сегодняшняя лекция состоит из трех частей. В первой секции мы поговорим про некоторые

00:00:28.360 --> 00:00:34.920
нюансы хранения данных в сервисе Amazon S3, какие классы хранения бывают, за что мы платим и так

00:00:34.920 --> 00:00:42.720
далее. Во второй секции мы поговорим про нюансы связанные с переносом данных в и из Amazon S3

00:00:42.720 --> 00:00:52.240
Bucket. И в последней секции мы поговорим о том, как правильно выбирать регион, какие нюансы есть,

00:00:52.240 --> 00:00:57.640
на что нужно обратить внимание. Также на этой неделе будет специальная демо. Она посвящена

00:00:57.640 --> 00:01:05.200
функционалу Transfer Acceleration от сервиса Amazon S3. Мы ее подробно разберем и наглядно посмотрим,

00:01:05.200 --> 00:01:12.560
как это работает. Также на этой неделе у нас запланирована лабораторная работа. Будет две

00:01:12.560 --> 00:01:20.960
активности ведения и разбор лабораторной работы. Это Challenge Lab, где в задании будет минимальное

00:01:20.960 --> 00:01:26.240
количество деталей и вам необходимо будет на основе тех знаний, которые вы получили на лекциях,

00:01:26.240 --> 00:01:33.400
а также на предыдущем Guided Lab применить эти знания для решения конкретной бизнес-задачи.

00:01:33.400 --> 00:01:44.360
Итак, поехали. Итак, мы с вами начинаем третью секцию. Третья секция, потому что мы взяли

00:01:44.360 --> 00:01:50.680
сквозную нумерацию. Первые две секции мы прошли на предыдущей неделе. Итак, мы сейчас разберем

00:01:50.680 --> 00:01:57.240
нюансы, связанные с хранением данных в сервисе Amazon S3. Начнем мы с существующих storage классов,

00:01:57.240 --> 00:02:03.080
то есть классов хранения. Самый первый, самый популярный и часто используемый вариант,

00:02:03.080 --> 00:02:11.400
это S3 Standard. Он идеально подходит для тех данных, которые должны быть доступны всегда в онлайне. При

00:02:11.400 --> 00:02:21.160
этом вы оплачиваете только за то, что вы используете и хранение оно достаточно надежное,

00:02:21.160 --> 00:02:32.120
как мы говорили ранее, 11 девяток. Следующий класс хранения это S3 Standard IA, то есть Infra-Contact Access.

00:02:32.120 --> 00:02:41.200
Оно немного дешевле с точки зрения хранения, но необходимо оплачивать отдельно за услуги

00:02:41.200 --> 00:02:49.600
извлечения ваших данных. Если ваши данные не часто запрашиваются, то вы фактически не будете

00:02:49.600 --> 00:02:57.040
оплачивать часть за извлечение данных. Соответственно, в целом хранение в этом классе будет для вас

00:02:57.040 --> 00:03:08.320
более выгодным решением. Следующий класс, который еще более выгодный, это S3 One Zone Infra-Contact Access.

00:03:08.320 --> 00:03:18.080
Он идеально подходит для тех данных, которые мы храним на более долгий период, которые не так часто

00:03:18.080 --> 00:03:24.920
запрашиваются и данные, которые мы можем себе позволить частично потерять, это не так критично,

00:03:24.920 --> 00:03:31.200
либо это могут быть те данные, которые можно легко восстановить. В этом случае мы оплачиваем еще

00:03:31.200 --> 00:03:41.120
меньше и отличие в том, что данные хранятся только на одной availability зоне, соответственно

00:03:41.120 --> 00:03:54.440
durability здесь чуть ниже, тогда как стандарт и стандарт IA Infra-Contact Access, они надежны на 11 девяток.

00:03:54.440 --> 00:04:04.120
Следующие два класса хранения, они больше относятся к архивным данным, это Amazon S3 Glacier

00:04:04.120 --> 00:04:14.800
и DeepArchive. Эти классы хранения идеально подходят для тех данных, которые мы сохраняем на долго,

00:04:14.800 --> 00:04:20.920
по тем или иным причинам, должны хранить некоторый период времени и хранение должно

00:04:20.920 --> 00:04:28.160
быть дешевым. Мало вероятно, что мы эти данные будем запрашивать, поэтому и излечение данных из этих

00:04:28.160 --> 00:04:36.280
классов хранения достаточно трудозатратно с точки зрения времени. Например, если мы говорим S3 Glacier,

00:04:36.280 --> 00:04:41.560
там есть три варианта излечения данных, самый первый и самый быстрый, но тем не менее самый

00:04:41.560 --> 00:04:47.800
дорогой это Expedited, когда мы данные можем излечь в течение одной и пяти минуты. Далее есть

00:04:47.800 --> 00:04:54.920
Standard Retrieval, это когда мы данные извлекаем в течение трех-пяти часов, она немного дешевле и

00:04:54.920 --> 00:05:01.480
самый дешевый вариант излечения для Glacier это Bulk Retrievals, когда мы данные получаем в течение

00:05:01.480 --> 00:05:10.760
пяти-двенадцати часов. Это самое дешевое с точки зрения оплаты за излечение, но тем не менее больше

00:05:10.760 --> 00:05:19.040
всего времени нужно будет ждать. Если мы говорим про Glacier Deep Archive, то оно еще больше дешевле,

00:05:19.040 --> 00:05:30.640
чем Glacier, то есть данные, которые мы совсем не планируем извлекать, можно сохранять в Glacier Deep

00:05:30.640 --> 00:05:40.720
Archive, оно также в себе содержит надежность 11 девяток и данные реплицируются на как минимум три

00:05:40.720 --> 00:05:48.800
availability зоны. Если мы говорим про излечение данных, то для Glacier Deep Archive данные изликаются

00:05:48.800 --> 00:05:59.240
в течение 12 часов. И самый последний класс хранения это S3 Intelligent Tiering, в этом случае

00:05:59.240 --> 00:06:06.760
мы оплачиваем некоторую дополнительную сумму за работу этого класса хранения. Идея этого класса

00:06:06.760 --> 00:06:16.160
хранения в том, что мы забываем про существование классов хранения и передаем эту работу самому AWS.

00:06:16.160 --> 00:06:28.120
AWS уже на основе логов обращения к файлам индивидуально для каждого файла подбирает

00:06:28.120 --> 00:06:36.320
подходящий класс хранения. При этом, если по тем или иным причинам определенный файл был запрошен

00:06:36.320 --> 00:06:43.840
чаще или наоборот реже, чем ожидалось, то перенос с одного класса хранения на другой класс

00:06:43.840 --> 00:06:51.400
хранения не оплачивается в случае использования Intelligent Tiering класса хранения. Однозначно утверждать,

00:06:51.400 --> 00:06:58.800
что тот или иной класс хранения лучше не совсем верно, так как в зависимости от вашей бизнес

00:06:58.800 --> 00:07:04.720
задачи тот или иной класс хранения может лучше для вас подходить, поэтому нужно смотреть на ваш

00:07:04.720 --> 00:07:17.960
бизнес кейс. То, что существует Intelligent класс хранения это очень хорошо, AWS старается по

00:07:17.960 --> 00:07:24.080
возможности помогать бизнесу, чтобы он не отвлекался на технические задачи и смог сконцентрироваться

00:07:24.080 --> 00:07:31.920
на бизнес задачах, но мы как владельцы данных лучше знаем как эти данные будут запрашиваться,

00:07:31.920 --> 00:07:39.640
мы знаем что при возникновении некоторых изменений как может поменяться частота обращения к этим файлам,

00:07:39.640 --> 00:07:50.420
поэтому была разработана специальная функция это Lifecycle Policies, идея в том что мы можем настроить

00:07:50.420 --> 00:08:02.200
полисе для нашего бакета и согласно этому полисе класс хранения на уровне каждого объекта будет

00:08:02.200 --> 00:08:10.920
изменяться в зависимости от этого полисе. Например мы говорим что у нас в систему загружается некие

00:08:10.920 --> 00:08:20.840
видео.mp4 файл и первые 30 дней она активно запрашивается используется, поэтому наиболее

00:08:20.840 --> 00:08:31.760
рационально его хранить в классе хранения S3 standard. Далее уже после 30 дней и до 60 дней файл

00:08:31.760 --> 00:08:39.960
потенциально может быть запрошен, но это достаточно редкий кейс, поэтому мы можем для уменьшения наших

00:08:39.960 --> 00:08:47.520
затрат на хранение перенести ее на следующий класс хранения standard.infra-frequent-access. Далее уже

00:08:47.520 --> 00:08:55.920
после двух месяцев после загрузки конкретно этого файла этот файл определенно использоваться не

00:08:55.920 --> 00:09:03.160
будет и мы в течение года возможно по некоторым внутренним положениям компании должны хранить ее

00:09:03.160 --> 00:09:14.040
в случае если оно нам понадобится. Поэтому после 60 дней она переходит в класс хранения

00:09:14.040 --> 00:09:21.680
Glacier для того чтобы снизить затраты на хранение зная что мы запрашивать не будем и после года

00:09:21.680 --> 00:09:32.240
использования этот файл нам не нужен и мы безопасно можем его удалить. Таким образом life cycle policy

00:09:32.240 --> 00:09:42.920
позволяет нам зная как наши данные будут запрашиваться в amazon S3 задать логику переноса

00:09:42.920 --> 00:09:52.240
между классами хранения и эта логика это life cycle policy будет накладываться на каждый объект в

00:09:52.240 --> 00:10:03.000
момент ее загрузки. Давайте теперь подробнее остановимся с вопросами оплаты за использование

00:10:03.000 --> 00:10:10.600
сервис amazon S3. Этот слайд посвящен тем пунктам когда мы оплачиваем за использование сервиса.

00:10:10.600 --> 00:10:18.440
Это связано с объемом данных которые мы храним. Есть определенный тариф за каждый гигабайт

00:10:18.440 --> 00:10:26.360
хранения и мы оплачиваем только за то что мы используем. Представим что мы храним один

00:10:26.360 --> 00:10:32.400
единственный наш файл размером 1 гигабайт нашим единственном S3 бакете загрузили ее на три дня

00:10:32.400 --> 00:10:41.120
после чего ее удалили. В конце месяца придет счет на оплату за 1 гигабайт объем данных но ровно за

00:10:41.120 --> 00:10:49.160
три дня. За оставшиеся 27 дней месяца так как amazon S3 ничего не хранила мы не оплачиваем.

00:10:49.160 --> 00:10:57.320
Следует также учитывать что цены могут отличаться в зависимости от региона и в зависимости от класса

00:10:57.320 --> 00:11:06.360
хранения. Второй пункт пункт где нам необходимо оплачивать за использование сервиса amazon S3 это

00:11:06.360 --> 00:11:17.720
перенос данных от S3 бакета. То есть представим случай когда мы с S3 бакета в регионе Норс-Вирджиния

00:11:17.720 --> 00:11:26.760
переносим данные в другой регион например Орегон наши данные. В этом случае это воспринимается

00:11:26.760 --> 00:11:32.480
как transfer out поэтому за этот объем данных необходимо будет некоторую сумму оплатить.

00:11:32.480 --> 00:11:41.960
Это также относится к кейсу когда мы с S3 бакета загружаем некий объем данных на локальный

00:11:41.960 --> 00:11:58.840
компьютер. Третье это то что мы оплачиваем также все API вызовы на amazon S3. Это могут быть запросы

00:11:58.840 --> 00:12:06.680
когда мы передаем файл на хранение, когда мы копируем ее, запрашиваем список объектов хранящихся

00:12:06.680 --> 00:12:16.280
в определенном S3 бакете и так далее. Это также относится к lifecycle transition мы помним что у нас

00:12:16.280 --> 00:12:23.880
есть функционал lifecycle policy которые в определенные промежутки времени индивидуально для каждого

00:12:23.880 --> 00:12:28.760
объекта переносится с одного класса хранения на другой класс хранения либо удаляет этот файл.

00:12:28.760 --> 00:12:35.680
Так вот каждый переход необходимо тоже отдельно оплачивать. Эти суммы относительно небольшие

00:12:35.680 --> 00:12:44.760
но что важно это перед началом использования amazon S3 если у вас очень большой объем данных

00:12:44.760 --> 00:12:53.840
рекомендуется более подробно изучить за что мы оплачиваем за сервис amazon S3 рассчитать ту

00:12:53.840 --> 00:13:02.080
стоимость которую мы будем ежемесячно оплачивать будь то приблизительные суммы и если эти суммы

00:13:02.080 --> 00:13:08.080
нам подходят мы можем начинать работать с этим сервисом зная что никаких дополнительных

00:13:08.080 --> 00:13:18.720
сюрпризов никаких дополнительных оплат точно не будет. Теперь мы остановимся на тех пунктах

00:13:18.720 --> 00:13:27.040
когда мы не оплачиваем при использовании сервиса amazon S3. Первый пункт это когда мы с интернета

00:13:27.040 --> 00:13:36.400
загружаем данные в S3 бакет. Как я говорил ранее политика такая что AWS с радостью принимает

00:13:36.400 --> 00:13:41.920
данные от вас для того чтобы ее накапливать но при этом когда вы эти данные начинаете

00:13:41.920 --> 00:13:46.680
извлекать вам необходимо производить некоторую оплату это применимо ко многим сервисам.

00:13:46.680 --> 00:13:55.760
Мы также не оплачиваем за перенос данных между двумя бакетами если они находятся в одном и

00:13:55.760 --> 00:14:02.760
том же регионе. Также мы не оплачиваем за перенос данных с S3 на любой другой сервис который

00:14:02.760 --> 00:14:08.680
также находится в одном регионе. Самый популярный кейс это использование сервиса S3 в вашем

00:14:08.680 --> 00:14:16.080
приложении и ваше приложение хостится на EC2 инстанциях. В этом случае если S3 и EC2 находятся

00:14:16.080 --> 00:14:24.400
в одном и том же регионе за трансфер данных мы не будем оплачивать. Другой кейс это то что у

00:14:24.400 --> 00:14:33.880
нас есть сервис Amazon CloudFront который является CDN то есть Content Delivery Network. Оно нативно

00:14:33.880 --> 00:14:43.160
интегрируется с S3 для того чтобы быстро доставлять данные вашим пользователям по всему миру. Так

00:14:43.160 --> 00:14:51.520
вот во время интеграции S3 с CloudFront при передаче данных с S3 на CloudFront для кэширования мы никаких

00:14:51.520 --> 00:15:00.880
оплат не производим. И последнее на те запросы которые связаны с удалением объектов S3 бакете а

00:15:00.880 --> 00:15:09.920
также отмененные действия они не учитываются и за эти вызовы API сервиса Amazon S3 мы не оплачиваем.

00:15:09.920 --> 00:15:17.920
Мы с вами добрались до конца третьей секции давайте остановимся на самых важных моментах.

00:15:17.920 --> 00:15:24.800
Мы рассмотрели какие классы хранения бывают далее познакомились с функционалом LifeCycle Policy

00:15:24.800 --> 00:15:31.880
и также рассмотрели все кейсы когда мы оплачиваем за использование сервиса Amazon S3 и

00:15:31.880 --> 00:15:42.000
когда оплачивать ничего не нужно. Двигаемся к следующей секции четвертая секция и здесь мы

00:15:42.000 --> 00:15:51.120
будем говорить про все нюансы связанные с трансфером данных из и в Amazon S3 бакеты.

00:15:55.120 --> 00:16:04.720
Давайте разберем те методы с применением которых мы можем загружать наши данные в Amazon S3. Самое

00:16:04.720 --> 00:16:10.520
первое и то что мы уже с вами неоднократно проделывали на наших демо и лабораторных работах

00:16:10.520 --> 00:16:19.720
это AWS Management Console используя UI консоли мы можем как загружать так и выгружать данные оттуда и

00:16:19.720 --> 00:16:27.680
полноценно видеть все необходимое связанное с сервисом Amazon S3. Следующая это AWS CLI более

00:16:27.680 --> 00:16:34.960
продвинутая опция когда мы можем написать некоторые скрипты либо набор команд и таким образом работать

00:16:34.960 --> 00:16:43.600
с объектами в сервисе Amazon S3. Далее еще более продвинутый вариант это использовать SDK software

00:16:43.600 --> 00:16:56.120
development kit. Самый популярный SDK для AWS это BOT03 он написан для языка программирования Python и вы

00:16:56.120 --> 00:17:02.000
можете используя высокоуровневый язык программирования написать некоторую логику когда код

00:17:02.000 --> 00:17:13.160
взаимодействует с сервисом Amazon S3. Мы двигаемся дальше и теперь рассмотрим интересный функционал

00:17:13.160 --> 00:17:23.160
называется Multi-Part Upload. Идея в том что для объектов большого размера мы можем ускорить

00:17:23.160 --> 00:17:30.360
загрузку в S3 bucket путем разделения ее на более мелкие части и загрузки этих частей индивидуально

00:17:30.360 --> 00:17:38.720
в S3. Далее после завершения загрузки всех частей она собирается на стороне S3 и этот файл становится

00:17:38.720 --> 00:17:46.840
доступен на стороне S3 bucket. Важные нюансы которые следует упомянуть минимальный размер файла

00:17:46.840 --> 00:17:54.960
который можно загрузить использование Multi-Part Upload это 5 мегабайтов. Если размер файла будет

00:17:54.960 --> 00:18:05.600
меньше то эту опция не сработает. Есть также такая рекомендация что файлы размером менее 100

00:18:05.600 --> 00:18:13.080
мегабайтов загружать рекомендуется цельным образом не применяя Multi-Part Upload. Если размер

00:18:13.080 --> 00:18:20.680
файла больше 100 мегабайтов в этом случае Multi-Part Upload может вам ускорить вашу загрузку в S3.

00:18:20.680 --> 00:18:31.520
Используя Multi-Part Upload у нас есть возможность загружать части параллельно это уменьшает время

00:18:31.520 --> 00:18:38.640
загрузки. Также в случае возникновения некоторых проблем с сетью если это один единственный файл то

00:18:38.640 --> 00:18:45.080
в случае проблем сетью загрузка полностью отменяется и все то что загружено она удаляется

00:18:45.080 --> 00:18:52.280
таким образом вам нужно будет начать загрузку еще раз. В случае когда мы это делаем через Multi-Part

00:18:52.280 --> 00:18:58.680
Upload все части которые были уже загружены их повторно загружать не нужно. Нужно загрузить

00:18:58.680 --> 00:19:11.000
перезагрузить только те части которые упали с ошибкой в связи с проблем с сетью. Также при

00:19:11.000 --> 00:19:18.040
загрузке через Multi-Part Upload у нас есть возможность паузить то есть временно

00:19:18.040 --> 00:19:27.720
приостанавливать загрузку и продолжать ее. Используя Multi-Part Upload мы можем загружать

00:19:27.720 --> 00:19:39.440
достаточно большие объекты до 5 терабайтов. Следующий функционал который достаточно

00:19:39.440 --> 00:19:47.240
интересный и позволяет нам большие объемы данных передавать в S3 Bucket это Transfer Acceleration.

00:19:47.240 --> 00:19:55.400
Идея ее в том что мы задействуем edge сервера от сервиса Amazon CloudFront таким образом мы не

00:19:55.400 --> 00:20:01.960
загружаем наши данные напрямую на S3 Bucket, а загружаем на ближайший кэш сервер. Таким

00:20:01.960 --> 00:20:08.320
образом загрузка происходит намного быстрее. Использовать Transfer Acceleration рекомендуется в

00:20:08.320 --> 00:20:18.360
случаях когда мы загружаем данные со всего мира в один централизованный Bucket на постоянной

00:20:18.360 --> 00:20:25.720
основе. Также рекомендуется использовать Transfer Acceleration когда мы гигабайты или терабайты

00:20:25.720 --> 00:20:36.240
данных загружаем в Bucket находящийся в другом регионе на постоянной основе. У нас будет отдельное

00:20:36.240 --> 00:20:42.160
демо посвященное Transfer Acceleration. Мы более подробнее разберем этот функционал и наглядно

00:20:42.160 --> 00:20:53.640
покажем какие преимущества оно дает. Следующие два примера связанные с семейством сервисов AWS Snow

00:20:53.640 --> 00:21:01.840
это Snowball и Snowmobile. Отличаются они размерами. Давайте сейчас подробнее остановимся на AWS

00:21:01.840 --> 00:21:10.320
Snowmobile. Это некий сервис который позволяет нам загружать несколько терабайтов или

00:21:10.320 --> 00:21:19.480
несколько десятков терабайтов данных на Amazon S3. Как это работает? Вы заходите в сервис, оставляете

00:21:19.480 --> 00:21:28.560
свою заявку и AWS выгружает вам физический чемоданчик который доезжает до вашего офиса и вы

00:21:28.560 --> 00:21:35.680
подключаете этот чемоданчик к локальной сети и загружаете в него все необходимые данные. Этот

00:21:35.680 --> 00:21:42.800
чемоданчик содержит необходимые для работы вычислительные мощности, а самое главное компоненты

00:21:42.800 --> 00:21:48.560
хранения, то есть жесткие диски. Как только вы загрузили намного быстрее через локальную

00:21:48.560 --> 00:21:56.640
сеть все необходимые данные вы ее запаковываете и отправляете обратно на адрес с которого он пришел.

00:21:56.640 --> 00:22:06.920
Как только он доезжает до ближайшего дата центра AWS она подключается к глобальной инфраструктуре и

00:22:06.920 --> 00:22:13.760
опять же через локальную сеть все эти данные загружается в S3 bucket на который вы указываете и

00:22:13.760 --> 00:22:20.680
ваши данные появляются в S3. Это отличная возможность если у вас большой объем данных и вы решили

00:22:20.680 --> 00:22:30.360
переезжать на AWS. Есть пример представим что у нас есть 10 петобайтов данных это 10 миллионов

00:22:30.360 --> 00:22:36.720
гигабайтов и если мы будем передавать это через интернет при этом у нас будет достаточно широкий

00:22:36.720 --> 00:22:44.520
канал загрузки данных в 10 гигабитов в секунду то на все про все нам необходимо будет порядка

00:22:44.520 --> 00:22:51.280
100 дней это может быть дорого и нерационально для бизнеса поэтому Snowmobile может быть отличным решением.

00:22:51.280 --> 00:23:02.960
Второй похожий сервис предназначенный для еще большего объема данных для передачи с локального

00:23:02.960 --> 00:23:16.440
дата центра AWS а именно в Amazon S3 это AWS Snowmobile это порядка 14 метровый контейнер который содержит

00:23:16.440 --> 00:23:23.540
в себе все необходимые вычислительные мощности по сути это маленький дата центр он привязан

00:23:23.540 --> 00:23:30.800
к нативно к своему грузовику и этот грузовик время после того как вы оставляете заявку в

00:23:30.800 --> 00:23:37.000
этом сервисе выезжает в сторону вашего офиса как только доезжает вы также подключаете к

00:23:37.000 --> 00:23:45.760
локальной сети и передаете ваши данные оно рассчитано на передачу петобайтов нескольких

00:23:45.760 --> 00:23:58.280
петобайтов и более данных с локального дата центра в облако AWS. Для того чтобы обслуживать

00:23:58.280 --> 00:24:09.360
подобный контейнер выделяется специальные люди они приезжают вместе с контейнером также у

00:24:09.360 --> 00:24:19.960
вас есть специальное наблюдение различные элементы безопасности вы можете отслеживать передвижение

00:24:19.960 --> 00:24:29.400
вашего контейнера через GPS все необходимое чтобы безопасно добраться до вашего локального

00:24:29.400 --> 00:24:39.040
офиса и в безопасности ваши данные доставить до ближайшего дата центра AWS. Мы с вами добрались

00:24:39.040 --> 00:24:46.160
до конца четвертой секции, вкратце пройдемся по основным моментам это то что есть функционал

00:24:46.160 --> 00:24:53.880
multi-part upload когда мы большие файлы с размером более 100 мегабайтов разделяем на несколько частей

00:24:53.880 --> 00:25:00.760
и отправляем в S3 по частям это дает некоторые преимущества другой вариант который позволяет

00:25:00.760 --> 00:25:07.440
ускорить загрузку ваших данных с локального дата центра в облако AWS это Transfer Acceleration

00:25:07.440 --> 00:25:17.360
который задействует edge сервера сервиса amazon cloud front и третье это то что есть семейство snow

00:25:17.360 --> 00:25:26.160
которое позволяет вам передавать еще большие объемы данных путем загрузки в некоторое физическое

00:25:26.160 --> 00:25:32.760
устройство которое приезжает к вам загружать туда ваши данные и отправляйте обратно в ближайшие

00:25:32.760 --> 00:25:40.160
дата центра AWS откуда оно потом через локальную сеть что намного быстрее загружает ваши данные

00:25:40.160 --> 00:25:51.200
сервис Amazon S3. Мы добрались с вами до пятой секции и здесь мы остановимся на некоторых нюансах

00:25:51.200 --> 00:26:04.960
какой же регион AWS выбрать для хостинга нашей архитектуры. При выборе регионе первым делом

00:26:04.960 --> 00:26:12.960
необходимо проверить есть ли некоторые положения либо регуляторные требования которые накладывают

00:26:12.960 --> 00:26:23.080
ограничения на хранение ваших данных вне вашей страны либо похожие нюансы нужно проверить

00:26:23.080 --> 00:26:32.760
действительно ли этот регион подходит вам с точки зрения закона вы не нарушаете закон в случае

00:26:32.760 --> 00:26:41.400
если есть подобные ограничения и если есть AWS регион в вашей стране либо в стране где вы не

00:26:41.400 --> 00:26:49.120
будете нарушать закон то следует использовать ее. Второй момент который также нужно учитывать это

00:26:49.120 --> 00:26:58.880
расстояние до ваших потенциальных пользователей даже небольшие изменения точнее отличия в скорости

00:26:58.880 --> 00:27:08.040
передачи данных оно может сильно отразиться на опыте использования вашим продуктом вашими

00:27:08.040 --> 00:27:16.200
пользователями поэтому необходимо проверить какой регион находится ближайшие до ваших потенциальных

00:27:16.200 --> 00:27:26.560
пользователей. Следующий пункт на который следует обратить внимание это доступность

00:27:26.560 --> 00:27:36.280
сервисов и функционала этих сервисов в выбранном вами регионе все новинки все новые сервисы и

00:27:36.280 --> 00:27:44.040
функционал сервисов в первую очередь появляется на первом основном регионе это регион Норс-Вирджиния

00:27:44.040 --> 00:27:51.960
далее по истечении некоторого времени после прохождения некоторых внутренних тестов новые

00:27:51.960 --> 00:27:57.320
сервисы новый функционал начинает распространяться на другие регионы таким образом есть некоторые

00:27:57.320 --> 00:28:05.360
регионы до которых обновление доходит несколько месяцев следует это учитывать есть на уровне

00:28:05.360 --> 00:28:12.640
каждого сервиса в документации так называемые AWS region table где прописывается доступность тех или

00:28:12.640 --> 00:28:23.720
иных сервисов также функционала в определенном регионе. Последний но немаловажный пункт на

00:28:23.720 --> 00:28:33.240
который стоит обратить внимание это cost то есть стоимость использования сервисов AWS в

00:28:33.240 --> 00:28:39.600
конкретном выбранном регионе. Цены отличаются здесь определенной логики ценообразования нет

00:28:39.600 --> 00:28:49.400
поэтому необходимо проверить в интересующих вас регионах цены на интересующие сервисы на тот

00:28:49.400 --> 00:29:04.160
функционал который дополнительно оплачивается и прикинуть действительно ли эти цены они вас устраивают. Мы с

00:29:04.160 --> 00:29:10.280
вами добрались до конца пятой секции вкратце остановились на четырех важных пунктах на

00:29:10.280 --> 00:29:20.960
которые следует обратить внимание при выборе AWS региона. Это была последняя секция на этом мы

00:29:20.960 --> 00:29:33.840
завершаем вторую часть темы посвященные хранению в облаке AWS мы сегодня рассмотрели какие классы

00:29:33.840 --> 00:29:43.320
хранения бывают у сервиса Amazon S3 рассмотрели нюансы передачи данных в и из S3 бакетов какие

00:29:43.320 --> 00:29:51.440
сервисы и функционал позволяет нам это делать более оптимально также рассмотрели кейсы связанные

00:29:51.440 --> 00:30:00.120
с выбором региона для хостинга нашей IT инфраструктуры здесь вы можете видеть ссылки

00:30:00.120 --> 00:30:08.720
на некоторые полезные источники это документация связанная с сервисом Amazon S3 также эти страницы

00:30:08.720 --> 00:30:18.120
вы можете легко найти вбив необходимые ключевые слова в поисковик на этом мы подошли к концу

00:30:18.120 --> 00:30:26.920
нашей сегодняшней лекции я очень надеюсь что вы получили более полные представления у сервиса

00:30:26.920 --> 00:30:37.320
Amazon S3 мы рассмотрели более подробнее этот сервис напоминаю что у нас будет на этой неделе еще

00:30:37.320 --> 00:30:44.960
демо активность а также лаборатурная работа связанная с сервисом Amazon S3 спасибо за внимание

00:30:44.960 --> 00:30:57.560
увидимся с вами на следующих наших активностях
