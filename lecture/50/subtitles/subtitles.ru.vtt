WEBVTT

00:00:00.000 --> 00:00:07.120
Добрый день, уважаемые студенты! Я рад вас
всех видеть на очередной лекции. Тема сегодняшней

00:00:07.120 --> 00:00:14.920
лекции - это сервисы хранения AWS. Сегодняшняя
лекция является продолжением предыдущей лекции,

00:00:14.920 --> 00:00:20.720
вторая часть. Мы продолжим говорить о
сервисе Amazon S3. Итак, давайте начнем.

00:00:20.720 --> 00:00:28.360
Сегодняшняя лекция состоит из трех частей.
В первой секции мы поговорим про некоторые

00:00:28.360 --> 00:00:34.920
нюансы хранения данных в сервисе Amazon S3, какие
 классы хранения бывают, за что мы платим и так

00:00:34.920 --> 00:00:42.720
далее. Во второй секции мы поговорим про нюансы
связанные с переносом данных в и из Amazon S3

00:00:42.720 --> 00:00:52.240
Bucket. И в последней секции мы поговорим о том,
как правильно выбирать регион, какие нюансы есть,

00:00:52.240 --> 00:00:57.640
на что нужно обратить внимание. Также на этой
неделе будет специальная Демо сессия. Она посвящена

00:00:57.640 --> 00:01:05.200
функционалу Transfer Acceleration от сервиса Amazon
S3. Мы ее подробно разберем и наглядно посмотрим,

00:01:05.200 --> 00:01:12.560
как это работает. Также на этой неделе у нас
запланирована лабораторная работа. Будут две

00:01:12.560 --> 00:01:20.960
активности - введение и разбор лабораторной работы.
Это - Challenge Lab, где в задании будет минимальное

00:01:20.960 --> 00:01:26.240
количество деталей и вам необходимо будет на
основе тех знаний, которые вы получили на лекциях,

00:01:26.240 --> 00:01:33.400
а также на предыдущем Guided Lab, применить
эти знания для решения конкретной бизнес-задачи.

00:01:33.400 --> 00:01:44.360
Итак, поехали. Мы с вами начинаем третью секцию.
Из-за сквозной нумерации сегодня

00:01:44.360 --> 00:01:50.680
будет третья секция. Первые две секции мы прошли
на предыдущей неделе. Итак, мы сейчас разберем

00:01:50.680 --> 00:01:57.240
нюансы, связанные с хранением данных в сервисе
Amazon S3. Начнем мы с существующих storage classes,

00:01:57.240 --> 00:02:03.080
то есть классов хранения. Самый первый, самый 
популярный и часто используемый вариант - это

00:02:03.080 --> 00:02:11.400
S3 Standard. Он идеально подходит для тех данных, 
которые должны быть доступны всегда онлайн.

00:02:11.400 --> 00:02:21.160
При этом вы оплачиваете только за то, что вы
используете и хранение достаточно надежное, как

00:02:21.160 --> 00:02:32.120
мы говорили ранее, 11 девяток. Следующий класс
хранения - это S3 Standard IA, Infrequently Accessed.

00:02:32.120 --> 00:02:41.200
Оно немного дешевле с точки зрения хранения,
но необходимо оплачивать отдельно за услуги

00:02:41.200 --> 00:02:49.600
извлечения ваших данных. Если ваши данные не
часто запрашиваются, то вы фактически не будете

00:02:49.600 --> 00:02:57.040
оплачивать за извлечение данных. Соответственно,
в целом хранение в этом классе будет для вас более

00:02:57.040 --> 00:03:08.320
выгодным решением. Следующий класс, который
еще выгоднее, S3 One Zone IA (Infrequently Accessed).

00:03:08.320 --> 00:03:18.080
Он идеально подходит для тех данных, которые мы
храним на более долгий период, которые не так часто

00:03:18.080 --> 00:03:24.920
запрашиваются и данные, которые мы можем себе
позволить частично потерять, это не так критично,

00:03:24.920 --> 00:03:31.200
либо это могут быть те данные, которые можно
легко восстановить. В этом случае, мы оплачиваем еще

00:03:31.200 --> 00:03:41.120
меньше и отличие в том, что данные хранятся
только на одной availability zone, соответственно,

00:03:41.120 --> 00:03:54.440
durability здесь чуть ниже, тогда как S3
Standard и S3 Standard IA надежны на 11 девяток.

00:03:54.440 --> 00:04:04.120
Следующие два класса хранения больше относятся
к архивным данным - это Amazon S3 Glacier or Deep

00:04:04.120 --> 00:04:14.800
Archive. Эти классы хранения идеально подходят для
тех данных, которые мы сохраняем на долго,

00:04:14.800 --> 00:04:20.920
по тем или иным причинам, должны хранить
некоторый период времени и хранение должно быть

00:04:20.920 --> 00:04:28.160
дешевым. Маловероятно, что мы эти данные будем
запрашивать, поэтому и извлечение данных из этих

00:04:28.160 --> 00:04:36.280
классов хранения достаточно трудозатратно с
точки зрения времени. Например, в Amazon S3 Glacier

00:04:36.280 --> 00:04:41.560
есть три варианта извлечения данных. Самый 
первый и самый быстрый, но тем не менее самый

00:04:41.560 --> 00:04:47.800
дорогой - это Expedited, когда мы данные
можем излечь в течение 1-5 минуты. Далее, есть

00:04:47.800 --> 00:04:54.920
Standard Retrieval, это когда мы данные извлекаем 
в течение 3-5 часов, она немного дешевле.

00:04:54.920 --> 00:05:01.480
Самый дешевый вариант излечения - это Bulk
Retrievals, когда мы данные получаем в течение

00:05:01.480 --> 00:05:10.760
5-12 часов. Это самое дешевое с точки зрения
оплаты за извлечение, но тем не менее больше

00:05:10.760 --> 00:05:19.040
всего времени нужно будет ждать. Если мы говорим
про Glacier Deep Archive, то оно еще больше дешевле,

00:05:19.040 --> 00:05:30.640
чем Glacier, то есть данные, которые мы совсем не
планируем извлекать, можно сохранять в Glacier Deep

00:05:30.640 --> 00:05:40.720
Archive. Оно также в себе содержит надежность 11
девяток и данные реплицируются на как минимум три

00:05:40.720 --> 00:05:48.800
availability zone. Если мы говорим про извлечение
данных, то для Glacier Deep Archive данные

00:05:48.800 --> 00:05:59.240
извлекаются в течение 12 часов. Последний класс
хранения - Amazon S3 Intelligent Tiering. В этом

00:05:59.240 --> 00:06:06.760
случае мы оплачиваем дополнительную сумму
за работу этого класса хранения. Идея этого класса

00:06:06.760 --> 00:06:16.160
хранения в том, что мы забываем про существование
классов хранения и передаем эту работу самому AWS.

00:06:16.160 --> 00:06:28.120
AWS уже на основе логов обращения к файлам
индивидуально для каждого файла подбирает

00:06:28.120 --> 00:06:36.320
подходящий класс хранения. При этом, если по тем
или иным причинам определенный файл был запрошен

00:06:36.320 --> 00:06:43.840
чаще или наоборот реже, чем ожидалось, то перенос
с одного класса хранения на другой класс хранения

00:06:43.840 --> 00:06:51.400
не оплачивается в случае использования Amazon 
S3 Intelligent Tiering. Однозначно утверждать,

00:06:51.400 --> 00:06:58.800
что тот или иной класс хранения лучше, не совсем
 верно, так как в зависимости от вашей бизнес

00:06:58.800 --> 00:07:04.720
задачи тот или иной класс хранения может лучше
для вас подходить, поэтому нужно смотреть на бизнес

00:07:04.720 --> 00:07:17.960
кейс. То, что существует Amazon S3 Intelligent
Tiering класс хранения это хорошо. AWS старается по

00:07:17.960 --> 00:07:24.080
возможности помогать бизнесу, чтобы он не отвлекался
на технические задачи и смог сконцентрироваться

00:07:24.080 --> 00:07:31.920
на бизнес задачах. Но мы как владельцы данных
лучше знаем как эти данные будут запрашиваться,

00:07:31.920 --> 00:07:39.640
мы знаем что при возникновении изменений как
может поменяться частота обращения к этим файлам.

00:07:39.640 --> 00:07:50.420
Поэтому разработана специальная функция Amazon
S3 Lifecycle Policies. Идея - мы можем настроить

00:07:50.420 --> 00:08:02.200
policy для нашего бакета и согласно этому policy
на уровне каждого объекта класс хранения будет

00:08:02.200 --> 00:08:10.920
изменяться в зависимости от этого policy. Например,
мы говорим что у нас в систему загружается некие

00:08:10.920 --> 00:08:20.840
.mp4 видео файл и первые 30 дней она активно
запрашивается используется, поэтому наиболее

00:08:20.840 --> 00:08:31.760
рационально его хранить в классе хранения S3
standard. Далее, уже после 30 дней и до 60 дней файл

00:08:31.760 --> 00:08:39.960
потенциально может быть запрошен, но это достаточно
редкий кейс, поэтому мы можем для уменьшения наших

00:08:39.960 --> 00:08:47.520
затрат на хранение перенести ее на следующий
класс хранения S3 Standard IA. Далее, уже

00:08:47.520 --> 00:08:55.920
после двух месяцев загрузки конкретно этого
файла этот файл определенно использоваться не

00:08:55.920 --> 00:09:03.160
будет и мы в течение года возможно по некоторым
внутренним положениям компании должны хранить ее,

00:09:03.160 --> 00:09:14.040
в случае если оно нам понадобится. Поэтому 
после 60 дней она переходит в класс хранения

00:09:14.040 --> 00:09:21.680
Amazon S3 Glacier, чтобы снизить затраты на
хранение, зная, что запрашивать не будем. После года

00:09:21.680 --> 00:09:32.240
использования этот файл нам не нужен и мы безопасно
можем его удалить. Таким образом Lifecycle Policies

00:09:32.240 --> 00:09:42.920
позволяет нам, зная как наши данные будут
запрашиваться в Amazon S3, задать логику переноса

00:09:42.920 --> 00:09:52.240
между классами хранения и эта логика, Lifecycle
policy, будет накладываться на каждый объект

00:09:52.240 --> 00:10:03.000
в момент ее загрузки. Давайте теперь подробнее
остановимся с вопросами оплаты за использование

00:10:03.000 --> 00:10:10.600
сервиса Amazon S3. Этот слайд посвящен тем пунктам,
когда мы оплачиваем за использование сервиса.

00:10:10.600 --> 00:10:18.440
Это связано с объемом данных, которые мы храним.
Есть определенный тариф за каждый гигабайт

00:10:18.440 --> 00:10:26.360
хранения и мы оплачиваем только за то, что
мы используем. Представим, что мы храним один

00:10:26.360 --> 00:10:32.400
единственный файл размером 1 гигабайт в нашем
единственном S3 бакете. Загрузили его на три дня,

00:10:32.400 --> 00:10:41.120
после чего удалили. В конце месяца придет счет
на оплату за 1 гигабайт объем данных, но ровно за

00:10:41.120 --> 00:10:49.160
три дня. За оставшиеся 27 дней месяца так как
Amazon S3 ничего не хранила мы не оплачиваем.

00:10:49.160 --> 00:10:57.320
Следует также учитывать, что цены могут отличаться
в зависимости от региона и в зависимости от класса

00:10:57.320 --> 00:11:06.360
хранения. Второй пункт, где нам необходимо
оплачивать за использование сервиса Amazon S3 - это

00:11:06.360 --> 00:11:17.720
перенос данных от S3 бакета. То есть представим
случай, когда мы с S3 бакета в регионе North Virginia

00:11:17.720 --> 00:11:26.760
переносим данные в другой регион, например, 
Oregon. В этом случае это воспринимается

00:11:26.760 --> 00:11:32.480
как Transfer OUT, поэтому за этот объем данных
необходимо будет некоторую сумму оплатить.

00:11:32.480 --> 00:11:41.960
Это также относится к кейсу, когда мы с S3
бакета загружаем некий объем данных на локальный

00:11:41.960 --> 00:11:58.840
компьютер. Третье - мы оплачиваем также все API
вызовы на Amazon S3. Это могут быть запросы, когда

00:11:58.840 --> 00:12:06.680
мы передаем файл на хранение, когда мы копируем 
ее, запрашиваем список объектов, хранящихся

00:12:06.680 --> 00:12:16.280
в определенном S3 бакете и т.д. Это также относится
к lifecycle transition. Мы помним, что у нас есть

00:12:16.280 --> 00:12:23.880
функционал lifecycle policy, который в определенные
промежутки времени индивидуально для каждого

00:12:23.880 --> 00:12:28.760
объекта переносится с одного класса хранения
на другой класс хранения, либо удаляет этот файл.

00:12:28.760 --> 00:12:35.680
Так вот каждый переход необходимо отдельно
оплачивать. Эти суммы относительно небольшие.

00:12:35.680 --> 00:12:44.760
Но важно перед началом использования
Amazon S3, если у вас очень большой объем данных,

00:12:44.760 --> 00:12:53.840
рекомендуется более подробно изучить за что мы
оплачиваем в сервисе Amazon S3. Также рассчитать

00:12:53.840 --> 00:13:02.080
стоимость, которую мы будем ежемесячно оплачивать,
будь то приблизительные суммы. И если эти суммы

00:13:02.080 --> 00:13:10.388
нам подходят, мы можем начинать
работать с этим сервисом, зная что никаких

00:13:10.412 --> 00:13:18.720
дополнительных оплат точно не будет.
Теперь мы остановимся на тех пунктах,

00:13:18.720 --> 00:13:27.040
когда мы не оплачиваем при использовании сервиса
Amazon S3. Первый пункт - когда мы с интернета

00:13:27.040 --> 00:13:36.400
загружаем данные в S3 бакет. Как я говорил
ранее, политика такая, что AWS с радостью принимает

00:13:36.400 --> 00:13:41.920
данные от вас, для того чтобы ее накапливать,
но при этом когда вы эти данные начинаете

00:13:41.920 --> 00:13:46.680
извлекать вам необходимо производить некоторую 
оплату - это применимо ко многим сервисам.

00:13:46.680 --> 00:13:55.760
Мы также не оплачиваем за перенос данных между 
двумя бакетами, если они находятся в одном и

00:13:55.760 --> 00:14:02.760
том же регионе. Также мы не оплачиваем за перенос
данных с Amazon S3 на любой другой сервис, который

00:14:02.760 --> 00:14:08.680
также находится в одном регионе. Самый популярный
кейс - это использование сервиса Amazon S3 в вашем

00:14:08.680 --> 00:14:16.080
приложении и ваше приложение хостится на Amazon 
EC2 инстансах. В этом случае если Amazon S3 и

00:14:16.080 --> 00:14:24.400
Amazon EC2 находятся в одном и том же регионе, за
трансфер данных не будем оплачивать. Другой кейс -

00:14:24.400 --> 00:14:33.880
есть сервис Amazon CloudFront, который является
CDN, то есть Content Delivery Network. Он нативно

00:14:33.880 --> 00:14:43.160
интегрируется с Amazon S3, чтобы быстро доставлять 
данные вашим пользователям по всему миру.

00:14:43.160 --> 00:14:47.359
Так вот во время интеграции Amazon
S3 с Amazon CloudFront при передаче

00:14:47.383 --> 00:14:51.520
данных с Amazon S3 на Amazon
CloudFront для кэширования, мы никаких

00:14:51.520 --> 00:15:00.880
оплат не производим. И последнее - на те запросы,
которые связаны с удалением объектов в S3 бакете,

00:15:00.880 --> 00:15:09.920
а также отмененные действия, не учитываются и за
эти вызовы API сервиса Amazon S3 мы не оплачиваем.

00:15:09.920 --> 00:15:17.920
Мы с вами добрались до конца третьей секции.
Давайте остановимся на самых важных моментах.

00:15:17.920 --> 00:15:24.800
Мы рассмотрели какие классы хранения бывают.
Познакомились с функционалом LifeCycle Policy.

00:15:24.800 --> 00:15:31.880
Также рассмотрели все кейсы, когда мы
оплачиваем за использование сервиса Amazon S3 и

00:15:31.880 --> 00:15:42.000
когда оплачивать ничего не нужно. Двигаемся к
следующей секции. Четвертая секция - здесь мы

00:15:42.000 --> 00:15:51.120
будем говорить про все нюансы, связанные с
трансфером данных из и в Amazon S3 бакеты.

00:15:55.120 --> 00:16:04.720
Давайте разберем те методы с применением которых
мы можем загружать наши данные в Amazon S3.

00:16:04.720 --> 00:16:10.520
Самое первое и то что мы уже с вами неоднократно
проделывали на наших Демо и лабораторных работах -

00:16:10.520 --> 00:16:19.720
это AWS Management Console. Используя UI Console,
мы можем загружать и выгружать данные оттуда и

00:16:19.720 --> 00:16:27.680
полноценно видеть все необходимое, связанное с
сервисом Amazon S3. Следующая - это AWS CLI, более

00:16:27.680 --> 00:16:34.960
продвинутая опция, когда мы можем написать 
скрипты либо набор команд и таким образом работать

00:16:34.960 --> 00:16:43.600
с объектами в сервисе Amazon S3. Далее, еще более
продвинутый вариант - использовать SDK - Software

00:16:43.600 --> 00:16:56.120
Development Kit. Самый популярный SDK для AWS - это
Boto3. Он написан для языка программирования Python.

00:16:56.120 --> 00:17:02.000
Используя высокоуровневый язык программирования,
вы можете написать некоторую логику, когда код

00:17:02.000 --> 00:17:13.160
взаимодействует с сервисом Amazon S3. Мы двигаемся
дальше и теперь рассмотрим интересный функционал

00:17:13.160 --> 00:17:23.160
- Multipart Upload. Идея в том, что для
объектов большого размера мы можем ускорить

00:17:23.160 --> 00:17:30.360
загрузку в S3 bucket путем разделения ее на более
мелкие части и загрузки этих частей индивидуально

00:17:30.360 --> 00:17:38.720
в Amazon S3. Далее, после завершения загрузки
всех частей, она собирается на Amazon S3 и этот

00:17:38.720 --> 00:17:42.488
файл становится доступен
на стороне Amazon S3 bucket.

00:17:42.512 --> 00:17:46.840
Важные нюансы, которые следует
упомянуть: минимальный размер файла,

00:17:46.840 --> 00:17:54.960
который можно загрузить с использованием Multipart
Upload это 5 мегабайтов. Если размер файла будет

00:17:54.960 --> 00:18:05.600
меньше, то эта опция не сработает. Есть также
такая рекомендация, что файлы размером менее 100

00:18:05.600 --> 00:18:13.080
мегабайтов загружать рекомендуется цельным
образом, не применяя Multipart Upload. Если размер

00:18:13.080 --> 00:18:20.680
файла больше 100 мегабайтов, в этом случае Multipart
Upload может вам ускорить вашу загрузку в Amazon S3.

00:18:20.680 --> 00:18:31.520
Используя Multipart Upload у нас есть возможность
загружать части параллельно, это уменьшает время

00:18:31.520 --> 00:18:38.640
загрузки. Также если это один единственный
файл, то в случае возникновения проблем с

00:18:38.640 --> 00:18:45.080
сетью, загрузка полностью отменяется
и все то, что загружено удаляется.

00:18:45.080 --> 00:18:52.280
Таким образом, вам нужно будет начать загрузку еще
раз. В случае, когда мы это делаем через Multipart

00:18:52.280 --> 00:18:58.680
Upload, все части, которые были уже
загружены повторно загружать не нужно. Нужно

00:18:58.680 --> 00:19:11.000
перезагрузить только те части, которые упали
с ошибкой в связи с проблем с сетью. Также при

00:19:11.000 --> 00:19:18.040
загрузке через Multipart Upload у нас есть
возможность временно приостанавливать

00:19:18.040 --> 00:19:27.720
загрузку и продолжать ее.
Используя Multipart Upload мы можем загружать

00:19:27.720 --> 00:19:39.440
достаточно большие объекты до 5 терабайтов.
Следующий функционал, который достаточно

00:19:39.440 --> 00:19:47.240
интересный и позволяет нам передавать большие 
объемы данных в S3 Bucket - Transfer Acceleration.

00:19:47.240 --> 00:19:55.400
Идея ее в том, что мы задействуем edge сервера
от сервиса Amazon CloudFront. Таким образом мы не

00:19:55.400 --> 00:20:01.960
загружаем наши данные напрямую на S3 Bucket, а
загружаем на ближайший кэш сервер. Следовательно

00:20:01.960 --> 00:20:08.320
загрузка происходит намного быстрее.
Использовать Transfer Acceleration рекомендуется

00:20:08.320 --> 00:20:18.360
в случаях, когда мы загружаем данные со всего
мира в один централизованный Bucket на постоянной

00:20:18.360 --> 00:20:25.720
основе. Также рекомендуется использовать Transfer
Acceleration, когда мы гигабайты или терабайты

00:20:25.720 --> 00:20:36.240
данных загружаем в Bucket находящийся в другом
регионе на постоянной основе. У нас будет отдельное

00:20:36.240 --> 00:20:42.160
Демо посвященное Transfer Acceleration. Мы более
подробнее разберем этот функционал и наглядно

00:20:42.160 --> 00:20:53.640
покажем какие преимущества он дает. Следующие два
примера, связанные с семейством сервисов AWS Snow

00:20:53.640 --> 00:21:01.840
- это AWS Snowball и AWS Snowmobile. Отличаются они
размерами. Давайте сейчас подробнее остановимся на

00:21:01.840 --> 00:21:10.320
AWS Snowball. Это некий сервис, который
позволяет нам загружать несколько терабайтов или

00:21:10.320 --> 00:21:19.480
несколько десятков терабайтов данных на Amazon S3.
Как это работает? Вы заходите в сервис, оставляете

00:21:19.480 --> 00:21:28.560
свою заявку и AWS выгружает вам физический
чемоданчик, который доезжает до вашего офиса.

00:21:28.560 --> 00:21:35.680
Вы подключаете этот чемоданчик к локальной
сети и загружаете в него все необходимые данные.

00:21:35.680 --> 00:21:42.800
Этот чемоданчик содержит необходимые для работы
вычислительные мощности, а самое главное компоненты

00:21:42.800 --> 00:21:48.560
хранения, то есть жесткие диски. Как только
вы загрузили намного быстрее через локальную

00:21:48.560 --> 00:21:56.640
сеть все необходимые данные вы ее запаковываете и
отправляете обратно на адрес, с которого он пришел.

00:21:56.640 --> 00:22:06.920
Как только он доезжает до ближайшего дата-центра
AWS, она подключается к глобальной инфраструктуре

00:22:06.920 --> 00:22:13.760
и опять же через локальную сеть все эти данные
загружаются в S3 bucket, на который вы указываете

00:22:13.760 --> 00:22:20.680
и ваши данные появляются в S3. Это отличная
возможность, если у вас большой объем данных и вы

00:22:20.680 --> 00:22:30.360
решили переезжать на AWS. Например, представим,
у нас есть 10 петабайтов данных, это 10 миллионов

00:22:30.360 --> 00:22:36.720
гигабайтов. Если мы будем передавать это через
интернет, при этом у нас будет достаточно широкий

00:22:36.720 --> 00:22:44.520
канал загрузки данных в 10 гигабитов в секунду,
то нам необходимо будет порядка 100 дней.

00:22:44.520 --> 00:22:51.280
Это может быть дорого и нерационально для бизнеса,
поэтому AWS Snowball может быть отличным решением.

00:22:51.280 --> 00:23:02.960
Второй похожий сервис, предназначенный для еще
большего объема данных для передачи с локального

00:23:02.960 --> 00:23:16.440
дата-центра AWS, а именно в Amazon S3 - это
AWS Snowmobile. Это порядка 14 метровый контейнер,

00:23:16.440 --> 00:23:23.540
который содержит в себе все необходимые
вычислительные мощности. По сути это маленький

00:23:23.540 --> 00:23:30.800
дата-центр, привязан к нативно к своему грузовику
и этот грузовик после того как вы оставляете заявку в

00:23:30.800 --> 00:23:37.000
этом сервисе выезжает в сторону вашего офиса.
Как только доезжает, вы также подключаете к

00:23:37.000 --> 00:23:45.760
локальной сети и передаете ваши данные.
Оно рассчитано на передачу нескольких

00:23:45.760 --> 00:23:58.280
петобайтов и более данных с локального дата-центра 
в облако AWS. Для того чтобы обслуживать

00:23:58.280 --> 00:24:09.360
подобный контейнер, выделяются специальные люди.
Они приезжают вместе с контейнером. Также у

00:24:09.360 --> 00:24:19.960
вас есть специальное наблюдение, различные элементы
безопасности. Вы можете отслеживать передвижение

00:24:19.960 --> 00:24:29.400
вашего контейнера через GPS, все необходимое,
чтобы безопасно добраться до вашего локального

00:24:29.400 --> 00:24:39.040
офиса и в безопасности ваши данные доставить до
ближайшего дата-центра AWS. Мы с вами добрались

00:24:39.040 --> 00:24:46.160
до конца четвертой секции. Вкратце пройдемся
по основным моментам. Есть функционал

00:24:46.160 --> 00:24:53.880
multipart upload, когда мы большие файлы с размером
более 100 мегабайтов разделяем на несколько частей

00:24:53.880 --> 00:25:00.760
и отправляем в Amazon S3 по частям. Это дает
некоторые преимущества. Другой вариант, который

00:25:00.760 --> 00:25:07.440
позволяет ускорить загрузку данных с локального
дата-центра в облако AWS - это Transfer Acceleration,

00:25:07.440 --> 00:25:17.360
который задействует edge сервера сервиса Amazon 
CloudFront. Третье - есть семейство AWS Snow,

00:25:17.360 --> 00:25:26.160
которое позволяет вам передавать еще большие
объемы данных путем загрузки в некоторое физическое

00:25:26.160 --> 00:25:32.760
устройство, которое приезжает к вам, вы загружаете
туда ваши данные и отправляете обратно в ближайший

00:25:32.760 --> 00:25:40.160
дата-центр AWS, откуда оно потом через локальную
сеть, что намного быстрее, загружает ваши данные

00:25:40.160 --> 00:25:51.200
сервис Amazon S3. Мы добрались с вами до пятой
секции и здесь мы остановимся на некоторых нюансах

00:25:51.200 --> 00:26:04.960
какой же регион AWS выбрать для хостинга нашей
архитектуры. При выборе региона первым делом

00:26:04.960 --> 00:26:12.960
необходимо проверить, есть ли некоторые положения
либо регуляторные требования, которые накладывают

00:26:12.960 --> 00:26:23.080
ограничения на хранение ваших данных вне
вашей страны, либо похожие нюансы. Нужно проверить

00:26:23.080 --> 00:26:32.760
действительно ли этот регион подходит
вам с точки зрения закона. В случае,

00:26:32.760 --> 00:26:41.400
если есть подобные ограничения и если есть AWS 
регион в вашей стране, либо в стране, где вы не

00:26:41.400 --> 00:26:49.120
будете нарушать закон, то следует использовать ее.
Второй момент, который также нужно учитывать, это

00:26:49.120 --> 00:26:58.880
расстояние до ваших потенциальных пользователей.
Даже небольшие отличия в скорости

00:26:58.880 --> 00:27:08.040
передачи данных может сильно отразиться на
опыте использования вашего продукта вашими

00:27:08.040 --> 00:27:16.200
пользователями. Поэтому необходимо проверить
ближайший до ваших потенциальных пользователей

00:27:16.200 --> 00:27:26.560
регион. Следующий пункт, на который
следует обратить внимание - это доступность

00:27:26.560 --> 00:27:36.280
сервисов и функционала этих сервисов в
выбранном вами регионе. Все новые сервисы и

00:27:36.280 --> 00:27:44.040
функционал сервисов в первую очередь появляется на
первом основном регионе - это регион North Virginia.

00:27:44.040 --> 00:27:51.960
Далее по истечении некоторого времени, после
прохождения некоторых внутренних тестов, новые

00:27:51.960 --> 00:27:57.320
сервисы, новый функционал начинает распространяться
на другие регионы. Таким образом, есть некоторые

00:27:57.320 --> 00:28:05.360
регионы до которых обновление доходит несколько 
месяцев, следует это учитывать. На уровне

00:28:05.360 --> 00:28:12.640
каждого сервиса в документации есть так называемый
AWS Region Table, где прописывается доступность

00:28:12.640 --> 00:28:23.720
тех или иных сервисов, также функционала в
определенном регионе. Последний, но немаловажный

00:28:23.720 --> 00:28:33.240
пункт, на который стоит обратить внимание - это
cost, то есть стоимость использования сервисов AWS

00:28:33.240 --> 00:28:39.600
в конкретном выбранном регионе. Цены различаются,
здесь определенной логики ценообразования нет,

00:28:39.600 --> 00:28:49.400
поэтому в интересующих вас регионах необходимо
проверить цены на интересующие сервисы,

00:28:49.400 --> 00:29:04.160
функционал, который дополнительно оплачивается и
прикинуть действительно ли эти цены вас устраивают.

00:29:04.160 --> 00:29:10.280
Мы с вами добрались до конца пятой секции.
Вкратце остановились на четырех важных пунктах,

00:29:10.280 --> 00:29:20.960
на которые следует обратить внимание при выборе
AWS региона. Это была последняя секция, на этом мы

00:29:20.960 --> 00:29:33.840
завершаем вторую часть темы посвященной хранению
в облаке AWS. Мы сегодня рассмотрели какие классы

00:29:33.840 --> 00:29:43.320
хранения бывают у сервиса Amazon S3, рассмотрели
нюансы передачи данных в и из S3 бакетов, какие

00:29:43.320 --> 00:29:51.440
сервисы и функционал позволяет нам это делать более
 оптимально, также рассмотрели кейсы, связанные

00:29:51.440 --> 00:30:00.120
с выбором региона для хостинга нашей IT
инфраструктуры. Здесь вы можете видеть ссылки

00:30:00.120 --> 00:30:08.720
на некоторые полезные источники - это документация
связанная с сервисом Amazon S3. Также эти страницы

00:30:08.720 --> 00:30:18.120
вы можете легко найти написав необходимые ключевые
слова в поисковик. На этом мы подошли к концу

00:30:18.120 --> 00:30:26.920
нашей сегодняшней лекции. Я очень надеюсь, что
вы получили более полные представления о сервисе

00:30:26.920 --> 00:30:37.320
Amazon S3. Мы рассмотрели более подробнее этот
сервис. Напоминаю, что у нас будет на этой неделе

00:30:37.320 --> 00:30:47.632
еще Демо активность, а также лабораторная
работа, связанная с сервисом Amazon S3.

00:30:47.656 --> 00:30:50.560
Спасибо за внимание, увидимся с
вами на следующих наших активностях.
