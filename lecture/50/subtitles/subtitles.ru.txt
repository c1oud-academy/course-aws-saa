Добрый день, уважаемые студенты! 
Я рад вас всех видеть на очередной лекции.
Тема сегодняшней лекции - это сервисы хранения AWS.
Сегодняшняя лекция является продолжением предыдущей лекции, вторая часть.
Мы продолжим говорить о сервисе Amazon S3.
Итак, давайте начнем.
Сегодняшняя лекция состоит из трех частей.
В первой секции мы поговорим про некоторые нюансы хранения данных в сервисе Amazon S3, какие классы хранения бывают, за что мы платим и так далее.
Во второй секции мы поговорим про нюансы связанные с переносом данных в и из Amazon S3 Bucket.
И в последней секции мы поговорим о том, как правильно выбирать регион, какие нюансы есть, на что нужно обратить внимание.
Также на этой неделе будет специальная Демо сессия.
Она посвящена функционалу Transfer Acceleration от сервиса Amazon S3.
Мы ее подробно разберем и наглядно посмотрим, как это работает.
Также на этой неделе у нас запланирована лабораторная работа.
Будут две активности - введение и разбор лабораторной работы.
Это - Challenge Lab, где в задании будет минимальное количество деталей и вам необходимо будет на основе тех знаний, которые вы получили на лекциях, а также на предыдущем Guided Lab, применить эти знания для решения конкретной бизнес-задачи.
Итак, поехали.
Мы с вами начинаем третью секцию.
Из-за сквозной нумерации сегодня будет третья секция.
Первые две секции мы прошли на предыдущей неделе.
Итак, мы сейчас разберем нюансы, связанные с хранением данных в сервисе Amazon S3.
Начнем мы с существующих storage classes, то есть классов хранения.
Самый первый, самый популярный и часто используемый вариант - это S3 Standard.
Он идеально подходит для тех данных, которые должны быть доступны всегда онлайн.
При этом вы оплачиваете только за то, что вы используете и хранение достаточно надежное, как мы говорили ранее, 11 девяток.
Следующий класс хранения - это S3 Standard IA, то есть Infrequently Accessed.
Оно немного дешевле с точки зрения хранения, но необходимо оплачивать отдельно за услуги извлечения ваших данных.
Если ваши данные не часто запрашиваются, то вы фактически не будете оплачивать часть за извлечение данных.
Соответственно, в целом хранение в этом классе будет для вас более выгодным решением.
Следующий класс, который еще выгоднее, это S3 One Zone IA (Infrequently Accessed).
Он идеально подходит для тех данных, которые мы храним на более долгий период, которые не так часто запрашиваются и данные, которые мы можем себе позволить частично потерять, это не так критично, либо это могут быть те данные, которые можно легко восстановить.
В этом случае, мы оплачиваем еще меньше и отличие в том, что данные хранятся только на одной availability zone, соответственно, durability здесь чуть ниже, тогда как S3 Standard и S3 Standard IA надежны на 11 девяток.
Следующие два класса хранения больше относятся к архивным данным - это Amazon S3 Glacier or Deep Archive.
Эти классы хранения идеально подходят для тех данных, которые мы сохраняем на долго, по тем или иным причинам, должны хранить некоторый период времени и хранение должно быть дешевым.
Маловероятно, что мы эти данные будем запрашивать, поэтому и извлечение данных из этих классов хранения достаточно трудозатратно с точки зрения времени.
Например, в Amazon S3 Glacier есть три варианта извлечения данных.
Самый первый и самый быстрый, но тем не менее самый дорогой - это Expedited, когда мы данные можем излечь в течение 1-5 минуты.
Далее, есть Standard Retrieval, это когда мы данные извлекаем в течение 3-5 часов, она немного дешевле.
Самый дешевый вариант излечения - это Bulk Retrievals, когда мы данные получаем в течение 5-12 часов.
Это самое дешевое с точки зрения оплаты за извлечение, но тем не менее больше всего времени нужно будет ждать.
Если мы говорим про Glacier Deep Archive, то оно еще больше дешевле, чем Glacier, то есть данные, которые мы совсем не планируем извлекать, можно сохранять в Glacier Deep Archive.
Оно также в себе содержит надежность 11 девяток и данные реплицируются на как минимум три availability zone.
Если мы говорим про извлечение данных, то для Glacier Deep Archive данные извлекаются в течение 12 часов.
И самый последний класс хранения - это Amazon S3 Intelligent Tiering.
В этом случае мы оплачиваем некоторую дополнительную сумму за работу этого класса хранения.
Идея этого класса хранения в том, что мы забываем про существование классов хранения и передаем эту работу самому AWS.
AWS уже на основе логов обращения к файлам индивидуально для каждого файла подбирает подходящий класс хранения.
При этом, если по тем или иным причинам определенный файл был запрошен чаще или наоборот реже, чем ожидалось, то перенос с одного класса хранения на другой класс хранения не оплачивается в случае использования Amazon S3 Intelligent Tiering класса хранения.
Однозначно утверждать, что тот или иной класс хранения лучше, не совсем верно, так как в зависимости от вашей бизнес задачи тот или иной класс хранения может лучше для вас подходить, поэтому нужно смотреть на ваш бизнес кейс.
То, что существует Amazon S3 Intelligent Tiering класс хранения это очень хорошо.
AWS старается по возможности помогать бизнесу, чтобы он не отвлекался на технические задачи и смог сконцентрироваться на бизнес задачах.
Но мы как владельцы данных лучше знаем как эти данные будут запрашиваться, мы знаем что при возникновении некоторых изменений как может поменяться частота обращения к этим файлам.
Поэтому была разработана специальная функция это Amazon S3 Lifecycle Policies.
Идея в том, что мы можем настроить policy для нашего бакета и согласно этому policy на уровне каждого объекта класс хранения будет изменяться в зависимости от этого policy.
Например, мы говорим что у нас в систему загружается некие .mp4 видео файл и первые 30 дней она активно запрашивается используется, поэтому наиболее рационально его хранить в классе хранения S3 standard.
Далее, уже после 30 дней и до 60 дней файл потенциально может быть запрошен, но это достаточно редкий кейс, поэтому мы можем для уменьшения наших затрат на хранение перенести ее на следующий класс хранения S3 Standard IA.
Далее, уже после двух месяцев загрузки конкретно этого файла этот файл определенно использоваться не будет и мы в течение года возможно по некоторым внутренним положениям компании должны хранить ее, в случае если оно нам понадобится.
Поэтому после 60 дней она переходит в класс хранения Amazon S3 Glacier, для того чтобы снизить затраты на хранение, зная, что мы запрашивать не будем.
После года использования этот файл нам не нужен и мы безопасно можем его удалить.
Таким образом Lifecycle Policies позволяет нам, зная как наши данные будут запрашиваться в Amazon S3, задать логику переноса между классами хранения и эта логика, то есть Lifecycle policy, будет накладываться на каждый объект в момент ее загрузки.
Давайте теперь подробнее остановимся с вопросами оплаты за использование сервис Amazon S3.
Этот слайд посвящен тем пунктам, когда мы оплачиваем за использование сервиса.
Это связано с объемом данных, которые мы храним.
Есть определенный тариф за каждый гигабайт хранения и мы оплачиваем только за то, что мы используем.
Представим, что мы храним один единственный файл размером 1 гигабайт в нашем единственном S3 бакете.
Загрузили его на три дня, после чего удалили.
В конце месяца придет счет на оплату за 1 гигабайт объем данных, но ровно за три дня.
За оставшиеся 27 дней месяца так как Amazon S3 ничего не хранила мы не оплачиваем.
Следует также учитывать, что цены могут отличаться в зависимости от региона и в зависимости от класса хранения.
Второй пункт, где нам необходимо оплачивать за использование сервиса Amazon S3 - это перенос данных от S3 бакета.
То есть представим случай, когда мы с S3 бакета в регионе North Virginia переносим данные в другой регион, например, Oregon.
В этом случае это воспринимается как Transfer OUT, поэтому за этот объем данных необходимо будет некоторую сумму оплатить.
Это также относится к кейсу, когда мы с S3 бакета загружаем некий объем данных на локальный компьютер.
Третье - мы оплачиваем также все API вызовы на Amazon S3.
Это могут быть запросы, когда мы передаем файл на хранение, когда мы копируем ее, запрашиваем список объектов, хранящихся в определенном S3 бакете и так далее.
Это также относится к lifecycle transition.
Мы помним что у нас есть функционал lifecycle policy, который в определенные промежутки времени индивидуально для каждого объекта переносится с одного класса хранения на другой класс хранения, либо удаляет этот файл.
Так вот каждый переход необходимо отдельно оплачивать.
Эти суммы относительно небольшие.
Но важно перед началом использования Amazon S3, если у вас очень большой объем данных, рекомендуется более подробно изучить за что мы оплачиваем в сервисе Amazon S3.
Также рассчитать стоимость, которую мы будем ежемесячно оплачивать, будь то приблизительные суммы.
И если эти суммы нам подходят, мы можем начинать работать с этим сервисом, зная что никаких дополнительных оплат точно не будет.
Теперь мы остановимся на тех пунктах, когда мы не оплачиваем при использовании сервиса Amazon S3.
Первый пункт - когда мы с интернета загружаем данные в S3 бакет.
Как я говорил ранее, политика такая, что AWS с радостью принимает данные от вас, для того чтобы ее накапливать, но при этом когда вы эти данные начинаете извлекать вам необходимо производить некоторую оплату - это применимо ко многим сервисам.
Мы также не оплачиваем за перенос данных между двумя бакетами, если они находятся в одном и том же регионе.
Также мы не оплачиваем за перенос данных с Amazon S3 на любой другой сервис, который также находится в одном регионе.
Самый популярный кейс - это использование сервиса Amazon S3 в вашем приложении и ваше приложение хостится на Amazon EC2 инстансах.
В этом случае если Amazon S3 и Amazon EC2 находятся в одном и том же регионе, за трансфер данных мы не будем оплачивать.
Другой кейс -  у нас есть сервис Amazon CloudFront, который является CDN, то есть Content Delivery Network.
Он нативно интегрируется с Amazon S3, для того чтобы быстро доставлять данные вашим пользователям по всему миру.
Так вот во время интеграции Amazon S3 с Amazon CloudFront при передаче данных с Amazon S3 на Amazon CloudFront для кэширования, мы никаких оплат не производим.
И последнее - на те запросы, которые связаны с удалением объектов в S3 бакете, а также отмененные действия, не учитываются и за эти вызовы API сервиса Amazon S3 мы не оплачиваем.
Мы с вами добрались до конца третьей секции.
Давайте остановимся на самых важных моментах.
Мы рассмотрели какие классы хранения бывают.
Далее, познакомились с функционалом LifeCycle Policy.
Также рассмотрели все кейсы, когда мы оплачиваем за использование сервиса Amazon S3 и когда оплачивать ничего не нужно.
Двигаемся к следующей секции.
Четвертая секция - здесь мы будем говорить про все нюансы, связанные с трансфером данных из и в Amazon S3 бакеты.
Давайте разберем те методы с применением которых мы можем загружать наши данные в Amazon S3.
Самое первое и то что мы уже с вами неоднократно проделывали на наших Демо и лабораторных работах - это AWS Management Console.
Используя UI Console, мы можем как загружать так и выгружать данные оттуда и полноценно видеть все необходимое, связанное с сервисом Amazon S3.
Следующая - это AWS CLI, более продвинутая опция, когда мы можем написать некоторые скрипты либо набор команд и таким образом работать с объектами в сервисе Amazon S3.
Далее, еще более продвинутый вариант - это использовать SDK - Software Development Kit.
Самый популярный SDK для AWS - это Boto3.
Он написан для языка программирования Python.
Вы можете, используя высокоуровневый язык программирования, написать некоторую логику, когда код взаимодействует с сервисом Amazon S3.
Мы двигаемся дальше и теперь рассмотрим интересный функционал - Multipart Upload.
Идея в том, что для объектов большого размера мы можем ускорить загрузку в S3 bucket путем разделения ее на более мелкие части и загрузки этих частей индивидуально в Amazon S3.
Далее, после завершения загрузки всех частей, она собирается на стороне Amazon S3 и этот файл становится доступен на стороне Amazon S3 bucket.
Важные нюансы, которые следует упомянуть: минимальный размер файла, который можно загрузить с использованием Multipart  Upload это 5 мегабайтов.
Если размер файла будет меньше, то эта опция не сработает.
Есть также такая рекомендация, что файлы размером менее 100 мегабайтов загружать рекомендуется цельным образом, не применяя Multipart Upload.
Если размер файла больше 100 мегабайтов, в этом случае Multipart Upload может вам ускорить вашу загрузку в Amazon S3.
Используя Multipart Upload у нас есть возможность загружать части параллельно, это уменьшает время загрузки.
Также если это один единственный файл, то в случае возникновения проблем с сетью, загрузка полностью отменяется и все то, что загружено удаляется.
Таким образом, вам нужно будет начать загрузку еще раз.
В случае, когда мы это делаем через Multipart Upload, все части, которые были уже загружены повторно загружать не нужно.
Нужно перезагрузить только те части, которые упали с ошибкой в связи с проблем с сетью.
Также при загрузке через Multipart Upload у нас есть возможность временно приостанавливать загрузку и продолжать ее.
Используя Multipart Upload мы можем загружать достаточно большие объекты до 5 терабайтов.
Следующий функционал, который достаточно интересный и позволяет нам передавать большие объемы данных в S3 Bucket - это Transfer Acceleration.
Идея ее в том, что мы задействуем edge сервера от сервиса Amazon CloudFront.
Таким образом мы не загружаем наши данные напрямую на S3 Bucket, а загружаем на ближайший кэш сервер.
Следовательно загрузка происходит намного быстрее.
Использовать Transfer Acceleration рекомендуется в случаях, когда мы загружаем данные со всего мира в один централизованный Bucket на постоянной основе.
Также рекомендуется использовать Transfer Acceleration, когда мы гигабайты или терабайты данных загружаем в Bucket находящийся в другом регионе на постоянной основе.
У нас будет отдельное Демо посвященное Transfer Acceleration.
Мы более подробнее разберем этот функционал и наглядно покажем какие преимущества он дает.
Следующие два примера, связанные с семейством сервисов AWS Snow - это AWS Snowball и AWS Snowmobile.
Отличаются они размерами.
Давайте сейчас подробнее остановимся на AWS Snowball.
Это некий сервис, который позволяет нам загружать несколько терабайтов или несколько десятков терабайтов данных на Amazon S3.
Как это работает? 
Вы заходите в сервис, оставляете свою заявку и AWS выгружает вам физический чемоданчик, который доезжает до вашего офиса.
Вы подключаете этот чемоданчик к локальной сети и загружаете в него все необходимые данные.
Этот чемоданчик содержит необходимые для работы вычислительные мощности, а самое главное компоненты хранения, то есть жесткие диски.
Как только вы загрузили намного быстрее через локальную сеть все необходимые данные вы ее запаковываете и отправляете обратно на адрес, с которого он пришел.
Как только он доезжает до ближайшего дата-центра AWS, она подключается к глобальной инфраструктуре и опять же через локальную сеть все эти данные загружаются в S3 bucket, на который вы указываете и ваши данные появляются в S3.
Это отличная возможность, если у вас большой объем данных и вы решили переезжать на AWS.
Например, представим, что у нас есть 10 петабайтов данных, это 10 миллионов гигабайтов.
Если мы будем передавать это через интернет, при этом у нас будет достаточно широкий канал загрузки данных в 10 гигабитов в секунду, то нам необходимо будет порядка 100 дней.
Это может быть дорого и нерационально для бизнеса, поэтому AWS Snowball может быть отличным решением.
Второй похожий сервис, предназначенный для еще большего объема данных для передачи с локального дата-центра AWS, а именно в Amazon S3 - это AWS Snowmobile.
Это порядка 14 метровый контейнер, который содержит в себе все необходимые вычислительные мощности.
По сути это маленький дата-центр, привязан к нативно к своему грузовику и этот грузовик после того как вы оставляете заявку в этом сервисе выезжает в сторону вашего офиса.
Как только доезжает, вы также подключаете к локальной сети и передаете ваши данные.
Оно рассчитано на передачу нескольких петобайтов и более данных с локального дата-центра в облако AWS.
Для того чтобы обслуживать подобный контейнер, выделяются специальные люди.
Они приезжают вместе с контейнером.
Также у вас есть специальное наблюдение, различные элементы безопасности.
Вы можете отслеживать передвижение вашего контейнера через GPS, все необходимое, чтобы безопасно добраться до вашего локального офиса и в безопасности ваши данные доставить до ближайшего дата-центра AWS.
Мы с вами добрались до конца четвертой секции.
Вкратце пройдемся по основным моментам.
Есть функционал multipart upload, когда мы большие файлы с размером более 100 мегабайтов разделяем на несколько частей и отправляем в Amazon S3 по частям.
Это дает некоторые преимущества.
Другой вариант, который позволяет ускорить загрузку ваших данных с локального дата-центра в облако AWS - это Transfer Acceleration, который задействует edge сервера сервиса Amazon CloudFront.
Третье -  есть семейство AWS Snow, которое позволяет вам передавать еще большие объемы данных путем загрузки в некоторое физическое устройство, которое приезжает к вам, вы загружаете туда ваши данные и отправляете обратно в ближайший дата-центр AWS, откуда оно потом через локальную сеть, что намного быстрее, загружает ваши данные сервис Amazon S3.
Мы добрались с вами до пятой секции и здесь мы остановимся на некоторых нюансах какой же регион AWS выбрать для хостинга нашей архитектуры.
При выборе региона первым делом необходимо проверить, есть ли некоторые положения либо регуляторные требования, которые накладывают ограничения на хранение ваших данных вне вашей страны, либо похожие нюансы.
Нужно проверить действительно ли этот регион подходит вам с точки зрения закона.
В случае, если есть подобные ограничения и если есть AWS регион в вашей стране, либо в стране, где вы не будете нарушать закон, то следует использовать ее.
Второй момент, который также нужно учитывать, это расстояние до ваших потенциальных пользователей.
Даже небольшие отличия в скорости передачи данных может сильно отразиться на опыте использования вашего продукта вашими пользователями.
Поэтому необходимо проверить ближайший до ваших потенциальных пользователей регион.
Следующий пункт, на который следует обратить внимание - это доступность сервисов и функционала этих сервисов в выбранном вами регионе.
Все новые сервисы и функционал сервисов в первую очередь появляется на первом основном регионе - это регион North Virginia.
Далее по истечении некоторого времени, после прохождения некоторых внутренних тестов, новые сервисы, новый функционал начинает распространяться на другие регионы.
Таким образом, есть некоторые регионы до которых обновление доходит несколько месяцев, следует это учитывать.
На уровне каждого сервиса в документации есть так называемый AWS Region Table, где прописывается доступность тех или иных сервисов, также функционала в определенном регионе.
Последний, но немаловажный пункт, на который стоит обратить внимание - это cost, то есть стоимость использования сервисов AWS в конкретном выбранном регионе.
Цены различаются, здесь определенной логики ценообразования нет, поэтому в интересующих вас регионах необходимо проверить цены на интересующие сервисы, функционал, который дополнительно оплачивается и прикинуть действительно ли эти цены вас устраивают.
Мы с вами добрались до конца пятой секции.
Вкратце остановились на четырех важных пунктах, на которые следует обратить внимание при выборе AWS региона.
Это была последняя секция, на этом мы завершаем вторую часть темы посвященной хранению в облаке AWS.
Мы сегодня рассмотрели какие классы хранения бывают у сервиса Amazon S3, рассмотрели нюансы передачи данных в и из S3 бакетов, какие сервисы и функционал позволяет нам это делать более оптимально, также рассмотрели кейсы, связанные с выбором региона для хостинга нашей IT инфраструктуры.
Здесь вы можете видеть ссылки на некоторые полезные источники - это документация связанная с сервисом Amazon S3.
Также эти страницы вы можете легко найти написав необходимые ключевые слова в поисковик.
На этом мы подошли к концу нашей сегодняшней лекции.
Я очень надеюсь, что вы получили более полные представления о сервисе Amazon S3.
Мы рассмотрели более подробнее этот сервис.
Напоминаю, что у нас будет на этой неделе еще Демо активность, а также лабораторная работа, связанная с сервисом Amazon S3.
Спасибо за внимание, увидимся с вами на следующих наших активностях.
