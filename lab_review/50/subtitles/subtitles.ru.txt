Добрый день, уважаемые студенты! Рад вас видеть на очередной сессии разбора лабораторной работы. Тема лабораторной работы это создание static website для нашего бизнес-кейса, а именно кафе. Эта лабораторная работа является Challenge Lab, поэтому меньше деталей было указано в задании. И теперь мы сейчас попробуем вместе это все проделать со всеми необходимыми деталями. Итак, давайте начнем! Мы начинаем разбор лабораторной работы. Необходимо нам открыть главную страницу лабораторной работы. Здесь необходимо нажать на кнопку Start Lab, после чего откроется всплывающее окно. Необходимо дождаться, чтобы Lab Status из состояния In Creation перейдет в состояние Ready. После чего можно закрывать эту страницу и нажимать на кнопку AWS. После нажатия этой кнопки нас перекинет на главную страницу AWS Management Console. Здесь нам первым делом необходимо скачать zip-архив, в котором содержание нашего веб-сайта, разархивировать локально на нашем компьютере и подготовить для загрузки на S3 бакет. Переходим обратно на AWS Management Console и здесь необходимо открыть сервис Amazon S3. В строке поиска сервисов начнем вводить S3. В выдаче увидим нужную нам ссылку и нажмем на нее. После того, как мы перейдем на главную страницу сервиса Amazon S3, мы увидим, что у нас есть системный бакет. На нее мы не обращаем внимания, нам необходимо создать новый. Поэтому в правой части экрана необходимо нажать на кнопку Create Bucket. Давайте назовем его следующим образом, пусть будет yelzhan-lab-review-50. Вы можете написать любое другое название, самое главное помните, что это название S3 бакета должно быть глобально уникальным. Как регион необходимо выбрать North Virginia. Мы с вами помним, что этот S3 бакет будет использоваться для публичного доступа, а именно для хостинга веб-сайта. Поэтому в секции Object Ownership выберем ACLs Enabled и удостоверимся, что Object Ownership отмечен как Bucket Owner Preferred. Далее необходимо прокрутить чуть ниже и убрать галочку с опции Block All Public Access. Чуть ниже необходимо подтвердить, что мы будем открывать публичный доступ и поставить галочку. Прокручиваем в самый низ страницы и нажимаем на кнопку Create Bucket. Нас направят на страницу со списком бакетов. Вы увидите соответствующее сообщение с зеленым фоном о том, что бакет был успешно создан. Теперь давайте нажмем на название бакета, чтобы перейти на основную страницу этого S3 бакета. Далее нам необходимо нажать на вкладку Properties. Здесь необходимо прокрутить в самый низ и активировать Static Website Hosting опцию. На текущий момент мы видим, что она отключена, поэтому необходимо нажать кнопку Edit. Откроется соответствующая страница. Необходимо выбрать опцию Enable. Далее как Hosting Type мы выбираем Host a Static Website. Как Index Document указываем наш index.html. Как Error Document указываем error.html и нажимаем на кнопку Save Changes. Как только мы это сделали, мы активировали Static Website Hosting опцию, теперь нам необходимо загрузить контент нашего веб-сайта. Для этого переходим на вкладку Objects и нажимаем на кнопку Upload. Так как у нас помимо отдельных файлов есть еще и папки, мы можем воспользоваться кнопкой Add Files и Add Folder и добавить все необходимые файлы. Вы видите список этих файлов, всего у нас 10 объектов, весит порядка 22 мегабайтов. Если все совпадает, в нижней части страницы необходимо нажать на кнопку Upload. Как только мы ее нажмем, нам необходимо проверить, как отображается наша веб-страница. Нам необходимо открыть вкладку Properties, прокрутить чуть ниже и опуститься до секции Static Website Hosting. Там как раз таки находится Bucket website endpoint, необходимо ее скопировать и открыть в новой вкладке браузера. Как только мы ее откроем, мы увидим, что выходит ошибка 403. Это связано с тем, что мы еще не выдавали для наших объектов публичный доступ. Перед тем, как мы перейдем к следующему заданию, нам сейчас необходимо ответить на вопрос теста. Для этого на странице лабораторной работы необходимо нажать на кнопку Details. Будет выпадающий список, необходимо нажать на кнопку Show. И в всплывающем окне нажать на текст, это ссылка Access the multiple choice questions. Откроется отдельная вкладка, закрывать не нужно, мы ее сохраняем до конца лабораторной работы. И сейчас нам необходимо ответить на первый вопрос. Первый вопрос звучит следующим образом. После выполнение третьего задания, смогли ли вы увидеть ваш веб-сайт в отдельной вкладке браузера? Мы увидеть его не смогли, поэтому мы отмечаем опцию No, the files are not publicly accessible. Нажимаем на кнопку Submit и двигаемся дальше. Для того, чтобы веб-сайт отобразился, нам необходимо предоставить публичный доступ. Для этого, на вкладке Objects нашего S3 бакета выделяем все объекты, нажимаем на кнопку Actions. И самым последним пунктом находим опцию Make public using ACL. Необходимо ее нажать, после чего подтвердить, что мы хотим сделать наши объекты доступными публично. Как только мы это сделаем, вернемся на страницу нашего веб-сайта и обновим страницу, мы увидим наш веб-сайт. Отлично. Теперь давайте проведем эксперимент и загрузим папку с картинками еще раз. Как только мы ее загрузили, попробуем открыть наш веб-сайт. Вы видите, что картинки поломались, так как повторная загрузка перевела публичный доступ к папке и файлам в значение по умолчанию, то есть они защищены и приватные. Для того, чтобы они снова отобразились, необходимо проделать предыдущее действие еще раз. Это достаточно неудобно, поэтому согласно нашему бизнес-кейсу, София решила написать Bucket Policy. Для того, чтобы его написать, нам необходимо открыть вкладку Permissions для нашего S3 бакета и опуститься до секции Bucket Policy. Сейчас будем изменять. Для этого необходимо нажать на кнопку Edit, откроется соответствующее окно. Здесь необходимо было вам ознакомиться с AWS документацией и найти подходящие policy. Правильным ответом является следующий документ. Мы здесь прописываем, что Principal является звездочка, то есть это любой анонимный пользователь интернета. Далее Effect: Allow, то есть мы разрешаем доступ на единственное действие Get Object, то есть это режим чтения. И как Resource указываем конкретно наш бакет /* для того, чтобы изменения затронули только объекты внутри нашего бакета. Отлично. Прокручиваем вниз страницы и нажимаем на кнопку Save Changes. Мы увидим на следующей странице сообщение о том, что Bucket Policy был успешно изменен. Это сообщение зеленым фоном. Также мы увидим возле названия бакета флажок красным цветом Publicly Accessible. Отлично. Давайте теперь попробуем обновить страницу с нашим веб-сайтом. И здесь мы увидим, что наши картинки вновь вернулись и все корректно отображается. Теперь мы переходим к следующему заданию. Нам необходимо предоставить дополнительную безопасность от случайных удалений и случайного переписывания объектов внутри S3 бакета. Для этого нам необходимо активировать Bucket versioning. Необходимо перейти на вкладку Properties и прокрутить до секции Bucket versioning. Мы видим, что она сейчас деактивирована. Необходимо нажать на кнопку Edit, чтобы изменить. Мы видим, что у нас есть две опции. Это Suspend или Enable. Так как он у нас сейчас все еще не включен, Suspend логически не подходит. Нам необходимо сейчас включить versioning. Я напоминаю, что после того, как вы включаете versioning, его отключить не получится. Единственный вариант – приостановить versioning. В этом случае новые версии не создаются. При необходимости вы можете versioning включить обратно. Отлично! Выбираем опцию Enable и нажимаем на кнопку Save changes внизу страницы. Теперь нам необходимо протестировать, как работает versioning. На локальном компьютере откроем в любом текстовом редакторе наш index.html файл. Нам необходимо было найти вхождение bgcolor="aquamarine", два вхождения, и одно вхождение bgcolor="orange". Эти значения заменить на, соответственно, bgcolor="gainsboro" и bgcolor="orange" заменить на bgcolor="cornsilk". Как только мы это сделали, давайте перейдем на список объектов в нашем бакете, нажмем на кнопку Upload для того, чтобы загрузить обновленный index.html. Как только мы ее загрузим, мы увидим уже после обновления страницы веб-сайта, что фон блоков в нижней части страницы обновились. Отлично. Теперь нам необходимо открыть главную страницу объекта index.html, далее открыть вкладку Versions и убедиться в том, что действительно versioning включен. На текущий момент у нас две версии и текущим является последняя версия, которую мы загрузили. Теперь мы переходим обратно к тестовым вопросам, необходимо ответить на второй вопрос. Вопрос звучал следующим образом. Выберите опцию, которая помогает нам максимально защитить и избежать от случайного удаления объектов в нашем S3 бакете. Давайте посмотрим какие варианты есть. Первый вариант - Cross-Region Replication. Это немного не подходящий вариант, так как оно лишь реплицирует наши данные на другой бакет, при этом на текущем бакете удалить эти файлы возможно. Другой вариант - это Multi-Factor Authentication, так называемый MFA. Это является правильным ответом, нам необходимо его отметить. Почему оно является правильным? Потому что мы можем привязать MFA верификацию при удалении объектов в S3 бакете. Как это происходит? Ваш IAM User подключается к AWS Management Console, будь то CLI, неважно. Далее вводит временно генерируемый ключ для того, чтобы подтвердить MFA устройство. Обычно это виртуальное MFA устройство, и после чего у него стоит пометка на некоторое время под пользователем, что он может производить действия, где требуется MFA. В момент удаления происходит эта проверка. Если MFA не пройдено, то он не сможет удалить объекты. Пользователи, у которых MFA даже не включен, не смогут удалять объекты, защищённые MFA. Третья опция - это Cross-Origin Resource Sharing CORS. Он относится больше к взаимодействию двух веб-сайтов между собой, поэтому не относится к безопасности. А именно к безопасности касательно удаления объектов в S3 бакете. И четвертая - это Bucket Policy. Тоже не совсем подходящий вариант в нашем случае. Отлично. Мы отметили второй вариант как верный, нажали Submit и двигаемся дальше. Мы с вами переходим к следующему заданию. Здесь нам необходимо оптимизировать затраты на хранение в S3 бакете. Для этого мы настроим Lifecycle Rules. Чтобы это сделать, необходимо перейти на вкладку Management. Первая секция это та секция, которая нам нужна. Она называется Lifecycle Rules. Мы видим, что у нас нет созданных рулов, поэтому нажмем на кнопку Create Lifecycle Rule. Нас перенаправят на соответствующую страницу, где необходимо ввести входные данные. Как Rule Name можем указать move-to-ia, то есть Infrequent Access. Как Choose a Rule Scope выберем опцию Apply to all objects in the Bucket, то есть оно будет относиться ко всем объектам в бакете. И необходимо в поле с подтверждением поставить галочку. Как Lifecycle Rule Actions нам необходимо выбрать вторую опцию. Она означает то, что мы будем не текущие версии объектов перемещать на другой Storage Class. Чуть ниже в следующей секции нам необходимо дать детали этого Storage Class. В нашем случае это Standard-IA, на который он переходит через 30 дней. На этом мы ввели все необходимые данные. Необходимо прокрутить до конца страницы и нажать на кнопку Create Rule. Нас направят на страницу со списком Lifecycle Rules. Мы видим, что созданный нами Rule уже отображается. Он активен. Теперь необходимо создать второй. Также нажмем на кнопку Create Lifecycle Rule. Откроется аналогичная страница. В этом случае как Rule Name ведем delete-rule. Также отметим, что оно относится ко всем объектам в бакете и подтвердим этот выбор. Для Lifecycle Rule Actions выберем предпоследний вариант, который говорит нам, что необходимо удалить все не текущие версии объектов. Чуть ниже необходимо указать количество дней, после которого вступает в силу этот Rule. Это 365 дней. На этом ввели все необходимые данные. Прокручиваем до конца страницы и нажимаем на кнопку Create Rule. Отлично! Вы видите в списке два рула, созданных нами. Они обе активированы. Мы двигаемся дальше. Переходим к следующему заданию. Здесь нам необходимо создать другой бакет в другом регионе для того, чтобы настроить Cross-Region replication. Открываем основную страницу сервиса Amazon S3. Нажимаем на кнопку Create Bucket и вводим необходимые входные данные. Здесь нам необходимо указать Bucket Name. В моем случае я указал yelzhan-replication-destination-bucket. Он уникальный. Далее как регион указываем Oregon. Это us-west-2. Чуть ниже мы включаем versioning. И в самом низу страницы нажимаем на кнопку Create Bucket, чтобы его создать. Нажимаем, увидим зеленое сообщение, что бакет был успешно создан. Также в списке бакетов видим, что у нас есть основной бакет, созданный ранее. Он находится в регионе North Virginia. Мы видим второй созданный бакет. Он находится в регионе Oregon. Все отлично! Двигаемся дальше. Теперь необходимо на основном S3 бакете настроить Replication Rules. Открываем основную страницу S3 бакета, переходим на вкладку Management и опускаемся до секции Replication Rules. На текущий момент у нас рулов нет, поэтому нажимаем на кнопку Create Replication Rule. Откроется отдельная страница. В этой странице необходимо ввести входные данные. Как Replication Rule Name укажем replication-rule-1. Вы можете указать любое другое название по желанию. Status будет у нас Enabled. Здесь ничего не меняется. Как Source Bucket нам необходимо в подсекции Choose a Rule Scope выбрать опцию Apply to all objects in the Bucket. Таким образом все объекты, которые находятся в основном S3 бакете будут реплицироваться на второй S3 бакет. Далее, как в Destination необходимо выбрать опцию Choose a Bucket in this Account и выбрать наш второй созданный S3 бакет. В моем случае это yelzhan-replication-destination-bucket. После того как мы ее выбрали, в подсекции Destination Region укажется регион этого бакета. В нашем случае это Oregon. Все верно. Двигаемся дальше. Секция IAM role - это та роль, которая будет производить действия по репликации. Для нас уже в рамках лабораторной работы уже была создана роль. Поэтому выбираем Choose from existing IAM roles и из списка выбираем роль CafeRole. На этом мы ввели все необходимые данные. Давайте прокрутим до конца страницы и нажмем на кнопку Save. Отлично. Теперь нас направят на страницу с S3 бакетом в соответствующую вкладку. И мы видим, что в списке Replication Rules есть нами созданный рул, который в состоянии Enabled. Отлично. Давайте теперь перейдем на Replication Bucket и проверим какое количество объектов сейчас там есть. Мы видим, что там сейчас объектов нет. И теперь нам необходимо перейти на страницу с тестовыми вопросами и ответить на третий вопрос. Третий вопрос звучит следующим образом. Увидели ли вы объекты из основного бакета в бакете, на который это все реплицируется? Мы отвечаем нет, так как файлы не появились и отправляем наш ответ. Теперь дам некоторые комментарии касательно того, почему же эти файлы там не появились. Все просто. На самом деле, когда мы загружали наши файлы, Replication еще не работал. С того момента, как он был активирован, теперь все изменения, которые произойдут в основном бакете, будут появляться и в Destination Bucket. Давайте попробуем это проверить. Для этого локально в файле index.html сделаем абсолютно любые изменения. Вы здесь видите пример моих изменений. Далее мы возвращаемся к основному S3 бакету, нажимаем на кнопку Upload. Далее нажимаем на Add Files, выбираем наш обновленный index.html, нажимаем на кнопку Open и подтверждаем нашу загрузку. Если мы откроем список версии для объекта index.html, мы увидим, что у нас три версии. Последняя загрузка является текущей версией для этого файла. Теперь, если мы откроем наш второй S3 бакет, который является Destination Bucket при Cross-Region Replication, мы увидим, что у нас появился один объект. Это index.html. Это последняя версия этого файла, которую мы загрузили после активации Cross-Region Replication. Теперь, что мы сделаем? На основном S3 бакете удалим последнюю версию index.html. Для этого необходимо из списка выбрать последнюю версию, нажать на кнопку Delete. Откроется отдельная страница с подтверждением списка объектов. В поле Permanently Delete Objects? необходимо подтвердить это удаление и написать руками permanently delete. После чего кнопка Delete Objects активируется. Давайте на нее нажмем и нас направит на предыдущую страницу. Здесь мы увидим, что у нас остались две версии. Предыдущая версия стала текущей версией. Отлично. Теперь, если мы откроем второй S3 бакет и обновим страницу, мы увидим, что index.html никуда не делся, новых версий не добавилось. На текущий момент у нас видна третья версия файла index.html. Давайте теперь откроем страницу с тестовыми вопросами и попробуем ответить на четвертый вопрос. Звучит следующим образом. После удаления версии файла в основном S3 бакете удалился ли также объект в Destination Bucket? В нашем случае ответ No. Почему так произошло? По умолчанию Delete маркеры не реплицируются в Replication Bucket. Поэтому удаление, которое произошло на основном бакете не отразилось на Replication, то есть на Destination Bucket. Если вы хотите также передавать удаление Delete Маркеры на Destination Bucket, для этого необходимо произвести дополнительные действия и эту опцию включить. Отлично. Я вас поздравляю. Мы завершили все задания лабораторной работы. Теперь нам необходимо запустить скрипт для автооценивания и убедиться в том, что мы корректно выполнили все задания. Для этого нам необходимо нажать на кнопку Submit на странице с лабораторным заданием. Как только вы ее нажмете, необходимо подтвердить, что мы хотим запустить автооценивание. Здесь нам необходимо подождать некоторое время. В моем случае я набрал максимальное количество баллов, 29 из 29, что говорит о том, что все задания были выполнены корректно. Отлично. Теперь нам необходимо безопасно завершить работу всех систем. Начнем мы с AWS аккаунта. Нам необходимо в правом верхнем углу нажать на имя пользователя, в выпадающем списке нажать на кнопку Sign out. Мы это проделывали несколько раз, но я не перестаю об этом повторять. Мы возвращаемся на страницу с лабораторным заданием. Здесь нам необходимо нажать на кнопку End lab, подтвердить, что мы завершаем лабораторную работу и увидеть сообщение о том, что процесс удаления временно созданных ресурсов запущен. Мы можем закрывать это окно и выходить с AWS Academy. Отлично. Я вас поздравляю. Мы завершили разбор лабораторной работы. Я очень надеюсь, что на все вопросы, которые у вас были, получили ответы. Если же остались еще вопросы, пожалуйста, их задавайте. С радостью ответим. Спасибо за внимание. Увидимся с вами на следующих наших активностях.