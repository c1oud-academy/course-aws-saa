 Добрый день, уважаемые студенты! Я рад вас всех видеть на очередной сессии разбора лабораторной работы. Тема лабораторной работы это создание статик-вебсайта для нашего бизнес-кейса, а именно кафе. Эта лабораторная работа является Challenge Lab, поэтому меньше деталей было указано в задании. И теперь мы сейчас попробуем вместе это все проделать со всеми необходимыми деталями. Итак, давайте начнем! Мы начинаем разбор лабораторной работы. Необходимо нам открыть главную страницу лабораторной работы. Здесь необходимо нажать на кнопку Start Lab, после чего откроется всплывающее окно. Необходимо дождаться, что Lab Status из состояния In Creation перейдет в состояние Ready. После чего можно закрывать эту страницу и нажимать на кнопку AWS. После нажатия этой кнопки нас перекинет на главную страницу AWS Management Console. Здесь нам первым делом необходимо скачать zip-архив, в котором содержание нашего веб-сайта, разархивировать его локально на нашем компьютере и подготовить для загрузки на S3 Bucket. Переходим обратно на AWS Management Console и здесь необходимо открыть сервис Amazon S3. Для этого в строке поиска сервисов начнем вводить S3. В выдаче увидим нужную нам ссылку и нажмем на нее. После того, как мы перейдем на главную страницу сервиса Amazon S3, мы увидим, что у нас есть системный бакет. На нее мы не обращаем внимания, нам необходимо создать новый. Поэтому к правой части экрана необходимо нажать на кнопку Create Bucket. Давайте назовем его следующим образом, пусть будет Yeljan Dash Lab Dash Review Dash 50. Вы можете назвать любое другое название, самое главное помните, что это название S3 Bucket должно быть глобально уникальным. Как регион необходимо выбрать Норс-Вирджиния. Мы с вами помним, что этот S3 Bucket будет использоваться для публичного доступа, а именно для хостинга веб-сайта. Поэтому в секции Object Ownership выберем ACLS Enabled и удостоверимся, что Object Ownership отмечен как Bucket Owner Preferred. Далее необходимо прокрутить чуть ниже и убрать галочку с опции Block All Public Access. Чуть ниже нам необходимо подтвердить, что мы будем открывать публичный доступ и поставить галочку. Прокручиваем в самый низ экрана и страницы и нажимаем на кнопку Create Bucket. Нас направят на страницу со списком Bucket. Вы увидите соответствующее сообщение с зеленым фоном о том, что Bucket был успешно создан. Теперь давайте нажмем на название Bucket, чтобы перейти на основную страницу этого S3 Bucket. Далее нам необходимо нажать на вкладку Properties. Здесь необходимо прокрутить самый низ и активировать Static Website Hosting опцию. На текущий момент мы видим, что она отключена, поэтому необходимо нажать кнопку Edit. Откроется соответствующая страница. Необходимо выбрать опцию Enable. Далее как Hosting Type мы выбираем Hosting Static Website. Как Index Document указываем наш Index.html. Как Error Document указываем Error.html и нажимаем на кнопку Save Changes. Как только мы это сделали, мы активировали Static Website Hosting опцию, теперь нам необходимо загрузить контент нашего веб-сайта. Для этого переходим на вкладку Objects и нажимаем на кнопку Upload. Так как у нас есть еще и папки помимо отдельных файлов, мы можем воспользоваться кнопкой Add Files и Add Folder и добавить все необходимые файлы. Вы видите список этих файлов, всего у нас 10 объектов, весит порядка 22 мегабайтов. Если все совпадает, в нижней части страницы необходимо нажать на кнопку Upload. Как только мы ее нажмем, нам необходимо проверить, как отображается наша веб-страница. Нам необходимо открыть вкладку Properties, прокрутить чуть ниже и опуститься до секции Static Website Hosting. Там как раз таки находится bucket website endpoint, необходимо ее скопировать и открыть в новой вкладке браузера. Как только мы ее откроем, мы увидим, что выходит ошибка 403. Это связано с тем, что мы еще не выдавали для наших объектов публичный доступ. Перед тем, как мы перейдем к следующему заданию, нам сейчас необходимо ответить на вопрос теста. Для этого на странице лабораторной работы необходимо нажать на кнопку Details. Будет выпадающий список, необходимо нажать на кнопку Show. И в всплывающем окне нажать на текст, это ссылка Access the multiple choice questions. Откроется отдельная вкладка, ее нам закрывать не нужно, мы ее сохраняем до конца лабораторной работы. И сейчас нам необходимо ответить на первый вопрос. Первый вопрос звучит следующим образом. Если выполнение третьего задания, смогли ли вы увидеть ваш веб-сайт в отдельной вкладке браузера? Мы увидеть его не смогли, поэтому мы отмечаем опцию No, the files are not publicly accessible. Нажимаем на кнопку Submit и двигаемся дальше. Для того, чтобы веб-сайт отобразился, нам необходимо предоставить публичный доступ. После этого, на вкладке Objects нашего стрибакета выделяем все объекты, нажимаем на кнопку Actions. И самым последним пунктом находим опцию Make public using ACL. Необходимо ее нажать, после чего подтвердить, что мы хотим сделать наши объекты доступными публично. Как только мы это сделаем, вернемся на страницу нашего веб-сайта и обновим страницу, мы увидим наш веб-сайт. Отлично. Теперь давайте проведем эксперимент и загрузим папку с картинками еще раз. Как только мы ее загрузили, попробуем открыть наш веб-сайт. Вы видите, что картинки поломались, так как повторная загрузка перевела публичный доступ к папке и файлам в значение по умолчанию, то есть они защищены и приватные. Для того, чтобы они снова отобразились, необходимо проделать предыдущее действие еще раз. Но это достаточно неудобно, поэтому согласно нашему бизнес-кейсу, София решила написать Bucket Policy. Для того, чтобы его написать, нам необходимо открыть вкладку Permissions для нашего S3 Bucket и опуститься до секции Bucket Policy. Мы сейчас его будем изменять. Для этого необходимо нажать на кнопку Edit, откроется соответствующее окно. Здесь необходимо было вам ознакомиться с AWS-документацией и найти подходящие policy. Правильным ответом является следующий документ. Мы здесь прописываем, что принципом является звездочка, то есть это любой анонимный пользователь интернета. Далее Effect Allow, то есть мы разрешаем доступ на единственное действие Get Object, то есть это режим чтения. И как ресурс указываем конкретно наш Bucket слэш звездочка для того, чтобы изменения затронули только объекты внутри нашего Bucket. Отлично. Прокручиваем вниз страницы и нажимаем на кнопку Save Changes. Мы увидим на следующей странице сообщение о том, что Bucket Policy был успешно изменен. Это сообщение зеленым фоном. Также мы увидим возле названия Bucket флажок красным цветом Publicly Accessible. Отлично. Давайте теперь попробуем обновить страницу с нашим веб-сайтом. И здесь мы увидим, что наши картинки вновь вернулись и все корректно отображается. Теперь мы переходим к следующему заданию. Нам необходимо предоставить дополнительную безопасность от случайных удалений и случайного переписывания объектов внутри S3 Bucket. Для этого нам необходимо активировать Bucket versioning. Чтобы это сделать, нам необходимо перейти на вкладку Properties и прокрутить до секции Bucket versioning. Мы видим, что она сейчас у нас деактивирована. Нам необходимо нажать на кнопку Edit, чтобы это изменить. Мы видим, что у нас есть две опции. Это Suspend или Enable. Так как он у нас сейчас все еще не включен, Suspend логически не подходит. Нам необходимо сейчас включить versioning. Я напоминаю, что после того, как вы включаете versioning, его отключить не получится. Единственный вариант – приостановить versioning. В этом случае новые версии не создаются. При необходимости вы можете versioning включить обратно. Отлично! Выбираем опцию Enable и нажимаем на кнопку Save changes внизу страницы. Теперь нам необходимо протестировать, как работает versioning. На локальном компьютере откроем в любом текстовом редакторе наш индекс HTML-файл. Нам необходимо было найти вхождение bagcolor aquamarine, два вхождения, и одно вхождение bagcolor orange. Эти значения заменить на, соответственно, bagcolor равно Gain сбору и orange заменить на corn silk. Как только мы это сделали, давайте перейдем на список объектов в нашем Stribucket, нажмем на кнопку Upload для того, чтобы загрузить обновленный индекс HTML. Как только мы ее загрузим, мы увидим уже после обновления страницы веб-сайта, что фон блоков в нижней части страницы обновились. Отлично. Теперь нам необходимо открыть главную страницу объекта индекса HTML, далее открыть вкладку versions и убедиться в том, что действительно versioning включен. На текущий момент у нас имеется две версии и текущим является последняя версия, которую мы загрузили. Теперь мы переходим обратно к нашим тестовым вопросам и нам необходимо ответить на второй вопрос. Вопрос звучал следующим образом. Выберите опцию, которая помогает нам максимально защитить и избежать от случайного удаления объектов в нашем Stribucket. Давайте посмотрим какие варианты есть. Первый вариант Cross Region Replication. Это немного не подходящий вариант, так как оно лишь реплицирует наши данные на другой бакет, при этом на текущем бакете удалить эти файлы возможно. Другой вариант это Multi-Factor Authentication, так называемый MFA. Это является правильным ответом, но необходимо его отметить. Почему оно является правильным? Так потому что мы можем привязать MFA верификацию при удалении объектов в Stribucket. Как это происходит? Ваш IAM-юзер подключается к AWS Management Console, будь то CLI, неважно. Далее вводит ключ временно генерируемый для того, чтобы подтвердить MFA устройство. Обычно это виртуальное MFA устройство, и после чего у него стоит пометка на некоторое время под пользователем, что он может производить действия, где требуется MFA. В момент удаления происходит эта проверка. Если MFA не пройдено, то он не сможет удалить эти объекты. Пользователи, у которых MFA даже не включен, не смогут удалять объекты, защищённые MFA. Третья опция это Cross-Origin Resource Sharing course. Он относится больше к взаимодействию двух веб-сайтов между собой, поэтому не относится к безопасности. А именно к безопасности касательно удаления объектов в Stribucket. И четвертая это Bucket Policy. Тоже не совсем подходящий вариант в нашем случае. Отлично. Мы отметили второй вариант как верный, субмитнули ее и двигаемся дальше. Мы с вами переходим к следующему заданию. Здесь нам необходимо оптимизировать затраты на хранение в Stribucket. Для этого мы настроим Lifecycle Rules. Чтобы это сделать, необходимо перейти на вкладку Management. Первая секция это та секция, которая нам нужна. Она называется Lifecycle Rules. Мы видим, что у нас нет созданных рулов, поэтому нажмем на кнопку Create Lifecycle Rule. Нас перенаправят на соответствующую страницу, где необходимо ввести входные данные. Как Rule Name можем указать Move to IA, то есть Infrequent Access. Как Choose a Rule Scope выберем опцию Apply to all objects in the Bucket, то есть оно будет относиться ко всем объектам в Bucket. И необходимо в поле с подтверждением поставить галочку. Как Lifecycle Rule Actions нам необходимо выбрать вторую опцию. Она означает то, что мы будем не текущей версии объектов перемещать на другой Storage Class. Чуть ниже в следующей секции нам необходимо дать детали этого Storage Class. В нашем случае это стандарт IA, на который он переходит через 30 дней. На этом мы ввели все необходимые данные. Необходимо прокрутить до конца страницы и нажать на кнопку Create Rule. Нас направят на страницу со списком Lifecycle Rules. Мы видим, что созданный номер Rule уже отображается. Он активен. Теперь необходимо создать второй. Также нажмем на кнопку Create Lifecycle Rule. Откроется аналогичная страница. В этом случае ведем как Rule Name Delete Rule. Также отметим, что оно относится ко всем объектам в Bucket и подтвердим этот выбор. Для Lifecycle Rule Actions выберем предпоследний вариант, который говорит нам, что необходимо удалить все не текущие версии объектов. Чуть ниже необходимо указать количество дней, после которого вступает силу этот Rule. Это 365 дней. На этом ввели все необходимые данные. Прокручиваем до конца страницы и нажимаем на кнопку Create Rule. Отлично! Вы видите в списке 2 рула, созданных нами. Они обе активированы. Мы двигаемся дальше. Переходим к следующему заданию. Здесь нам необходимо создать другой Bucket в другом регионе для того, чтобы настроить Cross-Region репликацию. Открываем основную страницу сервиса Amazon S3. Нажимаем на кнопку Create Bucket и вводим необходимые входные данные. Здесь нам необходимо указать Bucket Name. В моем случае я указал Yeljan Replication Destination Bucket. Он уникальный. Далее как регион указываем Oregon. Это US West 2. Чуть ниже мы включаем вершиник. И в самом низу страницы нажимаем на кнопку Create Bucket, чтобы его создать. Как только мы на нее нажимаем, мы увидим зеленое сообщение о том, что Bucket был успешно создан. Также в списке Bucket мы видим, что у нас есть основной Bucket, созданный ранее. Он находится в регионе North Virginia. Мы видим второй созданный Bucket. Он находится в регионе Oregon. Все отлично! Двигаемся дальше. Теперь нам необходимо на основном S3 Bucket настроить Replication Rules. Для этого открываем основную страницу S3 Bucket, переходим на вкладку Management и опускаемся до секции Replication Rules. На текущий момент у нас рулов нет, поэтому нажимаем на кнопку Create Replication Rule. Откроется отдельная страница. В этой странице необходимо ввести входные данные. Как Replication Rule Name укажем Replication Rule 1. Вы можете указать любое другое название по желанию. Status будет у нас Enabled. Здесь ничего не меняется. Как Source Bucket нам необходимо в подсекции Choose a Rule Scope выбрать опцию Apply to all objects in the Bucket. Таким образом все объекты, которые находятся в основном S3 Bucket будут реплицироваться на второй S3 Bucket. Далее как в Destination необходимо выбрать опцию Choose a Bucket in this Account и выбрать наш второй созданный S3 Bucket. В моем случае это Yelzhan Replication Destination Bucket. После того как мы ее выбрали в подсекции Destination Region укажется регион этого Bucket. В нашем случае это Oregon. Все верно. Двигаемся дальше. Секция IAMROL это та роль, которая будет производить действия по репликации. Для нас уже в рамках лабораторной работы уже была создана роль. Поэтому выбираем Choose from existing IAMROL и из списка выбираем роль CafeROL. На этом мы ввели все необходимые данные. Давайте прокрутим до конца страницы и нажмем на кнопку Save. Отлично. Теперь нас направят на страницу с S3 Bucket в соответствующую вкладку. И мы видим, что в списке Replication Rules у нас созданы Рулы, которые в состоянии Enabled. Отлично. Давайте теперь перейдем на Replication Bucket и проверим какое количество объектов сейчас там есть. Мы видим, что там сейчас объектов нет. И теперь нам необходимо перейти на страницу с тестовыми вопросами и ответить на третий вопрос. Третий вопрос звучит следующим образом. Увидели ли вы объекты из основного бакета в бакете, на который это все реплицируется? Мы отвечаем нет, так как файлы не появились и отправляем наш ответ. Теперь дам некоторые комментарии касательно того, почему же эти файлы там не появились. Все просто. На самом деле, когда мы загружали наши файлы, Replication еще не работал. С того момента, как он был активирован, теперь все изменения, которые произойдут в основном бакете, будут появляться и в Destination Bucket. Давайте попробуем это проверить. Для этого локально в файле index.html сделаем абсолютно любые изменения. Вы здесь видите пример моих изменений. Далее мы возвращаемся к основному S3 Bucket, нажимаем на кнопку Upload. Далее нажимаем на Add Files, выбираем наш обновленный index.html, нажимаем на кнопку Open и подтверждаем нашу загрузку. Если мы откроем список версии для объекта index.html, мы увидим, что у нас три версии. Последняя загрузка является текущей версии для этого файла. Теперь, если мы откроем наш второй S3 Bucket, который является Destination Bucket при Cross-Region Replication, мы увидим, что у нас появился один объект. Это index.html. Это последняя версия этого файла, которую мы загрузили после активации Cross-Region Replication. Теперь, что мы сделаем? На основном S3 Bucket удалим последнюю версию index.html. Для этого необходимо из списка выбрать последнюю версию, нажать на кнопку Delete. Откроются отдельные страницы с подтверждением списка объектов. В поле Permanently Delete Objects необходимо подтвердить это удаление и написать руками Permanently Delete. После чего кнопка Delete Objects активируется. Давайте на нее нажмем и нас направят на предыдущую страницу. Здесь мы увидим, что у нас остались две версии. Предыдущая версия стала текущей версией. Отлично. Теперь, если мы откроем второй S3 Bucket и обновим страницу, мы увидим, что index.html никуда не делся, новых версий не добавилось. На текущий момент у нас видна третья версия файла index.html. Давайте теперь откроем страницу с тестовыми вопросами и попробуем ответить на четвертый вопрос. Звучит он следующим образом. После удаления версии файла в основном S3 Bucket удалился ли также объект в Destination Bucket? В нашем случае ответ No. Дам некоторые комментарии, почему так произошло. По умолчанию Delete Маркеры не реплицируются в Replication Bucket. Поэтому удаление, которое произошло на основном Bucket не отразилось на Replication Bucket. Если вы хотите также передавать удаление Delete Маркеры на Destination Bucket, для этого необходимо произвести дополнительные действия и эту опцию включить. Отлично. Я вас поздравляю. Мы завершили все задания лаборторной работы. Теперь нам необходимо запустить скрипт для автооценивания и убедиться в том, что мы корректно выполнили все задания. Для этого нам необходимо нажать на кнопку Submit на странице с лаборторным заданием. Как только вы ее нажмете, необходимо подтвердить, что мы хотим запустить автооценивание. Здесь нам необходимо подождать некоторое время. В моем случае я набрал максимальное количество баллов, 29 из 29, что говорит о том, что все задания были выполнены корректно. Отлично. Теперь нам необходимо безопасно завершить работу всех систем. Начнем мы с AWS аккаунта. Нам необходимо вверху вправо нажать на имя пользователя, в выпадающем списке нажать на кнопку Sign out. Мы это проделывали несколько раз, но я не перестаю об этом повторять. Мы возвращаемся на страницу с лаборторным заданием. Здесь нам необходимо нажать на кнопку End lab, подтвердить, что мы завершаем лаборторную работу и увидеть сообщение о том, что процесс удаления временных созданных ресурсов запущен. Мы можем закрывать это окно и выходить с AWS Academy. Отлично. Я вас поздравляю. Мы завершили разбор лаборторной работы. Я очень надеюсь, что все вопросы, которые у вас были, вы получили на них ответы. Если же остались еще вопросы, пожалуйста их задавайте. С радостью на них также ответим. Спасибо за внимание. Увидимся с вами на следующих наших активностях.
