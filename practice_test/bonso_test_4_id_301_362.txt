QUESTION_ID_PLACEHOLDER
A data analytics company, which uses machine learning to collect and analyze consumer data, is using Redshift cluster as their data warehouse. You are instructed to implement a disaster recovery plan for their systems to ensure business continuity even in the event of an AWS region outage.   
Which of the following is the best approach to meet this requirement?
B) Do nothing because Amazon Redshift is a highly available, fully-managed data warehouse which can withstand an outage of an entire AWS region.
+A) Enable Cross-Region Snapshots Copy in your Amazon Redshift Cluster.
B) Use Automated snapshots of your Redshift Cluster.
B) Create a scheduled job that will automatically take the snapshot of your Redshift Cluster and store it to an S3 bucket. Restore the snapshot in case of an AWS region outage.

QUESTION_ID_PLACEHOLDER
A startup plans to develop a multiplayer game that uses UDP as the protocol for communication between clients and game servers. The data of the users will be stored in a key-value store. As the Solutions Architect, you need to implement a solution that will distribute the traffic across a number of servers.
Which of the following could help you achieve this requirement?
B) Distribute the traffic using Network Load Balancer and store the data in Amazon Aurora.
+A) Distribute the traffic using Network Load Balancer and store the data in Amazon DynamoDB.
B) Distribute the traffic using Application Load Balancer and store the data in Amazon DynamoDB.
B) Distribute the traffic using Application Load Balancer and store the data in Amazon RDS.

QUESTION_ID_PLACEHOLDER
A real-time data analytics application is using AWS Lambda to process data and store results in JSON format to an S3 bucket. To speed up the existing workflow, you have to use a service where you can run sophisticated Big Data analytics on your data without moving them into a separate analytics system.   
Which of the following group of services can you use to meet this requirement? 
B) Amazon X-Ray, Amazon Neptune, DynamoDB 
B) Amazon Glue, Glacier Select, Amazon Redshift 
+A) S3 Select, Amazon Athena, Amazon Redshift Spectrum 
B) S3 Select, Amazon Neptune, DynamoDB DAX 

QUESTION_ID_PLACEHOLDER
A web application is hosted in an Auto Scaling group of EC2 instances deployed across multiple Availability Zones behind an Application Load Balancer. You need to implement an SSL solution for your system to improve its security which is why you requested an SSL/TLS certificate from a third-party certificate authority (CA).
Where can you safely import the SSL/TLS certificate of your application?
B) CloudFront
+A) IAM certificate store
B) An S3 bucket configured with server-side encryption with customer-provided encryption keys (SSE-C)
+A) AWS Certificate Manager
B) A private S3 bucket with versioning enabled

QUESTION_ID_PLACEHOLDER
A company is building an internal application that processes loans, accruals, and interest rates for their clients. They require a storage service that is able to handle future increases in storage capacity of up to 16 TB and can provide the lowest-latency access to their data. The web application will be hosted in a single m5ad.24xlarge Reserved EC2 instance that will process and store data to the storage service.
Which of the following storage services would you recommend?
B) EFS
B) S3
B) Storage Gateway
+A) EBS

QUESTION_ID_PLACEHOLDER
The company you are working for has a set of AWS resources hosted in ap-northeast-1 region. You have been asked by your IT Manager to create an AWS CLI shell script that will call an AWS service which could create duplicate resources in another region in the event that ap-northeast-1 region fails. The duplicated resources should also contain the VPC Peering configuration and other networking components from the primary stack.
Which of the following AWS services could help fulfill this task?
B) Amazon SNS
B) Amazon LightSail
B) Amazon SQS
+A) AWS CloudFormation

QUESTION_ID_PLACEHOLDER
A technical lead of the Cloud Infrastructure team was consulted by a software developer regarding the required AWS resources of the web application that he is building. The developer knows that an Instance Store only provides ephemeral storage where the data is automatically deleted when the instance is terminated. To ensure that the data of the web application persists, the app should be launched in an EC2 instance that has a durable, block-level storage volume attached. The developer knows that they need to use an EBS volume, but they are not sure what type they need to use.
In this scenario, which of the following is true about Amazon EBS volume types and their respective usage?
B) General Purpose SSD (gp3) volumes with multi-attach enabled offer consistent and low-latency performance, and are designed for applications requiring multi-az resiliency.
+A) Provisioned IOPS volumes offer storage with consistent and low-latency performance, and are designed for I/O intensive applications such as large relational or NoSQL databases.
+A) Magnetic volumes provide the lowest cost per gigabyte of all EBS volume types and are ideal for workloads where data is accessed infrequently, and applications where the lowest storage cost is important.
B) Spot volumes provide the lowest cost per gigabyte of all EBS volume types and are ideal for workloads where data is accessed infrequently, and applications where the lowest storage cost is important.
B) Single root I/O virtualization (SR-IOV) volumes are suitable for a broad range of workloads, including small to medium-sized databases, development and test environments, and boot volumes.

QUESTION_ID_PLACEHOLDER
A company has hundreds of VPCs with multiple VPN connections to their data centers spanning 5 AWS Regions. As the number of its workloads grows, the company must be able to scale its networks across multiple accounts and VPCs to keep up. A Solutions Architect is tasked to interconnect all of the company's on-premises networks, VPNs, and VPCs into a single gateway, which includes support for inter-region peering across multiple AWS regions.
Which of the following is the BEST solution that the architect should set up to support the required interconnectivity?
B) Set up an AWS VPN CloudHub for inter-region VPC access and a Direct Connect gateway for the VPN connections to the on-premises data centers. Create a virtual private gateway in each VPC, then create a private virtual interface for each AWS Direct Connect connection to the Direct Connect gateway.
+A) Set up an AWS Transit Gateway in each region to interconnect all networks within it. Then, route traffic between the transit gateways through a peering connection.
B) Set up an AWS Direct Connect Gateway to achieve inter-region VPC access to all of the AWS resources and on-premises data centers. Set up a link aggregation group (LAG) to aggregate multiple connections at a single AWS Direct Connect endpoint in order to treat them as a single, managed connection. Launch a virtual private gateway in each VPC and then create a public virtual interface for each AWS Direct Connect connection to the Direct Connect Gateway.
B) Enable inter-region VPC peering that allows peering relationships to be established between multiple VPCs across different AWS regions. Set up a networking configuration that ensures that the traffic will always stay on the global AWS backbone and never traverse the public Internet.

QUESTION_ID_PLACEHOLDER
A company has a web application hosted in AWS cloud where the application logs are sent to Amazon CloudWatch. Lately, the web application has recently been encountering some errors which can be resolved simply by restarting the instance.
What will you do to automatically restart the EC2 instances whenever the same application error occurs?
B) First, look at the existing Flow logs for keywords related to the application error to create a custom metric. Then, create a CloudWatch alarm for that custom metric which calls a Lambda function that invokes an action to restart the EC2 instance.
+A) First, look at the existing CloudWatch logs for keywords related to the application error to create a custom metric. Then, create a CloudWatch alarm for that custom metric which invokes an action to restart the EC2 instance.
B) First, look at the existing Flow logs for keywords related to the application error to create a custom metric. Then, create a CloudWatch alarm for that custom metric which invokes an action to restart the EC2 instance.
B) First, look at the existing CloudWatch logs for keywords related to the application error to create a custom metric. Then, create an alarm in Amazon SNS for that custom metric which invokes an action to restart the EC2 instance.

QUESTION_ID_PLACEHOLDER
A company has a web-based order processing system that is currently using a standard queue in Amazon SQS. The IT Manager noticed that there are a lot of cases where an order was processed twice. This issue has caused a lot of trouble in processing and made the customers very unhappy. The manager has asked you to ensure that this issue will not recur.
What can you do to prevent this from happening again in the future?
B) Change the message size in SQS.
B) Alter the retention period in Amazon SQS.
+A) Use an Amazon SQS FIFO Queue instead.
B) Alter the visibility timeout of SQS.
+A) Replace Amazon SQS and instead, use Amazon Simple Workflow service.

QUESTION_ID_PLACEHOLDER
A company launched an online platform that allows people to easily buy, sell, spend, and manage their cryptocurrency. To meet the strict IT audit requirements, each of the API calls on all of the AWS resources should be properly captured and recorded. You used CloudTrail in the VPC to help you in the compliance, operational auditing, and risk auditing of your AWS account.
In this scenario, where does CloudTrail store all of the logs that it creates?
B) A RDS instance
B) DynamoDB
B) Amazon Redshift
+A) Amazon S3

QUESTION_ID_PLACEHOLDER
A leading IT consulting company has an application which processes a large stream of financial data by an Amazon ECS Cluster then stores the result to a DynamoDB table. You have to design a solution to detect new entries in the DynamoDB table then automatically trigger a Lambda function to run some tests to verify the processed data.
What solution can be easily implemented to alert the Lambda function of new entries while requiring minimal configuration change to your architecture?
B) Use Systems Manager Automation to detect new entries in the DynamoDB table then automatically invoke the Lambda function for processing.
B) Use CloudWatch Alarms to trigger the Lambda function whenever a new entry is created in the DynamoDB table.
+A) Enable DynamoDB Streams to capture table activity and automatically trigger the Lambda function.
B) Invoke the Lambda functions using SNS each time that the ECS Cluster successfully processed financial data.

QUESTION_ID_PLACEHOLDER
A company has a High Performance Computing (HPC) cluster that is composed of EC2 Instances with Provisioned IOPS volume to process transaction-intensive, low-latency workloads. The Solutions Architect must maintain high IOPS while keeping the latency down by setting the optimal queue length for the volume. The size of each volume is 10 GiB.
Which of the following is the MOST suitable configuration that the Architect should set up?
B) Set the IOPS to 800 then maintain a low queue length.
B) Set the IOPS to 400 then maintain a low queue length.
B) Set the IOPS to 600 then maintain a high queue length.
+A) Set the IOPS to 500 then maintain a low queue length.

QUESTION_ID_PLACEHOLDER
A media company is using Amazon EC2, ELB, and S3 for its video-sharing portal for filmmakers. They are using a standard S3 storage class to store all high-quality videos that are frequently accessed only during the first three months of posting.
As a Solutions Architect, what should you do if the company needs to automatically transfer or archive media data from an S3 bucket to Glacier?
+A) Use Lifecycle Policies
B) Use Amazon SQS
B) Use a custom shell script that transfers data from the S3 bucket to Glacier
B) Use Amazon SWF

QUESTION_ID_PLACEHOLDER
A Solutions Architect is designing the cloud architecture for the enterprise application suite of the company. Both the web and application tiers need to access the Internet to fetch data from public APIs. However, these servers should be inaccessible from the Internet.
Which of the following steps should the Architect implement to meet the above requirements?
+A) Deploy a NAT gateway in the public subnet and add a route to it from the private subnet where the web and application tiers are hosted.
B) Deploy the web and application tier instances to a private subnet and then allocate an Elastic IP address to each EC2 instance.
B) Deploy the web and application tier instances to a public subnet and then allocate an Elastic IP address to each EC2 instance.
B) Deploy a NAT gateway in the private subnet and add a route to it from the public subnet where the web and application tiers are hosted.

QUESTION_ID_PLACEHOLDER
A Fortune 500 company which has numerous offices and customers around the globe has hired you as their Principal Architect. You have staff and customers that upload gigabytes to terabytes of data to a centralized S3 bucket from the regional data centers, across continents, all over the world on a regular basis. At the end of the financial year, there are thousands of data being uploaded to the central S3 bucket which is in ap-southeast-2 (Sydney) region and a lot of employees are starting to complain about the slow upload times. You were instructed by the CTO to resolve this issue as soon as possible to avoid any delays in processing their global end of financial year (EOFY) reports.   
Which feature in Amazon S3 enables fast, easy, and secure transfer of your files over long distances between your client and your Amazon S3 bucket?
+A) Transfer Acceleration
B) Multipart Upload
B) Cross-Region Replication
B) AWS Global Accelerator

QUESTION_ID_PLACEHOLDER
A company plans to develop a custom messaging service that will also be used to train their AI for an automatic response feature which they plan to implement in the future. Based on their research and tests, the service can receive up to thousands of messages a day, and all of these data are to be sent to Amazon EMR for further processing. It is crucial that none of the messages are lost, no duplicates are produced, and that they are processed in EMR in the same order as their arrival.
Which of the following options can satisfy the given requirement?
B) Set up a default Amazon SQS queue to handle the messages.
B) Set up an Amazon SNS Topic to handle the messages.
+A) Create an Amazon Kinesis Data Stream to collect the messages.
B) Create a pipeline using AWS Data Pipeline to handle the messages.

QUESTION_ID_PLACEHOLDER
A customer is transitioning their ActiveMQ messaging broker service onto the AWS cloud in which they require an alternative asynchronous service that supports NMS and MQTT messaging protocol. The customer does not have the time and resources needed to recreate their messaging service in the cloud. The service has to be highly available and should require almost no management overhead.
Which of the following is the most suitable service to use to meet the above requirement?
+A) Amazon MQ
B) AWS Step Functions
B) Amazon SWF
B) Amazon SNS

QUESTION_ID_PLACEHOLDER
An automotive company is working on an autonomous vehicle development and deployment project using AWS. The solution requires High Performance Computing (HPC) in order to collect, store and manage massive amounts of data as well as to support deep learning frameworks. The Linux EC2 instances that will be used should have a lower latency and higher throughput than the TCP transport traditionally used in cloud-based HPC systems. It should also enhance the performance of inter-instance communication and must include an OS-bypass functionality to allow the HPC to communicate directly with the network interface hardware to provide low-latency, reliable transport functionality.
Which of the following is the MOST suitable solution that you should implement to achieve the above requirements?
+A) Attach an Elastic Fabric Adapter (EFA) on each Amazon EC2 instance to accelerate High Performance Computing (HPC).
B) Attach an Elastic Network Interface (ENI) on each Amazon EC2 instance to accelerate High Performance Computing (HPC).
B) Attach an Elastic Network Adapter (ENA) on each Amazon EC2 instance to accelerate High Performance Computing (HPC).
B) Attach a Private Virtual Interface (VIF) on each Amazon EC2 instance to accelerate High Performance Computing (HPC).

QUESTION_ID_PLACEHOLDER
A company recently launched an e-commerce application that is running in eu-east-2 region, which strictly requires six EC2 instances running at all times. In that region, there are 3 Availability Zones (AZ) that you can use - eu-east-2a, eu-east-2b, and eu-east-2c.
Which of the following deployments provide 100% fault tolerance if any single AZ in the region becomes unavailable?
+A) eu-east-2a with six EC2 instances, eu-east-2b with six EC2 instances, and eu-east-2c with no EC2 instances
B) eu-east-2a with two EC2 instances, eu-east-2b with four EC2 instances, and eu-east-2c with two EC2 instances
B) eu-east-2a with four EC2 instances, eu-east-2b with two EC2 instances, and eu-east-2c with two EC2 instances
+A) eu-east-2a with three EC2 instances, eu-east-2b with three EC2 instances, and eu-east-2c with three EC2 instances
B) eu-east-2a with two EC2 instances, eu-east-2b with two EC2 instances, and eu-east-2c with two EC2 instances

QUESTION_ID_PLACEHOLDER
A company decided to change its third-party data analytics tool to a cheaper solution. They sent a full data export on a CSV file which contains all of their analytics information. You then save the CSV file to an S3 bucket for storage. Your manager asked you to do some validation on the provided data export.
In this scenario, what is the most cost-effective and easiest way to analyze export data using standard SQL?
B) Create a migration tool to load the CSV export file from S3 to a DynamoDB instance. Once the data has been loaded, run queries using DynamoDB.
B) Use mysqldump client utility to load the CSV export file from S3 to a MySQL RDS instance. Run some SQL queries once the data has been loaded to complete your validation.
+A) To be able to run SQL queries, use AWS Athena to analyze the export data file in S3.
B) Use a migration tool to load the CSV export file from S3 to a database that is designed for online analytic processing (OLAP) such as AWS RedShift. Run some queries once the data has been loaded to complete your validation.

QUESTION_ID_PLACEHOLDER
A Solutions Architect is designing a setup for a database that will run on Amazon RDS for MySQL. He needs to ensure that the database can automatically failover to an RDS instance to continue operating in the event of failure. The architecture should also be as highly available as possible.
Which among the following actions should the Solutions Architect do?
B) Create five cross-region read replicas in each region. In the event of an Availability Zone outage, promote any replica to become the primary instance.
B) Create a read replica in the same region where the DB instance resides. In addition, create a read replica in a different region to survive a region’s failure. In the event of an Availability Zone outage, promote any replica to become the primary instance.
+A) Create a standby replica in another availability zone by enabling Multi-AZ deployment.
B) Create five read replicas across different availability zones. In the event of an Availability Zone outage, promote any replica to become the primary instance.

QUESTION_ID_PLACEHOLDER
To save costs, your manager instructed you to analyze and review the setup of your AWS cloud infrastructure. You should also provide an estimate of how much your company will pay for all of the AWS resources that they are using. In this scenario, which of the following will incur costs?
B) Using an Amazon VPC
+A) EBS Volumes attached to stopped EC2 Instances
B) A stopped On-Demand EC2 Instance
B) Public Data Set
+A) A running EC2 Instance

QUESTION_ID_PLACEHOLDER
A company is using an On-Demand EC2 instance to host a legacy web application that uses an Amazon Instance Store-Backed AMI. The web application should be decommissioned as soon as possible and hence, you need to terminate the EC2 instance.
When the instance is terminated, what happens to the data on the root volume?
B) Data is automatically saved as an EBS volume.
B) Data is unavailable until the instance is restarted.
+A) Data is automatically deleted.
B) Data is automatically saved as an EBS snapshot.

QUESTION_ID_PLACEHOLDER
A media company needs to configure an Amazon S3 bucket to serve static assets for the public-facing web application. Which methods ensure that all of the objects uploaded to the S3 bucket can be read publicly all over the Internet?
B) Configure the cross-origin resource sharing (CORS) of the S3 bucket to allow objects to be publicly accessible from all domains.
+A) Configure the S3 bucket policy to set all objects to public read.
+A) Grant public read access to the object when uploading it using the S3 Console.
B) Create an IAM role to set the objects inside the S3 bucket to public read.
B) Do nothing. Amazon S3 objects are already public by default.

QUESTION_ID_PLACEHOLDER
A data analytics company has been building its new generation big data and analytics platform on their AWS cloud infrastructure. They need a storage service that provides the scale and performance that their big data applications require such as high throughput to compute nodes coupled with read-after-write consistency and low-latency file operations. In addition, their data needs to be stored redundantly across multiple AZs and allows concurrent connections from multiple EC2 instances hosted on multiple AZs.   
Which of the following AWS storage services will you use to meet this requirement?
B) Glacier
B) EBS
B) S3
+A) EFS

QUESTION_ID_PLACEHOLDER
A company has a global news website hosted in a fleet of EC2 Instances. Lately, the load on the website has increased which resulted in slower response time for the site visitors. This issue impacts the revenue of the company as some readers tend to leave the site if it does not load after 10 seconds.
Which of the below services in AWS can be used to solve this problem?
+A) Use Amazon CloudFront with website as the custom origin.
+A) Use Amazon ElastiCache for the website's in-memory data store or cache.
B) For better read throughput, use AWS Storage Gateway to distribute the content across multiple regions.
B) Deploy the website to all regions in different VPCs for faster processing.

QUESTION_ID_PLACEHOLDER
A popular augmented reality (AR) mobile game is heavily using a RESTful API which is hosted in AWS. The API uses Amazon API Gateway and a DynamoDB table with a preconfigured read and write capacity. Based on your systems monitoring, the DynamoDB table begins to throttle requests during high peak loads which causes the slow performance of the game. 
Which of the following can you do to improve the performance of your app? 
B) Integrate an Application Load Balancer with your DynamoDB table. 
+A) Use DynamoDB Auto Scaling 
B) Add the DynamoDB table to an Auto Scaling Group. 
B) Create an SQS queue in front of the DynamoDB table. 

QUESTION_ID_PLACEHOLDER
A large multinational investment bank has a web application that requires a minimum of 4 EC2 instances to run to ensure that it can cater to its users across the globe. You are instructed to ensure fault tolerance of this system.
Which of the following is the best option?
+A) Deploy an Auto Scaling group with 2 instances in each of 3 Availability Zones behind an Application Load Balancer.
B) Deploy an Auto Scaling group with 4 instances in one Availability Zone behind an Application Load Balancer.
B) Deploy an Auto Scaling group with 2 instances in each of 2 Availability Zones behind an Application Load Balancer.
B) Deploy an Auto Scaling group with 1 instance in each of 4 Availability Zones behind an Application Load Balancer.

QUESTION_ID_PLACEHOLDER
A company has a distributed application in AWS that periodically processes large volumes of data across multiple instances. The Solutions Architect designed the application to recover gracefully from any instance failures. He is then required to launch the application in the most cost-effective way.
Which type of EC2 instance will meet this requirement?
+A) Spot Instances
B) Reserved instances
B) Dedicated instances
B) On-Demand instances

QUESTION_ID_PLACEHOLDER
A new company policy requires IAM users to change their passwords’ minimum length to 12 characters. After a random inspection, you found out that there are still employees who do not follow the policy.
How can you automatically check and evaluate whether the current password policy for an account complies with the company password policy?
B) Create a rule in the Amazon CloudWatch event. Build an event pattern to match events on IAM. Set the event name to “ChangePassword” in the event pattern. Configure SNS to send notifications to you whenever a user has made changes to his password.
B) Create a Scheduled Lambda Function that will run a custom script to check compliance against changes made to the passwords periodically.
+A) Configure AWS Config to trigger an evaluation that will check the compliance for a user’s password periodically.
B) Create a CloudTrail trail. Filter the result by setting the attribute to “Event Name” and lookup value to “ChangePassword”. This easily gives you the list of users who have made changes to their passwords.

QUESTION_ID_PLACEHOLDER
A company is looking to store their confidential financial files in AWS which are accessed every week. The Architect was instructed to set up the storage system which uses envelope encryption and automates key rotation. It should also provide an audit trail that shows who used the encryption key and by whom for security purposes.
Which combination of actions should the Architect implement to satisfy the requirement in the most cost-effective way?
B) Configure Server-Side Encryption with Customer-Provided Keys (SSE-C).
+A) Configure Server-Side Encryption with AWS KMS-Managed Keys (SSE-KMS).
B) Configure Server-Side Encryption with Amazon S3-Managed Keys (SSE-S3).
+A) Use Amazon S3 to store the data.
B) Amazon Certificate Manager
B) Use Amazon S3 Glacier Deep Archive to store the data.

QUESTION_ID_PLACEHOLDER
A company has a two-tier environment in its on-premises data center which is composed of an application tier and database tier. You are instructed to migrate their environment to the AWS cloud, and to design the subnets in their VPC with the following requirements:
1. There is an application load balancer that would distribute the incoming traffic among the servers in the application tier.
2. The application tier and the database tier must not be accessible from the public Internet. The application tier should only accept traffic coming from the load balancer.
3. The database tier contains very sensitive data. It must not share the same subnet with other AWS resources and its custom route table with other instances in the environment.
4. The environment must be highly available and scalable to handle a surge of incoming traffic over the Internet.
How many subnets should you create to meet the above requirements?
+A) 6
B) 2
B) 3
B) 4

QUESTION_ID_PLACEHOLDER
There is a new compliance rule in your company that audits every Windows and Linux EC2 instances each month to view any performance issues. They have more than a hundred EC2 instances running in production, and each must have a logging function that collects various system details regarding that instance. The SysOps team will periodically review these logs and analyze their contents using AWS Analytics tools, and the result will need to be retained in an S3 bucket.
In this scenario, what is the most efficient way to collect and analyze logs from the instances with minimal effort?
B) Install AWS Inspector Agent in each instance which will collect and push data to CloudWatch Logs periodically. Set up a CloudWatch dashboard to properly analyze the log data of all instances.
+A) Install the unified CloudWatch Logs agent in each instance which will automatically collect and push data to CloudWatch Logs. Analyze the log data with CloudWatch Logs Insights.
B) Install AWS SDK in each instance and create a custom daemon script that would collect and push data to CloudWatch Logs periodically. Enable CloudWatch detailed monitoring and use CloudWatch Logs Insights to analyze the log data of all instances.
B) Install the AWS Systems Manager Agent (SSM Agent) in each instance which will automatically collect and push data to CloudWatch Logs. Analyze the log data with CloudWatch Logs Insights.

QUESTION_ID_PLACEHOLDER
An auto scaling group of Linux EC2 instances is created with basic monitoring enabled in CloudWatch. You noticed that your application is slow so you asked one of your engineers to check all of your EC2 instances. After checking your instances, you noticed that the auto scaling group is not launching more instances as it should be, even though the servers already have high memory usage.
Which of the following options should the Architect implement to solve this issue?
+A) Install the CloudWatch agent to the EC2 instances which will trigger your Auto Scaling group to scale out.
B) Install AWS SDK in the EC2 instances. Create a script that will trigger the Auto Scaling event if there is high memory usage.
B) Enable detailed monitoring on the instances.
B) Modify the scaling policy to increase the threshold to scale out the number of instances.

QUESTION_ID_PLACEHOLDER
A tech startup has recently received a Series A round of funding to continue building their mobile forex trading application. You are hired to set up their cloud architecture in AWS and to implement a highly available, fault tolerant system. For their database, they are using DynamoDB and for authentication, they have chosen to use Cognito. Since the mobile application contains confidential financial transactions, there is a requirement to add a second authentication method that doesn't rely solely on user name and password.   
How can you implement this in AWS?
B) Integrate Cognito with Amazon SNS Mobile Push to allow additional authentication via SMS.
+A) Add multi-factor authentication (MFA) to a user pool in Cognito to protect the identity of your users.
B) Add a new IAM policy to a user pool in Cognito.
B) Develop a custom application that integrates with Cognito that implements a second layer of authentication.

QUESTION_ID_PLACEHOLDER
An online trading platform with thousands of clients across the globe is hosted in AWS. To reduce latency, you have to direct user traffic to the nearest application endpoint to the client. The traffic should be routed to the closest edge location via an Anycast static IP address. AWS Shield should also be integrated into the solution for DDoS protection.
Which of the following is the MOST suitable service that the Solutions Architect should use to satisfy the above requirements?
B) AWS PrivateLink
B) Amazon CloudFront
+A) AWS Global Accelerator
B) AWS WAF

QUESTION_ID_PLACEHOLDER
A company has an OLTP (Online Transactional Processing) application that is hosted in an Amazon ECS cluster using the Fargate launch type. It has an Amazon RDS database that stores data of its production website. The Data Analytics team needs to run queries against the database to track and audit all user transactions. These query operations against the production database must not impact application performance in any way.
Which of the following is the MOST suitable and cost-effective solution that you should implement?
B) Set up a Multi-AZ deployments configuration of your production database in RDS. Direct the Data Analytics team to query the production data from the standby instance.
B) Upgrade the instance type of the RDS database to a large instance.
+A) Set up a new Amazon RDS Read Replica of the production database. Direct the Data Analytics team to query the production data from the replica.
B) Set up a new Amazon Redshift database cluster. Migrate the product database into Redshift and allow the Data Analytics team to fetch data from it.

QUESTION_ID_PLACEHOLDER
A company has stored 200 TB of backup files in Amazon S3. The files are in a vendor-proprietary format. The Solutions Architect needs to use the vendor's proprietary file conversion software to retrieve the files from their Amazon S3 bucket, transform the files to an industry-standard format, and re-upload the files back to Amazon S3. The solution must minimize the data transfer costs.
Which of the following options can satisfy the given requirement?
B) Export the data using AWS Snowball Edge device. Install the file conversion software on the device. Transform the data and re-upload it to Amazon S3.
B) Deploy the EC2 instance in a different Region. Install the conversion software on the instance. Perform data transformation and re-upload it to Amazon S3.
+A) Deploy the EC2 instance in the same Region as Amazon S3. Install the file conversion software on the instance. Perform data transformation and re-upload it to Amazon S3.
B) Install the file conversion software in Amazon S3. Use S3 Batch Operations to perform data transformation.

QUESTION_ID_PLACEHOLDER
A company is using an Auto Scaling group which is configured to launch new t2.micro EC2 instances when there is a significant load increase in the application. To cope with the demand, you now need to replace those instances with a larger t2.2xlarge instance type.
How would you implement this change?
+A) Create a new launch configuration with the new instance type and update the Auto Scaling Group.
B) Just change the instance type to t2.2xlarge in the current launch configuration
B) Create another Auto Scaling Group and attach the new instance type.
B) Change the instance type of each EC2 instance manually.

QUESTION_ID_PLACEHOLDER
A company has a web application hosted in an On-Demand EC2 instance. You are creating a shell script that needs the instance's public and private IP addresses.
What is the best way to get the instance's associated IP addresses which your shell script can use?
B) By using IAM.
B) By using a Curl or Get Command to get the latest user data information from http://169.254.169.254/latest/user-data/
+A) By using a Curl or Get Command to get the latest metadata information from http://169.254.169.254/latest/meta-data/
B) By using a CloudWatch metric.

QUESTION_ID_PLACEHOLDER
A company launched an EC2 instance in the newly created VPC. They noticed that the generated instance does not have an associated DNS hostname.
Which of the following options could be a valid reason for this issue?
B) The security group of the EC2 instance needs to be modified.
+A) The DNS resolution and DNS hostname of the VPC configuration should be enabled.
B) Amazon Route53 is not enabled.
B) The newly created VPC has an invalid CIDR block.

QUESTION_ID_PLACEHOLDER
A financial company instructed you to automate the recurring tasks in your department such as patch management, infrastructure selection, and data synchronization to improve their current processes. You need to have a service which can coordinate multiple AWS services into serverless workflows.   
Which of the following is the most cost-effective service to use in this scenario?
+A) AWS Step Functions
B) AWS Lambda
B) AWS Batch
B) SWF

QUESTION_ID_PLACEHOLDER
A tech company currently has an on-premises infrastructure. They are currently running low on storage and want to have the ability to extend their storage using the AWS cloud.
Which AWS service can help them achieve this requirement?
B) Amazon SQS
B) Amazon EC2
+A) Amazon Storage Gateway
B) Amazon Elastic Block Storage

QUESTION_ID_PLACEHOLDER
A web application requires a minimum of six Amazon Elastic Compute Cloud (EC2) instances running at all times. You are tasked to deploy the application to three availability zones in the EU Ireland region (eu-west-1a, eu-west-1b, and eu-west-1c). It is required that the system is fault-tolerant up to the loss of one Availability Zone.
Which of the following setup is the most cost-effective solution which also maintains the fault-tolerance of your system?
B) 6 instances in eu-west-1a, 6 instances in eu-west-1b, and no instances in eu-west-1c
B) 6 instances in eu-west-1a, 6 instances in eu-west-1b, and 6 instances in eu-west-1c
B) 2 instances in eu-west-1a, 2 instances in eu-west-1b, and 2 instances in eu-west-1c
+A) 3 instances in eu-west-1a, 3 instances in eu-west-1b, and 3 instances in eu-west-1c

QUESTION_ID_PLACEHOLDER
A company plans to reduce the amount of data that Amazon S3 transfers to the servers in order to lower the operating costs as well as lower the latency of retrieving the data. To accomplish this, you need to use simple structured query language (SQL) statements to filter the contents of Amazon S3 objects and retrieve just the subset of data that you need.
Which of the following services will help you accomplish this requirement?
+A) S3 Select
B) AWS Step Functions
B) Redshift Spectrum
B) RDS

QUESTION_ID_PLACEHOLDER
A company needs to integrate the Lightweight Directory Access Protocol (LDAP) directory service from the on-premises data center to the AWS VPC using IAM. The identity store which is currently being used is not compatible with SAML.
Which of the following provides the most valid approach to implement the integration?
+A) Develop an on-premises custom identity broker application and use STS to issue short-lived AWS credentials.
B) Use IAM roles to rotate the IAM credentials whenever LDAP credentials are updated.
B) Use an IAM policy that references the LDAP identifiers and AWS credentials.
B) Use AWS Single Sign-On (SSO) service to enable single sign-on between AWS and your LDAP.

QUESTION_ID_PLACEHOLDER
A Solutions Architect is designing a monitoring application which generates audit logs of all operational activities of the company's cloud infrastructure. Their IT Security and Compliance team mandates that the application retain the logs for 5 years before the data can be deleted.
How can the Architect meet the above requirement?
B) Store the audit logs in an EBS volume and then take EBS snapshots every month.
B) Store the audit logs in an EFS volume and use Network File System version 4 (NFSv4) file-locking mechanism.
+A) Store the audit logs in a Glacier vault and use the Vault Lock feature.
B) Store the audit logs in an Amazon S3 bucket and enable Multi-Factor Authentication Delete (MFA Delete) on the S3 bucket.

QUESTION_ID_PLACEHOLDER
A Solutions Architect is working for a large global media company with multiple office locations all around the world. The Architect is instructed to build a system to distribute training videos to all employees.
Using CloudFront, what method would be used to serve content that is stored in S3, but not publicly accessible from S3 directly?
B) Create an S3 bucket policy that lists the CloudFront distribution ID as the principal and the target bucket as the Amazon Resource Name (ARN).
+A) Create an Origin Access Identity (OAI) for CloudFront and grant access to the objects in your S3 bucket to that OAI.
B) Create a web ACL in AWS WAF to block any public S3 access and attach it to the Amazon CloudFront distribution.
B) Create an Identity and Access Management (IAM) user for CloudFront and grant access to the objects in your S3 bucket to that IAM user.

QUESTION_ID_PLACEHOLDER
A company has a set of Linux servers running on multiple On-Demand EC2 Instances. The Audit team wants to collect and process the application log files generated from these servers for their report.
Which of the following services is best to use in this case?
B) Amazon S3 Glacier Deep Archive for storing the application log files and AWS ParallelCluster for processing the log files.
+A) Amazon S3 for storing the application log files and Amazon Elastic MapReduce for processing the log files.
B) A single On-Demand Amazon EC2 instance for both storing and processing the log files
B) Amazon S3 Glacier for storing the application log files and Spot EC2 Instances for processing them.

QUESTION_ID_PLACEHOLDER
An organization plans to use an AWS Direct Connect connection to establish a dedicated connection between its on-premises network and AWS. The organization needs to launch a fully managed solution that will automate and accelerate the replication of data to and from various AWS storage services.
Which of the following solutions would you recommend?
B) Use an AWS Storage Gateway file gateway to store and retrieve files directly using the SMB file system protocol.
B) Use an AWS DataSync agent to rapidly move the data over the Internet.
+A) Use an AWS DataSync agent to rapidly move the data over a service endpoint.
B) Use an AWS Storage Gateway tape gateway to store data on virtual tape cartridges and asynchronously copy your backups to AWS.

QUESTION_ID_PLACEHOLDER
A company deployed an online enrollment system database on a prestigious university, which is hosted in RDS. The Solutions Architect is required to monitor the database metrics in Amazon CloudWatch to ensure the availability of the enrollment system.
What are the enhanced monitoring metrics that Amazon CloudWatch gathers from Amazon RDS DB instances which provide more accurate information?
B) CPU Utilization
B) Freeable Memory
B) Database Connections
+A) RDS child processes.
+A) OS processes

QUESTION_ID_PLACEHOLDER
A company plans to deploy an application in an Amazon EC2 instance. The application will perform the following tasks:
1. Read large datasets from an Amazon S3 bucket.
2. Execute multi-stage analysis on the datasets.
3. Save the results to Amazon RDS.
During multi-stage analysis, the application will store a large number of temporary files in the instance storage. As the Solutions Architect, you need to recommend the fastest storage option with high I/O performance for the temporary files.
Which of the following options fulfills this requirement?
+A) Configure RAID 0 in multiple instance store volumes.
B) Configure RAID 1 in multiple instance store volumes.
B) Attach multiple Provisioned IOPS SSD volumes in the instance.
B) Enable Transfer Acceleration in Amazon S3.

QUESTION_ID_PLACEHOLDER
A financial firm is designing an application architecture for its online trading platform that must have high availability and fault tolerance. Their Solutions Architect configured the application to use an Amazon S3 bucket located in the us-east-1 region to store large amounts of intraday financial data. The stored financial data in the bucket must not be affected even if there is an outage in one of the Availability Zones or if there's a regional service failure.
What should the Architect do to avoid any costly service disruptions and ensure data durability?
+A) Enable Cross-Region Replication.
B) Create a Lifecycle Policy to regularly backup the S3 bucket to Amazon Glacier.
B) Create a new S3 bucket in another region and configure Cross-Account Access to the bucket located in us-east-1.
B) Copy the S3 bucket to an EBS-backed EC2 instance.

QUESTION_ID_PLACEHOLDER
An application is using a RESTful API hosted in AWS which uses Amazon API Gateway and AWS Lambda. There is a requirement to trace and analyze user requests as they travel through your Amazon API Gateway APIs to the underlying services. 
Which of the following is the most suitable service to use to meet this requirement?
B) VPC Flow Logs
B) CloudTrail
B) CloudWatch
+A) AWS X-Ray

QUESTION_ID_PLACEHOLDER
A company plans to migrate a NoSQL database to an EC2 instance. The database is configured to replicate the data automatically to keep multiple copies of data for redundancy. The Solutions Architect needs to launch an instance that has a high IOPS and sequential read/write access.
Which of the following options fulfills the requirement if I/O throughput is the highest priority?
+A) Use Storage optimized instances with instance store volume.
B) Use Compute optimized instance with instance store volume.
B) Use General purpose instances with EBS volume.
B) Use Memory optimized instances with EBS volume.

QUESTION_ID_PLACEHOLDER
There are a few, easily reproducible but confidential files that your client wants to store in AWS without worrying about storage capacity. For the first month, all of these files will be accessed frequently but after that, they will rarely be accessed at all. The old files will only be accessed by developers so there is no set retrieval time requirement. However, the files under a specific corp-finance prefix in the S3 bucket will be used for post-processing that requires millisecond retrieval time.
Given these conditions, which of the following options would be the most cost-effective solution for your client's storage needs?
B) Store the files in S3 then after a month, change the storage class of the bucket to S3-IA using lifecycle policy.
B) Store the files in S3 then after a month, change the storage class of the corp-finance prefix to S3-IA while the remaining go to Glacier using lifecycle policy.
+A) Store the files in S3 then after a month, change the storage class of the corp-finance prefix to One Zone-IA while the remaining go to Glacier using lifecycle policy.
B) Store the files in S3 then after a month, change the storage class of the bucket to Intelligent-Tiering using lifecycle policy.

QUESTION_ID_PLACEHOLDER
A company recently migrated their applications to AWS. The Solutions Architect must ensure that the applications are highly available and safe from common web security vulnerabilities.
Which is the most suitable AWS service to use to mitigate Distributed Denial of Service (DDoS) attacks from hitting your back-end EC2 instances?
B) Amazon GuardDuty 
B) AWS Firewall Manager 
+A) AWS Shield 
B) AWS WAF 

QUESTION_ID_PLACEHOLDER
A large electronics company is using Amazon Simple Storage Service to store important documents. For reporting purposes, they want to track and log every request access to their S3 buckets including the requester, bucket name, request time, request action, referrer, turnaround time, and error code information. The solution should also provide more visibility into the object-level operations of the bucket.
Which is the best solution among the following options that can satisfy the requirement?
B) Enable Amazon S3 Event Notifications for PUT and POST.
+A) Enable server access logging for all required Amazon S3 buckets.
B) Enable AWS CloudTrail to audit all Amazon S3 bucket access.
B) Enable the Requester Pays option to track access via AWS Billing.

QUESTION_ID_PLACEHOLDER
A company needs to implement a solution that will process real-time streaming data of its users across the globe. This will enable them to track and analyze globally-distributed user activity on their website and mobile applications, including clickstream analysis. The solution should process the data in close geographical proximity to their users and respond to user requests at low latencies.
Which of the following is the most suitable solution for this scenario?
+A) Integrate CloudFront with Lambda@Edge in order to process the data in close geographical proximity to users and respond to user requests at low latencies. Process real-time streaming data using Kinesis and durably store the results to an Amazon S3 bucket.
B) Integrate CloudFront with Lambda@Edge in order to process the data in close geographical proximity to users and respond to user requests at low latencies. Process real-time streaming data using Amazon Athena and durably store the results to an Amazon S3 bucket.
B) Use a CloudFront web distribution and Route 53 with a latency-based routing policy, in order to process the data in close geographical proximity to users and respond to user requests at low latencies. Process real-time streaming data using Kinesis and durably store the results to an Amazon S3 bucket.
B) Use a CloudFront web distribution and Route 53 with a Geoproximity routing policy in order to process the data in close geographical proximity to users and respond to user requests at low latencies. Process real-time streaming data using Kinesis and durably store the results to an Amazon S3 bucket.

QUESTION_ID_PLACEHOLDER
A technology company is building a new cryptocurrency trading platform that allows the buying and selling of Bitcoin, Ethereum, Ripple, Tether, and many others. You were hired as a Cloud Engineer to build the required infrastructure needed for this new trading platform. On your first week at work, you started to create CloudFormation YAML scripts that define all of the needed AWS resources for the application. Your manager was shocked that you haven't created the EC2 instances, S3 buckets, and other AWS resources straight away. He does not understand the text-based scripts that you have done and has asked for your clarification.
In this scenario, what are the benefits of using the Amazon CloudFormation service that you should tell your manager to clarify his concerns?
+A) Enables modeling, provisioning, and version-controlling of your entire AWS infrastructure
B) A storage location for the code of your application
B) Provides highly durable and scalable data storage
+A) Allows you to model your entire infrastructure in a text file
B) Using CloudFormation itself is free, including the AWS resources that have been created.

QUESTION_ID_PLACEHOLDER
A company launched a global news website that is deployed to AWS and is using MySQL RDS. The website has millions of viewers from all over the world which means that the website has read-heavy database workloads. All database transactions must be ACID compliant to ensure data integrity.
In this scenario, which of the following is the best option to use to increase the read throughput on the MySQL database?
+A) Enable Amazon RDS Read Replicas
B) Enable Multi-AZ deployments
B) Enable Amazon RDS Standby Replicas
B) Use SQS to queue up the requests

